{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7d3862",
   "metadata": {},
   "source": [
    "\n",
    "## NanoDiP all-in-one Jupyter Notebook\n",
    "\n",
    "*J. Hench, C. Hultschig, J. Brugger, and S. Frank, Neuropathology, IfP Basel,\n",
    "2021-2022*\n",
    "\n",
    "This software is provided free of charge and warranty; by using it you agree to\n",
    "do this on your own risk. The authors shall not be held liable for any damage\n",
    "caused by this software. We have assembled this and tested it to the best of\n",
    "our knowledge.\n",
    "\n",
    "The purpose of NanoDiP (Nanopore Digital Pathology) is to compare low-coverage\n",
    "Nanopore sequencing data from natively extracted DNA sequencing runs against a\n",
    "flexibly adaptable collection of 450K/850K Illumina Infinium Methylation array\n",
    "data. These data have to be preprocessed into binary beta value files; this\n",
    "operation is performed in R (uses minfi to read raw array data) and outputs\n",
    "bindary float files (one per dataset). These beta values files (e.g.,\n",
    "204949770141_R03C01_betas_filtered.bin) are named according to the array ID\n",
    "(Sentrix ID) followed by the suffix. A collection of betas_filtered.bin files\n",
    "can be provided in a static manner and XLSX (Microsoft Excel) tables can be\n",
    "used to select a subset thereof alongside a user-defined annotation. The\n",
    "corresponding datasets will be loaded into memory and then serve as the\n",
    "reference cohort to which the Nanopore data are compared by dimension reduction\n",
    "(UMAP). This comparison is optimized for speed and low resource consumption so\n",
    "that it can run on the computer that operates the sequencer. The sequencing run\n",
    "is initiated through the MinKNOW API by this application. Basecalling and\n",
    "methylation calling occur as background tasks outside this Jupyter Notebook.\n",
    "User interaction occurs through a web interface based on CherryPy which has\n",
    "been tested on Chromium web browser. It is advisable to run it locally, there\n",
    "are no measures to secure the generated website.\n",
    "\n",
    "In order to use this application properly please make sure to be somewhat\n",
    "familiar with Jupyter Notebook. To run the software, press the button called\n",
    "*restart the kernel, re-run the whole notebook (with dialog)* and confirm\n",
    "execution. Then, in Chromium Browser, navigate to http://localhost:8080/ and\n",
    "preferably bookmark this location for convenience. In case of errors, you may\n",
    "just again click the same button *restart the kernel, re-run the whole notebook\n",
    "(with dialog)*.\n",
    "\n",
    "___ ### Technical Details\n",
    "* Tested with Python 3.7.5; 3.8.8 fails to load minknow_api in jupyter\n",
    "* notebook.  Verified to run on Ubuntu 18.04/Jetpack on ARMv8 and x86_64 CPUs;\n",
    "* not tested on Windows and Mac OS. The latter two platforms are unsupported,\n",
    "* we do not intend to support them.  **CAUTION**: Requires a *patched* version\n",
    "* of minknow api, file\n",
    "* `[VENV]/lib/python3.7/site-packages/minknow_api/tools/protocols.py`. Without\n",
    "* the patch, the generated fast5 sequencing data will be unreadable with f5c or\n",
    "* nanopolish (wrong compression algorithm, which is the default in the MinKNOW\n",
    "* backend).\n",
    "\n",
    "___ ### Headless / Command Line Mode CherryPy, the underlying web server of\n",
    "NanoDiP allows for headless (command line-based) utilization of the software\n",
    "besides or instead of browser-based use. Hence, the software may be operated as\n",
    "a post-hoc analysis pipeline for previously acquired data. This is particularly\n",
    "useful for benchmarking and validation purposes.\n",
    "\n",
    "#### Examples: Generate copy number of for sample\n",
    "**GBM_RTK2_20210311_Testrun_BC06**: `curl\n",
    "'http://localhost:8080/cnvplot?sampleName=GBM_RTK2_20210311_Testrun_BC06'`\n",
    "\n",
    "Calculate UMAP plot for sample **GBM_RTK2_20210311_Testrun_BC06** with\n",
    "reference annotation **AllIDATv2_20210804.xlsx**: `curl\n",
    "'http://localhost:8080/umapplot?sampleName=GBM_RTK2_20210311_Testrun_BC06&refAnno=AllIDATv2_20210804.xlsx'`\n",
    "\n",
    "Assemble PDF report for sample **GBM_RTK2_20210311_Testrun_BC06** with\n",
    "reference annotation **AllIDATv2_20210804.xlsx**: `curl\n",
    "'http://localhost:8080/makePdf?sampleName=GBM_RTK2_20210311_Testrun_BC06&refAnno=AllIDATv2_20210804.xlsx'`\n",
    "\n",
    "### Version Details\n",
    "\n",
    "**30:** UMAP report score / PDF (NanoDiP)\n",
    "\n",
    "**32:** UMAP report score / PDF (EpiDiP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede3d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify running Python version (should be 3.7.5) and adjust jupyter notebook.\n",
    "import IPython\n",
    "import os\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5cfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set display witdth to 100%\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "os.system('python --version')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7937236",
   "metadata": {},
   "source": [
    "\n",
    "## Multithreading Options\n",
    "Depending on the number of parallel threads/cores of the underlying hardware,\n",
    "threading options for multithreaded modules need to be set as\n",
    "environment-specific parameters. One way to do so is through the *os* module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution-wide multithreading options, set according to your hardware. Jetson\n",
    "# AGX: suggest \"2\" needs to be set before importing other modules that query\n",
    "# these parameters.\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a3ea4",
   "metadata": {},
   "source": [
    "\n",
    "## Modules\n",
    "This section imports the required modules that should have been installed via\n",
    "pip. Other package managers have not been tested. To install packages, use the\n",
    "setup script provided with this software or, alternatively, install them one\n",
    "by one, ideally in a virtual python environment. Note that the MinKNOW API\n",
    "requires manual patching after installation with pip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a816f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minknow_api.acquisition_pb2 import READY, STARTING, PROCESSING, FINISHING\n",
    "from minknow_api.manager import Manager\n",
    "from minknow_api.tools import protocols\n",
    "from pdf2image import convert_from_path\n",
    "from plotly.io import write_json, from_json\n",
    "from tqdm import tqdm\n",
    "from urllib import request\n",
    "import argparse\n",
    "import bisect\n",
    "import cherrypy\n",
    "import colorsys\n",
    "import csv\n",
    "import datetime\n",
    "import grpc\n",
    "import hashlib\n",
    "import inspect\n",
    "import jinja2\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import psutil\n",
    "import pysam\n",
    "import re\n",
    "import shutil\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import threading\n",
    "import warnings\n",
    "import xhtml2pdf.pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049bef9c",
   "metadata": {},
   "source": [
    "\n",
    "Configuration\n",
    "-------------------------------------------------------------------------------\n",
    "Below are system-specific parameters that may or may not require adaptation.\n",
    "Many variable names are self-explanatory. The key difference between Nanopore\n",
    "setups are between devices provided by ONT (MinIT inclusively running the MinIT\n",
    "distribution on a NVIDIA Jetson developer kit such as the AGX Xavier, GridION)\n",
    "and the typical Ubuntu-based MinKNOW version on x86_64 computers. The raw data\n",
    "are written into a `/data` directory on ONT-based devices while they are found\n",
    "in `/var/lib/minknow/data` on x86_64 installations. Make sure to adapt your\n",
    "`DATA` accordingly. There are furthermore permission issues and special folders\n",
    "/ files in the MinKNOW data directory. These files / folders should be excluded\n",
    "from analysis through `EXCLUDED_FROM_ANALYSIS` so that only real run folders\n",
    "will be parsed. Finally, the `NANODIP_OUTPUT` is the place in which the\n",
    "background methylation and alignment process will place its results by\n",
    "replicating the directory hierarchy of the MinKNOW data location.  It will not\n",
    "duplicate the data, and these data will be much smaller than raw run data. They\n",
    "can be placed anywhere in the file tree, but also inside the MinKNOW data path\n",
    "within a sub-folder. If the latter is the case, make sure to apply appropriate\n",
    "read/write permissions. Final reports and figures generated by NanoDiP are\n",
    "written into `NANODIP_REPORTS`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c234452",
   "metadata": {},
   "source": [
    "\n",
    "General\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb207fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NanoDiP version number.\n",
    "__version__ = \"31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e585a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables/disables debug mode.\n",
    "DEBUG_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458537f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement this.\n",
    "VERBOSITY = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bad413",
   "metadata": {},
   "source": [
    "\n",
    "Data directories for MinKNOW and NanoDiP output.\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f004e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where MinKNOW places its data.\n",
    "DATA = \"/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254af578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to write intermediate analysis data, i.e. methylation and alignment\n",
    "# files.\n",
    "NANODIP_OUTPUT = os.path.join(DATA, \"nanodip_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location to write reports and figures.\n",
    "NANODIP_REPORTS = os.path.join(DATA, \"nanodip_reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce7e57",
   "metadata": {},
   "source": [
    "\n",
    "Reference data\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02befb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of all reference data.\n",
    "REFERENCE_DATA = \"/applications/reference_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of preprocessed beta values.\n",
    "BETA_VALUES = os.path.join(REFERENCE_DATA, \"betaEPIC450Kmix_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of annotation spreadsheets.\n",
    "ANNOTATIONS = os.path.join(REFERENCE_DATA, \"reference_annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b375c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spreadsheet containing description of annotation codes (Basel internal).\n",
    "ANNOTATIONS_ABBREVIATIONS_BASEL = os.path.join(\n",
    "    ANNOTATIONS, \"mc_anno_ifp_basel.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spreadsheet containing description of annotation codes (TCGA). From:\n",
    "# https://gdc.cancer.gov/resources-tcga-users/tcga-code-tables/tcga-study-abbreviations\n",
    "ANNOTATIONS_ABBREVIATIONS_TCGA = os.path.join(\n",
    "    ANNOTATIONS, \"tcga_study_abbreviations.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illumina probe names of the 450K array.\n",
    "ILLUMINA_CG_MAP = os.path.join(\n",
    "    REFERENCE_DATA,\n",
    "    \"minimap_data/hg19_HumanMethylation450_15017482_v1-2_cgmap.tsv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of binary methylation data and metadata.\n",
    "REFERENCE_METHYLATION_DATA = os.path.join(REFERENCE_DATA, \"EPIC450K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary methylation file.\n",
    "REFERENCE_METHYLATION = os.path.join(\n",
    "    REFERENCE_METHYLATION_DATA, \"methylation.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483a99c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata containing list of CpG names.\n",
    "REFERENCE_CPG_SITES = os.path.join(REFERENCE_METHYLATION_DATA, \"cpg_sites.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffcbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata containing names of specimens.\n",
    "REFERENCE_SPECIMENS = os.path.join(REFERENCE_METHYLATION_DATA, \"specimens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa072054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata containing methylation matrix dimensions.\n",
    "REFERENCE_METHYLATION_SHAPE = os.path.join(\n",
    "    REFERENCE_METHYLATION_DATA, \"shape.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69323b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genome reference data containing chromosome lengths and centromere position.\n",
    "CHROMOSOMES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19_chromosomes.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98be0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human reference genome in fa format.\n",
    "REFERENCE_GENOME_FA = os.path.join(REFERENCE_DATA, \"minimap_data/hg19.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human reference genome in minimap2 mmi format.\n",
    "REFERENCE_GENOME_MMI = os.path.join(\n",
    "    REFERENCE_DATA, \"minimap_data/hg19_20201203.mmi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HG19 Gene data downloaded from:\n",
    "# https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/genes/hg19.refGene.gtf.gz\n",
    "GENES_RAW = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19.refGene.gtf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f25b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the data from GENES_RAW in simplified form.\n",
    "GENES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd20ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of clinically important genes.\n",
    "RELEVANT_GENES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"relevant_genes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a335e",
   "metadata": {},
   "source": [
    "\n",
    "File handling\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String patterns in sample names that exclude data from downstream analysis,\n",
    "# e.g., test runs\n",
    "ANALYSIS_EXCLUSION_PATTERNS = [\"_TestRun_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files and folders in DATA to be excluded from analysis.\n",
    "EXCLUDED_FROM_ANALYSIS = [\n",
    "    \".Trash-1000\",\n",
    "    \"core-dump-db\",\n",
    "    \"intermediate\",\n",
    "    \"lost+found\",\n",
    "    \"minimap_data\",\n",
    "    \"nanodip_output\",\n",
    "    \"nanodip_reports\",\n",
    "    \"nanodip_tmp\",\n",
    "    \"non-ont\",\n",
    "    \"pings\",\n",
    "    \"playback_raw_runs\",\n",
    "    \"queued_reads\",\n",
    "    \"raw_for_playback\",\n",
    "    \"reads\",\n",
    "    \"user_scripts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file name sections that identify past runs.\n",
    "RESULT_ENDING = {\n",
    "    \"cnv_png\": \"CNVplot.png\",\n",
    "    \"ranking\": \"NanoDiP_ranking.pdf\",\n",
    "    \"report\": \"NanoDiP_report.pdf\",\n",
    "    \"umap_all\": \"UMAP_all.html\",\n",
    "    \"umap_top\": \"UMAP_top.html\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bd800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used file endings.\n",
    "ENDING = {\n",
    "    **RESULT_ENDING,\n",
    "    \"aligned_reads\": \"alignedreads.txt\",\n",
    "    \"cnv_bins_json\": \"CNV_binsplot.json\",\n",
    "    \"cnv_html\": \"CNVplot.html\",\n",
    "    \"cnv_json\": \"CNVplot.json\",\n",
    "    \"cnv_pdf\": \"CNVplot.pdf\",\n",
    "    \"cnv_png\": \"CNVplot.png\",\n",
    "    \"cpg_cnt\": \"cpgcount.txt\",\n",
    "    \"genes\": \"genes.csv\",\n",
    "    \"methyl\": \"methyl_overlap.npy\",\n",
    "    \"pie\": \"pie.png\",\n",
    "    \"reads_csv\": \"reads.csv\",\n",
    "    \"relevant_genes\": \"relevant_genes.csv\",\n",
    "    \"sel_ref\": \"selected_reference.txt\",\n",
    "    \"umap_all_html\": \"UMAP_all.html\",\n",
    "    \"umap_all_json\": \"UMAP_all.json\",\n",
    "    \"umap_all_png\": \"UMAP_all.png\",\n",
    "    \"umap_csv\": \"UMAP.csv\",\n",
    "    \"umap_top_json\": \"UMAP_top.json\",\n",
    "    \"umap_top_png\": \"UMAP_top.png\",\n",
    "    \"umap_xlsx\": \"UMAP.xlsx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff7ef2",
   "metadata": {},
   "source": [
    "\n",
    "Experiments & basecalling\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290311f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta values above this cutoff will be interpreted as methylated.\n",
    "METHYLATION_CUTOFF = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcode strings, currently kit SQK-RBK004.\n",
    "BARCODE_NAMES = [\n",
    "    \"barcode01\",\n",
    "    \"barcode02\",\n",
    "    \"barcode03\",\n",
    "    \"barcode04\",\n",
    "    \"barcode05\",\n",
    "    \"barcode06\",\n",
    "    \"barcode07\",\n",
    "    \"barcode08\",\n",
    "    \"barcode09\",\n",
    "    \"barcode10\",\n",
    "    \"barcode11\",\n",
    "    \"barcode12\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f25d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reads per file. 400 works well on the Jetson AGX. Higher numbers\n",
    "# increase batch size and RAM usage, lower numbers use more I/O resources due\n",
    "# to more frequent reloading of alignment reference.\n",
    "READS_PER_FILE = \"400\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basecalled bases until run termination occurs.\n",
    "NEEDED_NUMBER_OF_BASES = 150_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to binaries for methylation calling.\n",
    "F5C = \"/applications/f5c/f5c\"\n",
    "MINIMAP2 = \"/applications/nanopolish/minimap2/minimap2\"\n",
    "SAMTOOLS = \"/applications/samtools/samtools\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed331e",
   "metadata": {},
   "source": [
    "\n",
    "UMAP/CNV plots, Epidip\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9319af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to load PDF with CNV plot for a given Sentrix ID (substituted for '%s')\n",
    "CNV_LINK = (\n",
    "    \"http://s1665.rootserver.io/umapplot01/%s_CNV_IFPBasel_annotations.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to load precalculated UMAP coordinates.\n",
    "UMAP_LINK = \"http://s1665.rootserver.io/umap_links/%s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of UMAP coordinate files hosted on EpiDiP.\n",
    "EPIDIP_UMAP_COORDINATE_FILES = [\n",
    "    \"UMAP_all_bVals_top_25000.xlsx\",\n",
    "    \"UMAP_all_bVals_top_50000.xlsx\",\n",
    "    \"UMAP_all_bVals_top_75000.xlsx\",\n",
    "    \"gpumap_25000.xlsx\",\n",
    "    \"gpumap_50000.xlsx\",\n",
    "    \"gpumap_75000.xlsx\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de25ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to precalculated CNV plotly grid.\n",
    "CNV_GRID = \"/applications/reference_data/hg19_cnv/grid.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reference cases to be shown in subplot including copy\n",
    "# number profile links (not advisable >200, plotly will become really\n",
    "# slow)\n",
    "UMAP_PLOT_TOP_MATCHES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa15b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls the browser API used to draw marks. Default \"webgl\", alternative\n",
    "# \"svg\" without proper webgl support (e.g. for Firefox, use \"svg\"; slower,\n",
    "# but does not require GPU).\n",
    "PLOTLY_RENDER_MODE = \"webgl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712a97a",
   "metadata": {},
   "source": [
    "\n",
    "CherryPy\n",
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69282d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host and port on which the NanoDiP UI will be served\n",
    "CHERRYPY_HOST = \"localhost\"\n",
    "THIS_HOST = \"localhost\"\n",
    "CHERRYPY_PORT = 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c27b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web browser favicon file for this application.\n",
    "BROWSER_FAVICON = \"/applications/nanodip/nanodip/static/img/logo.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c0fdf",
   "metadata": {},
   "source": [
    "\n",
    "## Utils\n",
    "\n",
    "Contains general utility functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check():\n",
    "    \"\"\"Checks if reference data is available and generates a warning\n",
    "    otherwise.\n",
    "    \"\"\"\n",
    "    requested_files = [\n",
    "        BETA_VALUES,\n",
    "        ANNOTATIONS_ABBREVIATIONS_BASEL,\n",
    "        ANNOTATIONS_ABBREVIATIONS_TCGA,\n",
    "        ILLUMINA_CG_MAP,\n",
    "        CHROMOSOMES,\n",
    "        REFERENCE_GENOME_FA,\n",
    "        REFERENCE_GENOME_MMI,\n",
    "        GENES_RAW,\n",
    "        GENES,\n",
    "        RELEVANT_GENES,\n",
    "        BROWSER_FAVICON,\n",
    "        F5C,\n",
    "        MINIMAP2,\n",
    "        SAMTOOLS,\n",
    "    ]\n",
    "    for f in requested_files:\n",
    "        if not os.path.exists(f):\n",
    "            warnings.warn(\n",
    "                f\"File '{f}' not found.\\nFunctionality may be restricted.\",\n",
    "                RuntimeWarning,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae35218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_referenced_cpgs(sample_methylation,\n",
    "                            output_overlap,\n",
    "                            output_overlap_cnt):\n",
    "    \"\"\"Extract Illumina CpG sites including methylation status from sample.\n",
    "    Sex chromosomes are removed.\n",
    "\n",
    "    Args:\n",
    "        sample_methylation: methylation file of sample\n",
    "        output_overlap: file path of CpG overlap\n",
    "        output_overlap_cnt: file path of CpG overlap count\n",
    "    \"\"\"\n",
    "    reference_cpgs = pd.read_csv(\n",
    "        ILLUMINA_CG_MAP,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"ilmnid\", \"chromosome\", \"strand\", \"start\"],\n",
    "    )\n",
    "    sample_cpgs = pd.read_csv(\n",
    "        sample_methylation,\n",
    "        delimiter=\"\\t\",\n",
    "    )\n",
    "    cpgs = pd.merge(sample_cpgs, reference_cpgs, on=[\"chromosome\", \"start\"])\n",
    "    # Extract singelton CpG's\n",
    "    cpgs = cpgs.loc[cpgs[\"num_cpgs_in_group\"] == 1]\n",
    "    # Remove duplicates and sex chromosomes\n",
    "    cpgs = cpgs.loc[\n",
    "       (~cpgs[\"chromosome\"].isin([\"chrX\", \"chrY\"]))\n",
    "       & (~cpgs[\"ilmnid\"].duplicated())\n",
    "    ]\n",
    "    cpgs[\"is_methylated\"] = 0\n",
    "    cpgs.loc[cpgs[\"methylated_frequency\"] > 0.5, \"is_methylated\"] = 1\n",
    "    # Write overlap Data Frame\n",
    "    cpgs[[\"ilmnid\", \"is_methylated\"]].to_csv(\n",
    "        output_overlap, header=False, index=False, sep=\"\\t\",\n",
    "    )\n",
    "    # Write number of CpG's\n",
    "    with open(output_overlap_cnt, \"w\") as f:\n",
    "        f.write(f\"{len(cpgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42658868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_template(template_name, **context):\n",
    "    \"\"\"Renders jinja2 templates to HTML.\"\"\"\n",
    "    loader = jinja2.FileSystemLoader(\"templates\")\n",
    "    template = jinja2.Environment(\n",
    "        loader=loader).get_template(template_name)\n",
    "    return template.render(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bcf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_for(url_func, **args):\n",
    "    \"\"\"Transforms a cherrypy function together with argument list to\n",
    "    url string.\n",
    "    Example:\n",
    "        url_for(CherryPyClass.url_func, var0=2, var1=7)\n",
    "        == \"url_func?var0=2&var1=7\"\n",
    "    Raises error if argument names are not correct.\n",
    "    \"\"\"\n",
    "    # Find variable names of url_func.\n",
    "    default = []\n",
    "    non_default = []\n",
    "    sig = inspect.signature(url_func)\n",
    "    for param in sig.parameters.values():\n",
    "        if param.default is param.empty:\n",
    "            non_default.append(param.name)\n",
    "        else:\n",
    "            default.append(param.name)\n",
    "    # Check if variable names are correct.\n",
    "    for param in args:\n",
    "        if param not in default + non_default:\n",
    "            raise ValueError(\n",
    "                f\"'{param}' is not a valid Parameter of {url_func.__name__}.\"\n",
    "            )\n",
    "    url = url_func.__name__\n",
    "    if args:\n",
    "        # If args are supplied, enforce that all mandatory variables are\n",
    "        # contained in args.\n",
    "        for param in non_default:\n",
    "            if param not in args and param != \"self\":\n",
    "                raise ValueError(\n",
    "                    f\"Parameter '{param}' must be supplied.\"\n",
    "                )\n",
    "        url += \"?\" + \"&\".join(\n",
    "            [f\"{key}={value}\" for key, value in args.items()]\n",
    "        )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_html_to_pdf(source_html, output_file):\n",
    "    \"\"\"Create PDF from HTML-string.\"\"\"\n",
    "    with open(output_file, \"w+b\") as f:\n",
    "        xhtml2pdf.pisa.CreatePDF(source_html, dest=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33db8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time_string_now():\n",
    "    \"\"\"Return current date and time as a string to create time stamps.\"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa506e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs():\n",
    "    \"\"\"Return list of run folders from MinKNOW data directory sorted by\n",
    "    modification time.\n",
    "    \"\"\"\n",
    "    runs = []\n",
    "    for f in os.listdir(DATA):\n",
    "        if f not in EXCLUDED_FROM_ANALYSIS:\n",
    "            file_path = os.path.join(DATA, f)\n",
    "            mod_time = os.path.getmtime(file_path)\n",
    "            if os.path.isdir(file_path):\n",
    "                runs.append([f, mod_time])\n",
    "    # Sort based on modification date\n",
    "    runs.sort(key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    # Remove date after sorting\n",
    "    return [x[0] for x in runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results():\n",
    "    \"\"\"Return list of all analysis result files in report directory sorted\n",
    "    by modification time.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for f in os.listdir(NANODIP_REPORTS):\n",
    "        for e in RESULT_ENDING.values():\n",
    "            if f.endswith(e):\n",
    "                mod_time = os.path.getmtime(\n",
    "                    os.path.join(NANODIP_REPORTS, f)\n",
    "                )\n",
    "                files.append([f, mod_time])\n",
    "    files.sort(key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    return [f[0] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_by_ending(directory, sample_name, ending):\n",
    "    \"\"\"Returns a list containing all sample output files with a given\n",
    "    ending.\n",
    "    \"\"\"\n",
    "    sample_path = os.path.join(directory, sample_name)\n",
    "    output_files = []\n",
    "    for root, _, files in os.walk(sample_path):\n",
    "        output_files.extend(\n",
    "            [os.path.join(root, f) for f in files if f.endswith(ending)]\n",
    "        )\n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50715cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predominant_barcode(sample_name):\n",
    "    \"\"\"Returns the predominant barcode within all fast5 files.\"\"\"\n",
    "    fast5_files = files_by_ending(DATA, sample_name, ending=\".fast5\")\n",
    "    pass_fast5_files = [f for f in fast5_files if \"_pass_\" in f]\n",
    "    barcode_hits = []\n",
    "    for barcode in BARCODE_NAMES:\n",
    "        barcode_hits.append(\n",
    "            len([f for f in pass_fast5_files if barcode in f])\n",
    "        )\n",
    "    max_barcode_cnt = max(barcode_hits)\n",
    "    if max_barcode_cnt > 1:\n",
    "        predominant = BARCODE_NAMES[\n",
    "            barcode_hits.index(max_barcode_cnt)\n",
    "        ]\n",
    "    else:\n",
    "        predominant = \"undetermined\"\n",
    "    return predominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_annotations():\n",
    "    \"\"\"Return list of all reference annotation files (MS Excel XLSX format).\"\"\"\n",
    "    annotations = []\n",
    "    for r in os.listdir(ANNOTATIONS):\n",
    "        if r.endswith(\".xlsx\"):\n",
    "            annotations.append(r)\n",
    "    return [a.replace(\".xlsx\", \"\") for a in annotations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_path(directory, *args):\n",
    "    \"\"\"Generate composite file-paths of the type\n",
    "        'directory/arg1_arg2_arg3'\n",
    "    \"\"\"\n",
    "    file_name = \"_\".join([str(x) for x in args])\n",
    "    return os.path.join(\n",
    "        directory,\n",
    "        file_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3895bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_colors(names):\n",
    "    \"\"\"Pseudorandom color scheme based on hashed values. Colors\n",
    "    of methylation classes will be fixed to their name.\n",
    "        Args:\n",
    "            names: List of strings.\n",
    "        Returns:\n",
    "            Dictionary of color scheme for all string elements.\n",
    "    \"\"\"\n",
    "    color = {}\n",
    "    for var in set(names):\n",
    "        hash_str = hashlib.md5(bytes(var, \"utf-8\")).digest()\n",
    "        hash1 = int.from_bytes(hash_str[:8], byteorder=\"big\")\n",
    "        hash2 = int.from_bytes(hash_str[8:12], byteorder=\"big\")\n",
    "        hash3 = int.from_bytes(hash_str[12:], byteorder=\"big\")\n",
    "        hue = hash1 % 365\n",
    "        saturation = hash2 % 91 + 10\n",
    "        lightness = hash3 % 41 + 30\n",
    "        # hsl has to be transformed to rgb, since otherwise not all colors\n",
    "        # are displayed correctly, probably due to plotly bug.\n",
    "        rgb_frac = colorsys.hls_to_rgb(hue/364, lightness/100, saturation/100)\n",
    "        rgb = tuple(int(255 * x) for x in rgb_frac)\n",
    "        color[var] = f\"rgb{rgb}\"\n",
    "    return color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab64f4b",
   "metadata": {},
   "source": [
    "\n",
    "## Data\n",
    "\n",
    "Data containers for sample, reference-data and reference-genome/gene\n",
    "data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_reference_data_exists():\n",
    "    \"\"\"Check if the binary form of the reference data has already been\n",
    "    created.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        os.path.exists(REFERENCE_METHYLATION_DATA) and\n",
    "        os.path.exists(REFERENCE_METHYLATION) and\n",
    "        os.path.exists(REFERENCE_CPG_SITES) and\n",
    "        os.path.exists(REFERENCE_SPECIMENS) and\n",
    "        os.path.exists(REFERENCE_METHYLATION_SHAPE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c58e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_reference_data(\n",
    "    input_dir=BETA_VALUES,\n",
    "    output_dir=REFERENCE_METHYLATION_DATA,\n",
    "    cutoff=METHYLATION_CUTOFF,\n",
    "):\n",
    "    \"\"\"Create binary methylation files from raw reference data.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Directory of raw reference data (beta values)\n",
    "            as float array-files.\n",
    "        output_dir: Output directory where binary methylation file\n",
    "            and metadata will be written.\n",
    "        cutoff: Empirical cutoff value for methylated\n",
    "            (round to 1) and unmethylated (round to 0) CpGs.\n",
    "    \"\"\"\n",
    "    print(\"The binary reference data is generated. Takes 5-10 minutes.\")\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    specimens = [f for f in os.listdir(input_dir) if f.endswith(\".bin\")]\n",
    "\n",
    "    # Get shape parameters of output_data\n",
    "    specimen_path0 = os.path.join(input_dir, specimens[0])\n",
    "    with open(specimen_path0, \"r\") as f:\n",
    "        beta_values_0 = np.fromfile(f, dtype=float)\n",
    "    shape = (len(specimens), len(beta_values_0))\n",
    "\n",
    "    methylation_data = np.empty(shape, dtype=bool)\n",
    "    for i, specimen in enumerate(tqdm(specimens, desc=\"Reading reference\")):\n",
    "        specimen_path = os.path.join(input_dir, specimen)\n",
    "        with open(specimen_path, \"rb\") as f:\n",
    "            beta_values = np.fromfile(f, dtype=float)\n",
    "            methylation_data[i] = np.digitize(\n",
    "                beta_values,\n",
    "                bins=[cutoff]\n",
    "            ).astype(bool)\n",
    "\n",
    "    # write methylation data as binary\n",
    "    methylation_file = os.path.join(output_dir, \"methylation.bin\")\n",
    "    methylation_data.tofile(methylation_file)\n",
    "\n",
    "    # write shape parameters\n",
    "    shape_file = os.path.join(output_dir, \"shape.csv\")\n",
    "    with open(shape_file, \"w\") as f:\n",
    "        f.write(\"%s\\n %s\" % shape)\n",
    "\n",
    "    # write reference specimens\n",
    "    specimens_file = os.path.join(output_dir, \"specimens.csv\")\n",
    "    specimen_names = [s[:-len(\"_betas_filtered.bin\")] for s in specimens]\n",
    "    with open(specimens_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(specimen_names))\n",
    "\n",
    "    # write reference cpg sites\n",
    "    index_file = os.path.join(output_dir, \"cpg_sites.csv\")\n",
    "    with open(os.path.join(input_dir, \"index.csv\")) as f:\n",
    "        index = f.read()\n",
    "    with open(index_file, \"w\") as f:\n",
    "        f.write(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9006f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_reference_data_if_needed():\n",
    "    if not binary_reference_data_exists():\n",
    "        make_binary_reference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reference:\n",
    "    \"\"\"Container of reference data and metadata.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        make_binary_reference_data_if_needed()\n",
    "        self.name = name\n",
    "        with open(REFERENCE_CPG_SITES, \"r\") as f:\n",
    "            # Save cpgs as dictionary to allow fast index lookup.\n",
    "            self.cpg_site_to_index = {\n",
    "                cpg:i for i, cpg in enumerate(f.read().splitlines())\n",
    "            }\n",
    "        self.cpg_sites = self.cpg_site_to_index.keys()\n",
    "        self.annotation = self.get_annotation()\n",
    "        with open(REFERENCE_SPECIMENS) as f:\n",
    "            self.all_specimens = f.read().splitlines()\n",
    "        # Only consider specimens with annotation entry and binary file.\n",
    "        annotated_specimens = set(self.annotation[\"id\"]) & set(\n",
    "            self.all_specimens\n",
    "        )\n",
    "        # Save as dictionary to allow fast index lookup.\n",
    "        specimen_to_index = {s:i for i, s in enumerate(self.all_specimens)}\n",
    "        self.specimens_index = [\n",
    "            specimen_to_index[a] for a in annotated_specimens\n",
    "        ]\n",
    "        self.specimens_index.sort()\n",
    "        # Save as dictionary to allow fast methylation class lookup.\n",
    "        specimen_to_mc = {\n",
    "            i:mc for i, mc in zip(\n",
    "                self.annotation.id, self.annotation.methylation_class\n",
    "            )\n",
    "        }\n",
    "        # Annotated specimens sorted by increasing index\n",
    "        self.specimens = [\n",
    "            self.all_specimens[i] for i in self.specimens_index\n",
    "        ]\n",
    "        self.methylation_class = [\n",
    "            specimen_to_mc[s] for s in self.specimens\n",
    "        ]\n",
    "        self.description = Reference.get_description(\n",
    "            self.methylation_class\n",
    "        )\n",
    "\n",
    "    def get_annotation(self):\n",
    "        \"\"\"Reads annotation as csv file from disk, and returns it as\n",
    "        pd.DataFrame. If csv is missing or file not up to date, annotation\n",
    "        is read from original excel file (slow) and csv file is written to\n",
    "        disk.\n",
    "        \"\"\"\n",
    "        path_csv = os.path.join(ANNOTATIONS, self.name + \".csv\")\n",
    "        path_xlsx = os.path.join(ANNOTATIONS, self.name + \".xlsx\")\n",
    "        csv_exists_and_up_to_date = (\n",
    "            os.path.exists(path_csv) and\n",
    "            os.path.getmtime(path_csv) > os.path.getmtime(path_xlsx)\n",
    "        )\n",
    "        if csv_exists_and_up_to_date:\n",
    "            return pd.read_csv(path_csv)\n",
    "        annotation = pd.read_excel(\n",
    "            path_xlsx,\n",
    "            header=None,\n",
    "            names=[\"id\", \"methylation_class\", \"custom_text\"],\n",
    "            engine=\"openpyxl\",\n",
    "        )\n",
    "        annotation.to_csv(path_csv, index=False)\n",
    "        return annotation\n",
    "\n",
    "    def get_description(methylation_classes):\n",
    "        \"\"\"Returns a description of the methylation class using\n",
    "        a heuristic approach.\n",
    "        \"\"\"\n",
    "        abbr_df = pd.read_csv(ANNOTATIONS_ABBREVIATIONS_BASEL)\n",
    "        abbr = {\n",
    "            mc:desc for mc, desc in\n",
    "            zip(abbr_df.MethylClassStr, abbr_df.MethylClassShortDescr)\n",
    "        }\n",
    "        non_trivial_abbr = abbr.copy()\n",
    "        non_trivial_abbr.pop(\"-\")\n",
    "        tcga_df = pd.read_csv(ANNOTATIONS_ABBREVIATIONS_TCGA, delimiter=\"\\t\")\n",
    "        tcga = {r[0]:r[1] for _, r in tcga_df.iterrows()}\n",
    "        def description(mc):\n",
    "            \"\"\"Returns description of methylation class {mc}.\"\"\"\n",
    "            mc = mc.upper()\n",
    "            # Exact match\n",
    "            if mc in abbr:\n",
    "                return abbr[mc]\n",
    "            # Else choose longest substring from Basel-Annotations/TCGA\n",
    "            basel_substring = [a for a in non_trivial_abbr if a in mc]\n",
    "            basel_substring.sort(key=len)\n",
    "            tcga_substring = [a for a in tcga if a in mc]\n",
    "            tcga_substring.sort(key=len)\n",
    "            # Prefer Basel Annotation\n",
    "            if (\n",
    "                basel_substring and (\n",
    "                    not tcga_substring or\n",
    "                    len(basel_substring[-1]) >= len(tcga_substring[-1])\n",
    "                )\n",
    "            ):\n",
    "                return abbr[basel_substring[-1]]\n",
    "            # Else use TCGA Annotation\n",
    "            if tcga_substring:\n",
    "                return tcga[tcga_substring[-1]]\n",
    "            # No proper annotation for \"PITUI\"\n",
    "            if mc == \"PITUI\":\n",
    "                return \"Pituicytoma\"\n",
    "            return \"\"\n",
    "        mc_description = [\n",
    "            description(mc).capitalize() for mc in methylation_classes\n",
    "        ]\n",
    "        return mc_description\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints overview of object for debugging purposes.\"\"\"\n",
    "        lines = [\n",
    "            f\"Reference object:\",\n",
    "            f\"name: '{self.name}'\",\n",
    "            f\"annotation:\\n{self.annotation}\",\n",
    "            f\"cpg_site_to_index:\\n{pd.DataFrame(self.cpg_site_to_index.items())}\",\n",
    "            f\"cpg_sites:\\n{pd.DataFrame(self.cpg_sites)}\",\n",
    "            f\"all_specimens:\\n{pd.DataFrame(self.all_specimens)}\",\n",
    "            f\"specimens :\\n{pd.DataFrame(self.specimens)}\",\n",
    "            f\"specimens_index\\n{pd.DataFrame(self.specimens_index)}\",\n",
    "            f\"methylation_class: {pd.DataFrame(self.methylation_class)}\",\n",
    "            f\"description: {pd.DataFrame(self.description)}\",\n",
    "        ]\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genome:\n",
    "    \"\"\"Data container for reference genome data.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.chrom = pd.read_csv(CHROMOSOMES, delimiter=\"\\t\", index_col=False)\n",
    "        self.chrom[\"offset\"] = [0] + np.cumsum(self.chrom[\"len\"]).tolist()[:-1]\n",
    "        self.chrom[\"center\"] = self.chrom[\"offset\"] + self.chrom[\"len\"]//2\n",
    "        self.chrom[\"centromere_offset\"] = (\n",
    "            self.chrom[\"offset\"]\n",
    "            + (self.chrom[\"centromere_start\"] + self.chrom[\"centromere_end\"])\n",
    "            // 2\n",
    "        )\n",
    "        self.length = (\n",
    "            self.chrom[\"offset\"].iloc[-1] + self.chrom[\"len\"].iloc[-1]\n",
    "        )\n",
    "        if not os.path.exists(GENES):\n",
    "            self.write_genes_csv()\n",
    "        self.genes = pd.read_csv(GENES, delimiter=\"\\t\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Enables looping over chromosomes.\"\"\"\n",
    "        return self.chrom.itertuples()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def write_genes_csv(self):\n",
    "        \"\"\"Write csv gene list with one selected transcript per gene.\"\"\"\n",
    "        genes = pd.read_csv(\n",
    "            GENES_RAW,\n",
    "            delimiter=\"\\t\",\n",
    "            names=[\"seqname\", \"source\", \"feature\", \"start\", \"end\",\n",
    "                   \"score\", \"strand\", \"frame\", \"attribute\"],\n",
    "            usecols=[\"seqname\", \"feature\", \"start\", \"end\", \"attribute\"]\n",
    "        )\n",
    "        genes = genes.loc[\n",
    "            (genes[\"feature\"] == \"transcript\")\n",
    "            & (genes[\"seqname\"].isin(self.chrom.name))\n",
    "        ]\n",
    "        genes[\"name\"] = genes.attribute.apply(\n",
    "            lambda x: re.search('gene_name(.*)\"(.*)\"', x).group(2)\n",
    "        )\n",
    "        genes[\"transcript\"] = genes.attribute.apply(\n",
    "            lambda x: re.search(\n",
    "                'transcript_id(.*)\"(.*)\"(.*)gene_name(.*)', x\n",
    "                ).group(2)\n",
    "        )\n",
    "        genes = genes.drop_duplicates(subset=[\"name\", \"seqname\"], keep=\"first\")\n",
    "        genes = genes.sort_values(\"name\")\n",
    "        genes[\"loc\"] = genes.apply(\n",
    "            lambda z: (\n",
    "                  z[\"seqname\"]\n",
    "                + \":\"\n",
    "                + \"{:,}\".format(z[\"start\"])\n",
    "                + \"-\"\n",
    "                + \"{:,}\".format(z[\"end\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        # Make data compatible with pythonic notation\n",
    "        genes[\"end\"] += 1\n",
    "        offset = {i.name:i.offset for i in self}\n",
    "        genes[\"start\"] = genes.apply(\n",
    "            lambda z: offset[z[\"seqname\"]] + z[\"start\"],\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"end\"] = genes.apply(\n",
    "            lambda z: offset[z[\"seqname\"]] + z[\"end\"],\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"midpoint\"] = (genes[\"start\"] + genes[\"end\"]) // 2\n",
    "        with open(RELEVANT_GENES, \"r\") as f:\n",
    "            relevant_genes = f.read().splitlines()\n",
    "        genes[\"relevant\"] = genes.name.apply(lambda x: x in relevant_genes)\n",
    "        genes[\"len\"] = genes[\"end\"] - genes[\"start\"]\n",
    "        genes[[\"name\", \"seqname\", \"start\", \"end\",\n",
    "               \"len\", \"midpoint\", \"relevant\", \"transcript\",\n",
    "               \"loc\",\n",
    "        ]].to_csv(GENES, index=False, sep=\"\\t\")\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints overview of object for debugging purposes.\"\"\"\n",
    "        lines = [\n",
    "            \"Genome object:\",\n",
    "            f\"length: {self.length}\",\n",
    "            f\"chrom:\\n{self.chrom}\",\n",
    "            f\"genes:\\n{self.genes}\",\n",
    "        ]\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpg_methyl_from_reads(sample_name):\n",
    "    \"\"\"Returns all Illumina methylation CpG-sites with methylation\n",
    "    status extracted so far.\n",
    "\n",
    "    Args:\n",
    "        sample_name: sample name to be analysed\n",
    "\n",
    "    Returns:\n",
    "        Pandas Data Frame containing the reads Illumina cpg_sites and\n",
    "        methylation status.\n",
    "    \"\"\"\n",
    "\n",
    "    cpg_files = files_by_ending(NANODIP_OUTPUT, sample_name,\n",
    "                                ending=\"methoverlap.tsv\")\n",
    "    methylation_info = pd.DataFrame(columns=[\"cpg_site\", \"methylation\"])\n",
    "    for f in cpg_files:\n",
    "        # Some fast5 files do not contain any CpGs.\n",
    "        try:\n",
    "            cpgs = pd.read_csv(f, delimiter=\"\\t\", header=None,\n",
    "                                names=[\"cpg_site\", \"methylation\"])\n",
    "            methylation_info = methylation_info.append(cpgs)\n",
    "        except FileNotFoundError:\n",
    "            logger.exception(\"Empty file encountered, skipping\")\n",
    "    return methylation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    \"\"\"Container of sample data.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.methyl_df = cpg_methyl_from_reads(name)\n",
    "        self.cpg_overlap = set()\n",
    "        self.cpg_overlap_index = None\n",
    "        self.reads = None\n",
    "\n",
    "    def set_reads(self):\n",
    "        \"\"\"Calculate all read start and end positions and save data\n",
    "        as list to self.reads.\n",
    "        \"\"\"\n",
    "        genome = Genome()\n",
    "        bam_files = files_by_ending(NANODIP_OUTPUT, self.name, ending=\".bam\")\n",
    "        read_positions = []\n",
    "        for f in bam_files:\n",
    "            samfile = pysam.AlignmentFile(f, \"rb\")\n",
    "            for chrom in genome:\n",
    "                for read in samfile.fetch(chrom.name):\n",
    "                    read_positions.append([\n",
    "                        read.reference_start + chrom.offset,\n",
    "                        # reference_end equals first position after alignment\n",
    "                        # consistent with python notations.\n",
    "                        read.reference_end + chrom.offset,\n",
    "                    ])\n",
    "                    assert (read.reference_length != 0), \"Empty read\"\n",
    "        self.reads = read_positions\n",
    "\n",
    "    def set_cpg_overlap(self, reference):\n",
    "        \"\"\"Sets CpG overlap and cpg-site-index between sample\n",
    "        and reference.\n",
    "\n",
    "        This is necessary since some probes have been skipped from the\n",
    "        reference set, e.g. sex chromosomes.\n",
    "        \"\"\"\n",
    "        self.cpg_overlap = set(self.methyl_df[\"cpg_site\"]).intersection(\n",
    "            reference.cpg_sites)\n",
    "        self.cpg_overlap_index = [\n",
    "            reference.cpg_site_to_index[f] for f in self.cpg_overlap\n",
    "        ]\n",
    "        self.cpg_overlap_index.sort()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Prints overview of object for debugging purposes.\"\"\"\n",
    "        lines = [\n",
    "            f\"Sample object:\",\n",
    "            f\"name: '{self.name}':\",\n",
    "            f\"methyl_df: {self.methyl_df}\",\n",
    "            f\"cpg_overlap: {pd.DataFrame(self.cpg_overlap)}\",\n",
    "            f\"cpg_overlap_index: {pd.DataFrame(self.cpg_overlap_index)}\",\n",
    "            f\"reads: {pd.DataFrame(self.reads)}\",\n",
    "        ]\n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44faacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_methylation_from_index(reference_index, cpg_index):\n",
    "    \"\"\"Extract and return (reference-specimen x CpG-site) methylation\n",
    "    submatrix from reference data.\n",
    "\n",
    "    Args:\n",
    "        reference_index: Indices of references to extract from reference\n",
    "            data.\n",
    "        cpg_index: Indices of Illumina CpG's to extract data.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array matrix containing submatrix of reference methylation\n",
    "        with rows=reference_index and columns=cpg_index.\n",
    "    \"\"\"\n",
    "    make_binary_reference_data_if_needed()\n",
    "    shape = [len(reference_index), len(cpg_index)]\n",
    "    delta_offset = np.diff(reference_index, prepend=-1) - 1\n",
    "    reference_submatrix = np.empty(shape, dtype=bool)\n",
    "    with open(REFERENCE_METHYLATION_SHAPE, \"r\") as f:\n",
    "        number_of_cpgs = [int(s) for s in f.read().splitlines()][1]\n",
    "    with open(REFERENCE_METHYLATION, \"rb\") as f:\n",
    "        for i, d in enumerate(delta_offset):\n",
    "            reference_submatrix[i] = np.fromfile(\n",
    "                f, dtype=bool, offset=d*number_of_cpgs, count=number_of_cpgs\n",
    "            )[cpg_index]\n",
    "    return reference_submatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_methylation(sample, reference):\n",
    "    \"\"\"Extract and return (reference-specimen x CpG-site) methylation\n",
    "    matrix from overlap of sample CpG's with annotated reference data.\n",
    "    \"\"\"\n",
    "    if not sample.cpg_overlap:\n",
    "        raise ValueError(\"CpG overlap is empty\")\n",
    "    reference_index = reference.specimens_index\n",
    "    cpg_index = sample.cpg_overlap_index\n",
    "    return reference_methylation_from_index(reference_index, cpg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b6f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_methylation(sample, reference):\n",
    "    \"\"\"Calculate and return sample methylation from reads.\n",
    "\n",
    "    Args:\n",
    "        sample: Sample to be analysed.\n",
    "        reference: Reference used to determine CpG overlap with sample.\n",
    "    Returns:\n",
    "        Numpy array containing sample methylation on CpG overlap\n",
    "            sites.\n",
    "    \"\"\"\n",
    "    if not sample.cpg_overlap:\n",
    "        raise ValueError(\"CpG overlap is empty\")\n",
    "    sample_methylation = np.full(\n",
    "        len(reference.cpg_sites), 0, dtype=bool\n",
    "    )\n",
    "    sample_mean_methylation = sample.methyl_df.groupby(\n",
    "        \"cpg_site\",\n",
    "        as_index=False).mean()\n",
    "\n",
    "    for _, row in sample_mean_methylation.iterrows():\n",
    "        cpg = row[\"cpg_site\"]\n",
    "        if cpg in sample.cpg_overlap:\n",
    "            i = reference.cpg_site_to_index[cpg]\n",
    "            sample_methylation[i] = row[\"methylation\"] > METHYLATION_CUTOFF\n",
    "    return sample_methylation[sample.cpg_overlap_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25683f2",
   "metadata": {},
   "source": [
    "\n",
    "## Plots\n",
    "\n",
    "Functions for creating Copy Number Variation plot.\n",
    "Functions for creating methylation UMAP plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8139d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ad056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_edges(n_bins, genome):\n",
    "    \"\"\"Returns sequence of {n_bins} equal sized bins on chromosomes used\n",
    "    by numpy histogram. Every bin is limited to one chromosome.\n",
    "    \"\"\"\n",
    "    edges = np.linspace(0, len(genome), num=n_bins + 1).astype(int)\n",
    "    # limit bins to only one chromosome\n",
    "    for chrom_edge in genome.chrom.offset:\n",
    "        i_nearest = np.abs(edges - chrom_edge).argmin()\n",
    "        edges[i_nearest] = chrom_edge\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c10090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnv(read_positions, genome):\n",
    "    \"\"\"Return CNV.\n",
    "    Args:\n",
    "        read_positions: List of reads in the form [start, end].\n",
    "        genome: Reference genome.\n",
    "    Returns:\n",
    "        bin_midpoints: x-values\n",
    "        copy_numbers: y-values\n",
    "    \"\"\"\n",
    "    expected_reads_per_bin = 30\n",
    "    n_bins = len(read_positions)//expected_reads_per_bin\n",
    "    read_start_positions = [i[0] for i in read_positions]\n",
    "    copy_numbers, bin_edges = np.histogram(\n",
    "        read_start_positions,\n",
    "        bins=get_bin_edges(n_bins, genome),\n",
    "        range=[0, len(genome)],\n",
    "    )\n",
    "    bin_midpoints = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    return bin_midpoints, copy_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnv_grid(genome):\n",
    "    \"\"\"Returns chromosome grid layout for CNV Plot as plotly object and\n",
    "    saves it on disk. If available grid is directly read from disk.\n",
    "    \"\"\"\n",
    "    # Check if grid exists and return if available.\n",
    "    if os.path.exists(CNV_GRID):\n",
    "        with open(CNV_GRID, \"r\") as f:\n",
    "            grid = from_json(f.read())\n",
    "        return grid\n",
    "\n",
    "    grid = go.Figure()\n",
    "    grid.update_layout(\n",
    "        coloraxis_showscale=False,\n",
    "        xaxis = dict(\n",
    "            linecolor=\"black\",\n",
    "            linewidth=1,\n",
    "            mirror=True,\n",
    "            range=[0, len(genome)],\n",
    "            showgrid=False,\n",
    "            ticklen=10,\n",
    "            tickmode=\"array\",\n",
    "            ticks=\"outside\",\n",
    "            tickson=\"boundaries\",\n",
    "            ticktext=genome.chrom.name,\n",
    "            tickvals=genome.chrom.center,\n",
    "            zeroline=False,\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            linecolor=\"black\",\n",
    "            linewidth=1,\n",
    "            mirror=True,\n",
    "            showline=True,\n",
    "        ),\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "    # Vertical line: centromere.\n",
    "    for i in genome.chrom.centromere_offset:\n",
    "        grid.add_vline(x=i, line_color=\"black\", line_dash=\"dot\", line_width=1)\n",
    "    # Vertical line: chromosomes.\n",
    "    for i in genome.chrom.offset.tolist() + [len(genome)]:\n",
    "        grid.add_vline(x=i, line_color=\"black\", line_width=1)\n",
    "    # Save to disk\n",
    "    grid.write_json(CNV_GRID)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnv_plot_from_data(data_x, data_y, expt_y, sample_name, read_num, genome):\n",
    "    \"\"\"Create CNV plot from CNV data.\n",
    "\n",
    "    Args:\n",
    "        data_x: x-Values to plot.\n",
    "        data_y: y-Values to plot.\n",
    "        expt_y: expected y-Value.\n",
    "        sample_name: Name of sample.\n",
    "        read_num: Number of read reads.\n",
    "        genome: Reference Genome.\n",
    "    \"\"\"\n",
    "    grid = cnv_grid(genome)\n",
    "    # Expected value: draw horizontal line.\n",
    "    grid.add_hline(y=expt_y, line_color=\"black\", line_width=1)\n",
    "    plot = px.scatter(\n",
    "        x=data_x,\n",
    "        y=data_y,\n",
    "        labels={\n",
    "            \"x\":f\"Number of mapped reads: {read_num}\",\n",
    "            \"y\":f\"Copy numbers per {round(len(genome)/(len(data_x)*1e6), 2)} MB\"\n",
    "        },\n",
    "        title=f\"Sample ID: {sample_name}\",\n",
    "        color=data_y,\n",
    "        range_color=[expt_y*0, expt_y*2],\n",
    "        color_continuous_scale=\"Portland\",\n",
    "        render_mode=PLOTLY_RENDER_MODE,\n",
    "    )\n",
    "    plot.update_traces(hovertemplate=\"Copy Numbers = %{y} <br>\")\n",
    "    plot.update_layout(grid.layout, yaxis_range = [-0.5, 2*expt_y])\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2151d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_reads(sorted_read_start_pos, interval):\n",
    "    \"\"\"Return the number of starting sequences within interval. Reads must\n",
    "    be sorted in ascending order.\n",
    "    \"\"\"\n",
    "    left, right = interval\n",
    "    i_left = bisect.bisect_left(sorted_read_start_pos, left)\n",
    "    i_right = bisect.bisect_left(sorted_read_start_pos, right)\n",
    "    return len(sorted_read_start_pos[i_left:i_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnv_plot(sample, bin_midpoints, cnv, genome):\n",
    "    \"\"\"Create a genome-wide copy number plot and save data on dist.\"\"\"\n",
    "    logger.info(\"CNVP start\")\n",
    "    logger.info(sample)\n",
    "    logger.info(\"Bin midpoints:\\n%s\", bin_midpoints)\n",
    "    logger.info(\"CNV:\\n%s\", cnv)\n",
    "\n",
    "    avg_read_per_bin = len(sample.reads) // len(bin_midpoints)\n",
    "\n",
    "    plot = cnv_plot_from_data(\n",
    "        data_x=bin_midpoints,\n",
    "        data_y=cnv,\n",
    "        expt_y = avg_read_per_bin,\n",
    "        sample_name=sample.name,\n",
    "        read_num=len(sample.reads),\n",
    "        genome=genome,\n",
    "    )\n",
    "    logger.info(\"CNVP done\")\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNVData:\n",
    "    \"\"\"CNV data container and methods for invoking CNV plot algorithm.\"\"\"\n",
    "    genome = Genome()\n",
    "    def __init__(self, sample_name):\n",
    "        self.sample = Sample(sample_name)\n",
    "        self.plot = None\n",
    "        self.plot_json = None\n",
    "        self.genes = None\n",
    "        self.relevant_genes = None\n",
    "        self.bin_midpoints = None\n",
    "        self.cnv = None\n",
    "\n",
    "    def path(self, ending):\n",
    "        \"\"\"Returns generic path with corresponding ending.\"\"\"\n",
    "        return composite_path(\n",
    "            NANODIP_REPORTS, self.sample.name, ENDING[ending]\n",
    "        )\n",
    "\n",
    "    def files_on_disk(self):\n",
    "        \"\"\"Checks if files are on disk.\"\"\"\n",
    "        return (\n",
    "            os.path.exists(self.path(\"cnv_json\")) and\n",
    "            os.path.exists(self.path(\"genes\"))\n",
    "        )\n",
    "\n",
    "    def read_from_disk(self):\n",
    "        \"\"\"Reads files from disk.\"\"\"\n",
    "        with open(self.path(\"cnv_json\"), \"r\") as f:\n",
    "            self.plot_json = f.read()\n",
    "        self.plot = from_json(self.plot_json)\n",
    "        self.genes = pd.read_csv(self.path(\"genes\"))\n",
    "\n",
    "    def make_cnv_plot(self):\n",
    "        \"\"\"Generates CNV plot and saves to disk.\"\"\"\n",
    "        self.sample.set_reads() # time consumption 2.5s\n",
    "        self.bin_midpoints, self.cnv = get_cnv(\n",
    "            self.sample.reads,\n",
    "            CNVData.genome,\n",
    "        )\n",
    "        if len(self.bin_midpoints) == 0:\n",
    "            raise ValueError(\"no points to plot\")\n",
    "        self.plot = cnv_plot(\n",
    "            sample=self.sample,\n",
    "            bin_midpoints=self.bin_midpoints,\n",
    "            cnv=self.cnv,\n",
    "            genome=CNVData.genome,\n",
    "        )\n",
    "        self.plot_json = self.plot.to_json()\n",
    "        self.genes = self.gene_cnv()\n",
    "        self.relevant_genes = self.genes.loc[self.genes.relevant]\n",
    "        self.save_to_disk()\n",
    "\n",
    "    def save_to_disk(self):\n",
    "        \"\"\"Saves attributes to disk.\"\"\"\n",
    "        self.plot.write_html(\n",
    "            self.path(\"cnv_html\"),\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "        write_json(self.plot, self.path(\"cnv_json\"))\n",
    "        # time consuming operation (1.96s)\n",
    "        self.plot.write_image(\n",
    "            self.path(\"cnv_png\"), width=1280, height=720, scale=3,\n",
    "        )\n",
    "        with open(self.path(\"aligned_reads\"), \"w\") as f:\n",
    "            f.write(f\"{len(self.sample.reads)}\")\n",
    "        with open(self.path(\"reads_csv\"), \"w\") as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows(self.sample.reads)\n",
    "        self.genes.to_csv(self.path(\"genes\"), index=False)\n",
    "        self.relevant_genes.to_csv(self.path(\"relevant_genes\"), index=False)\n",
    "\n",
    "    def gene_cnv(self):\n",
    "        \"\"\"Returns pandas DataFrame containing copy number variation\n",
    "        for all genes in reference genome.\n",
    "        \"\"\"\n",
    "        genes = CNVData.genome.genes\n",
    "        genes[\"interval\"] = list(zip(genes.start, genes.end))\n",
    "        read_start_pos = [i[0] for i in self.sample.reads]\n",
    "        read_start_pos.sort()\n",
    "        genes[\"cn_obs\"] = genes.interval.apply(\n",
    "            lambda z: number_of_reads(read_start_pos, z)\n",
    "        )\n",
    "        bin_size = len(CNVData.genome)/(len(self.bin_midpoints))\n",
    "        genes[\"cn_per_bin\"] = genes.apply(\n",
    "            lambda z: z[\"cn_obs\"]/z[\"len\"] * bin_size, # TODO auto draw extreme values\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"cn_exp\"] = genes.apply(\n",
    "            lambda z: len(self.sample.reads)*z[\"len\"]/len(CNVData.genome),\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"cn_obs_exp_ratio\"] = genes.apply(\n",
    "            lambda z: z[\"cn_obs\"]/z[\"cn_exp\"],\n",
    "            axis=1,\n",
    "        )\n",
    "        genes = genes.sort_values(by=\"cn_obs\", ascending=False)\n",
    "        return genes\n",
    "\n",
    "    def get_gene_positions(self, genes):\n",
    "        \"\"\"Returns sub-DataFrame containing the genes of the list {genes}.\n",
    "        \"\"\"\n",
    "        gene_pos = self.genes.loc[self.genes.name.isin(genes)]\n",
    "        return gene_pos\n",
    "\n",
    "    def plot_cnv_and_genes(self, gene_names):\n",
    "        \"\"\"Returns json plot of the CNV plot including the CN of all\n",
    "        genes in the list {gene_names}.\n",
    "        \"\"\"\n",
    "        genes = self.get_gene_positions(gene_names)\n",
    "        plot = go.Figure(self.plot)\n",
    "        plot.add_trace(\n",
    "            go.Scatter(\n",
    "                customdata=genes[[\n",
    "                    \"name\",          # 0\n",
    "                    \"loc\",           # 1\n",
    "                    \"transcript\",    # 2\n",
    "                    \"len\",           # 3\n",
    "                ]],\n",
    "                hovertemplate=(\n",
    "                    \"Copy numbers = %{y} <br>\"\n",
    "                    \"<b> %{customdata[0]} </b> <br>\"\n",
    "                    \"%{customdata[1]} \"\n",
    "                    \"(hg19 %{customdata[2]}) <br>\"\n",
    "                    \"%{customdata[3]} bases <br>\"\n",
    "                ),\n",
    "                name=\"\",\n",
    "                marker_color=\"rgba(0,0,0,1)\",\n",
    "                mode=\"markers+text\",\n",
    "                marker_symbol=\"diamond\",\n",
    "                textfont_color=\"rgba(0,0,0,1)\",\n",
    "                showlegend=False,\n",
    "                text=genes.name,\n",
    "                textposition=\"top center\",\n",
    "                x=genes.midpoint,\n",
    "                y=genes.cn_obs,\n",
    "            ))\n",
    "        return plot.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_plot_from_data(sample, reference, umap_df, close_up):\n",
    "    \"\"\"Create and return umap plot from UMAP data.\n",
    "\n",
    "    Args:\n",
    "        sample: Sample data.\n",
    "        reference: Reference data.\n",
    "        umap_df: pandas data frame containing UMAP matrix and\n",
    "            attributes. First row,w corresponds to sample.\n",
    "        close_up: Bool to indicate if only top matches should be plotted.\n",
    "    Returns:\n",
    "        UMAP plot as plotly object.\n",
    "    \"\"\"\n",
    "    umap_sample = umap_df.iloc[0]\n",
    "    umap_title = (\n",
    "        f\"UMAP for {sample.name} <br><sup>Reference: {reference.name} \"\n",
    "        f\"({len(reference.specimens)} cases), \"\n",
    "        f\"{len(sample.cpg_overlap)} CpGs </sup>\"\n",
    "    )\n",
    "    if close_up:\n",
    "        umap_title = \"Close-up \" + umap_title\n",
    "    methyl_classes = umap_df.methylation_class[1:].to_list()\n",
    "    methyl_classes.sort()\n",
    "    umap_plot = px.scatter(\n",
    "        umap_df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        labels={\"x\":\"UMAP 0\", \"y\":\"UMAP 1\", \"methylation_class\":\"WHO class\"},\n",
    "        title=umap_title,\n",
    "        color=\"methylation_class\",\n",
    "        color_discrete_map={\n",
    "            sample.name: \"#ff0000\",\n",
    "            **discrete_colors(methyl_classes),\n",
    "        },\n",
    "        hover_name=\"id\",\n",
    "        category_orders={\"methylation_class\": [sample.name] + methyl_classes},\n",
    "        hover_data=[\"description\"],\n",
    "        render_mode=PLOTLY_RENDER_MODE,\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "    umap_plot.add_annotation(\n",
    "        x=umap_sample[\"x\"],\n",
    "        y=umap_sample[\"y\"],\n",
    "        text=sample.name,\n",
    "        showarrow=True,\n",
    "        arrowhead=1,\n",
    "    )\n",
    "    umap_plot.update_yaxes(\n",
    "        scaleanchor = \"x\",\n",
    "        scaleratio = 1,\n",
    "        mirror=True,\n",
    "    )\n",
    "    umap_plot.update_xaxes(\n",
    "        mirror=True,\n",
    "    )\n",
    "\n",
    "    # If close-up add hyperlinks for all references and draw circle\n",
    "    if close_up:\n",
    "        umap_plot.update_traces(marker=dict(size=5))\n",
    "        # Add hyperlinks\n",
    "        for _, row in umap_df.iloc[1:].iterrows():\n",
    "            url = CNV_LINK % row[\"id\"]\n",
    "            umap_plot.add_annotation(\n",
    "                x=row[\"x\"],\n",
    "                y=row[\"y\"],\n",
    "                text=f\"<a href='{url}' target='_blank'>&nbsp;</a>\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1,\n",
    "            )\n",
    "        # Draw circle\n",
    "        radius = umap_df[\"distance\"].iloc[-1]\n",
    "        umap_plot.add_shape(\n",
    "            type=\"circle\",\n",
    "            x0=umap_sample[\"x\"] - radius,\n",
    "            y0=umap_sample[\"y\"] - radius,\n",
    "            x1=umap_sample[\"x\"] + radius,\n",
    "            y1=umap_sample[\"y\"] + radius,\n",
    "            fillcolor=\"rgba(0,0,0,0)\",\n",
    "            line_color=\"black\",\n",
    "            line_width=1.0,\n",
    "        )\n",
    "    return umap_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_reduction(sample, reference):\n",
    "    \"\"\"Performs UMAP 2d-dimension reduction.\n",
    "\n",
    "    Args:\n",
    "        sample: Sample to analyse.\n",
    "        reference: Reference data which are compared with sample.\n",
    "    Returns:\n",
    "        methyl_overlap: Methlation matrix with rows corresponding to sample\n",
    "            (first row) and reference specimens (remaining rows) and columns\n",
    "            corresponding to CpGs present both in the reference specimens\n",
    "            and the sample data set.\n",
    "        umap_df: UMAP DataFrame corresponding to dimension reduction of\n",
    "            methyl_overlap.\n",
    "    \"\"\"\n",
    "    import umap #Moved here due to long loading time (13.5s)\n",
    "\n",
    "    logger.info(\"Start UMAP for %s / %s.\", sample.name, reference.name)\n",
    "    logger.info(reference)\n",
    "\n",
    "    # Calculate overlap of sample CpG's with reference CpG's (some probes\n",
    "    # have been skipped from the reference set, e.g. sex chromosomes).\n",
    "    sample.set_cpg_overlap(reference)\n",
    "    logger.info(sample)\n",
    "\n",
    "    if not sample.cpg_overlap:\n",
    "        logger.info(\"UMAP done. No Matrix created, no overlapping data.\")\n",
    "        raise ValueError(\"Sample has no overlapping CpG's with reference.\")\n",
    "\n",
    "    # Extract reference and sample methylation according to CpG overlap.\n",
    "    reference_methylation = get_reference_methylation(sample, reference)\n",
    "    logger.info(\"Reference methylation extracted:\\n%s\", reference_methylation)\n",
    "    sample_methylation = get_sample_methylation(sample, reference)\n",
    "    logger.info(\"Sample methylation extracted:\\n%s\", sample_methylation)\n",
    "\n",
    "    # Calculate UMAP Nx2 Matrix. Time intensive (~1min).\n",
    "    methyl_overlap = np.vstack([sample_methylation, reference_methylation])\n",
    "    logger.info(\"UMAP algorithm initiated.\")\n",
    "    umap_2d = umap.UMAP(verbose=True).fit_transform(methyl_overlap)\n",
    "    logger.info(\"UMAP algorithm done.\")\n",
    "\n",
    "    # Free memory\n",
    "    del reference_methylation\n",
    "    del sample_methylation\n",
    "\n",
    "    umap_sample = umap_2d[0]\n",
    "    umap_df = pd.DataFrame({\n",
    "        \"distance\": [np.linalg.norm(z - umap_sample) for z in umap_2d],\n",
    "        \"methylation_class\": [sample.name] + reference.methylation_class,\n",
    "        \"description\":  [\"Analysis sample\"] + reference.description,\n",
    "        \"id\": [sample.name] + reference.specimens,\n",
    "        \"x\": umap_2d[:,0],\n",
    "        \"y\": umap_2d[:,1],\n",
    "    })\n",
    "\n",
    "    logger.info(\"UMAP done. Matrix created.\")\n",
    "    return (methyl_overlap, umap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e692589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_chart(umap_data):\n",
    "    \"\"\"Returns plotly pie chart of the methylation classes of the nearest UMAP\n",
    "    neighbors (according to euclidean 2d-distance) of the sample.\n",
    "    \"\"\"\n",
    "    umap_neighbors = umap_data.umap_df.sort_values(by=\"distance\")[\n",
    "        1 : UMAP_PLOT_TOP_MATCHES + 1\n",
    "    ]\n",
    "\n",
    "    num_per_class = (\n",
    "        umap_neighbors.groupby([\"methylation_class\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"counts\")\n",
    "    )\n",
    "    sample = umap_data.sample\n",
    "    reference = umap_data.reference\n",
    "    plot = px.pie(\n",
    "        num_per_class,\n",
    "        values=\"counts\",\n",
    "        names=\"methylation_class\",\n",
    "        color=\"methylation_class\",\n",
    "        color_discrete_map=discrete_colors(num_per_class.methylation_class),\n",
    "        title=(\n",
    "            f\"Nearest UMAP neighbors for {umap_data.sample.name} <br><sup>\"\n",
    "            f\"Reference: {reference.name} \"\n",
    "            f\"({len(reference.specimens)}\"\n",
    "            f\"cases), {len(sample.cpg_overlap)} CpGs</sup>\"\n",
    "        ),\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219234d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMAPData:\n",
    "    \"\"\"UMAP data container and methods for invoking UMAP plot algorithm.\"\"\"\n",
    "    def __init__(self, sample_name, reference_name):\n",
    "        self.sample = Sample(sample_name)\n",
    "        self.reference = Reference(reference_name)\n",
    "        self.methyl_overlap = None\n",
    "        self.umap_df = None\n",
    "        self.cu_umap_df = None\n",
    "        self.plot = None\n",
    "        self.plot_json = None\n",
    "        self.cu_plot = None\n",
    "        self.cu_plot_json = None\n",
    "        self.pie_chart = None\n",
    "\n",
    "    def path(self, ending):\n",
    "        \"\"\"Returns generic path with corresponding ending.\"\"\"\n",
    "        return composite_path(\n",
    "            NANODIP_REPORTS,\n",
    "            self.sample.name, self.reference.name, ENDING[ending],\n",
    "        )\n",
    "\n",
    "    def make_umap_plot(self):\n",
    "        \"\"\"Invoke UMAP plot algorithm and save files to disk.\"\"\"\n",
    "        self.methyl_overlap, self.umap_df = dimension_reduction(\n",
    "            self.sample, self.reference\n",
    "        )\n",
    "        self.draw_scatter_plots()\n",
    "        self.draw_pie_chart()\n",
    "        self.save_to_disk()\n",
    "\n",
    "    def draw_pie_chart(self):\n",
    "        \"\"\"Draw pie chart of nearest UMAP neighbors.\"\"\"\n",
    "        self.pie_chart = pie_chart(self)\n",
    "\n",
    "    def draw_scatter_plots(self):\n",
    "        \"\"\"Draws UMAP scatter plot with close-up plot from data.\"\"\"\n",
    "        self.plot = umap_plot_from_data(\n",
    "            self.sample,\n",
    "            self.reference,\n",
    "            self.umap_df,\n",
    "            close_up=False,\n",
    "        )\n",
    "        logger.info(\"UMAP plot generated.\")\n",
    "        self.cu_umap_df = self.umap_df.sort_values(\n",
    "            by=\"distance\"\n",
    "        )[:UMAP_PLOT_TOP_MATCHES + 1]\n",
    "        self.cu_plot = umap_plot_from_data(\n",
    "            self.sample,\n",
    "            self.reference,\n",
    "            self.cu_umap_df,\n",
    "            close_up=True,\n",
    "        )\n",
    "        logger.info(\"UMAP close-up plot generated.\")\n",
    "\n",
    "        # Convert to json.\n",
    "        self.plot_json = self.plot.to_json()\n",
    "        self.cu_plot_json = self.cu_plot.to_json()\n",
    "\n",
    "    def save_to_disk(self):\n",
    "        \"\"\"Saves attributes to disk.\"\"\"\n",
    "        # Save methylation matrix.\n",
    "        np.save(self.path(\"methyl\"), self.methyl_overlap)\n",
    "\n",
    "        # Save UMAP Matrix.\n",
    "        self.umap_df.to_csv(self.path(\"umap_csv\"), index=False)\n",
    "\n",
    "        # Write UMAP plot to disk.\n",
    "        file_path = self.path(\"umap_all\")\n",
    "        self.plot.write_html(file_path, config=dict({\"scrollZoom\": True}))\n",
    "        self.plot.write_json(file_path[:-4] + \"json\")\n",
    "        self.plot.write_image(file_path[:-4] + \"png\") # Time consumption 1.8s\n",
    "\n",
    "        # Write UMAP close-up plot to disk.\n",
    "        file_path = self.path(\"umap_top\")\n",
    "        self.cu_plot.write_html(file_path, config=dict({\"scrollZoom\": True}))\n",
    "        self.cu_plot.write_json(file_path[:-4] + \"json\")\n",
    "        self.cu_plot.write_image(\n",
    "            file_path[:-4] + \"png\", width=450, height=400, scale=3\n",
    "        )   # Time consumption 0.9s\n",
    "\n",
    "        # Write pie chart to disk.\n",
    "        self.pie_chart.write_image(\n",
    "            self.path(\"pie\"), width=450, height=400, scale=3\n",
    "        )\n",
    "\n",
    "        # Save close up ranking report.\n",
    "        self.save_ranking_report() # Time consumption 0.4s\n",
    "\n",
    "    def save_ranking_report(self):\n",
    "        \"\"\"Save pdf containing the nearest neighbours from umap analyis.\"\"\"\n",
    "        rows = [row for _, row in self.cu_umap_df.iterrows()]\n",
    "        html_report = render_template(\"umap_report.html\", rows=rows)\n",
    "        convert_html_to_pdf(html_report, self.path(\"ranking\"))\n",
    "        with open(self.path(\"cpg_cnt\"), \"w\") as f:\n",
    "            f.write(f\"{len(self.sample.cpg_overlap)}\")\n",
    "\n",
    "    def files_on_disk(self):\n",
    "        \"\"\"Check if files are on disk.\"\"\"\n",
    "        return (\n",
    "            os.path.exists(self.path(\"methyl\")) and\n",
    "            os.path.exists(self.path(\"umap_all_json\")) and\n",
    "            os.path.exists(self.path(\"umap_top_json\")) and\n",
    "            os.path.exists(self.path(\"umap_csv\"))\n",
    "        )\n",
    "\n",
    "    def read_from_disk(self):\n",
    "        \"\"\"Read plot data from disk.\"\"\"\n",
    "        # Read UMAP plot as json.\n",
    "        with open(self.path(\"umap_all_json\"), \"r\") as f:\n",
    "            self.plot_json = f.read()\n",
    "\n",
    "        # Read UMAP close-up plot as json.\n",
    "        with open(self.path(\"umap_top_json\"), \"r\") as f:\n",
    "            self.cu_plot_json = f.read()\n",
    "\n",
    "        # Read Methylation Matrix.\n",
    "        self.methyl_overlap = np.load(self.path(\"methyl\"), allow_pickle=True)\n",
    "\n",
    "        # Read UMAP Matrix.\n",
    "        self.umap_df = pd.read_csv(self.path(\"umap_csv\"))\n",
    "\n",
    "    def read_precalculated_umap_matrix(self, umap_matrix):\n",
    "        \"\"\"Reads precalculated UMAP matrix from disk.\"\"\"\n",
    "        path_xlsx = composite_path(\n",
    "            NANODIP_REPORTS,\n",
    "            self.sample.name,\n",
    "            umap_matrix.replace(\".xlsx\", \"\"),\n",
    "            ENDING[\"umap_xlsx\"],\n",
    "        )\n",
    "        precalculated_umap = pd.read_excel(\n",
    "            path_xlsx,\n",
    "            header=0,\n",
    "            names=[\"id\", \"x\", \"y\"],\n",
    "            engine=\"openpyxl\",\n",
    "        )   # TODO better use csv. Time consumption 4.4s\n",
    "        reference_df = pd.DataFrame(\n",
    "            zip(\n",
    "                self.reference.specimens,\n",
    "                self.reference.methylation_class,\n",
    "                self.reference.description,\n",
    "            ),\n",
    "            columns=[\"id\", \"methylation_class\", \"description\"],\n",
    "        )\n",
    "        if not self.sample.name in reference_df.id.values:\n",
    "            reference_df.loc[len(reference_df.index)] = [\n",
    "                self.sample.name, self.sample.name, \"Analysis Sample\"\n",
    "            ]\n",
    "        self.umap_df = pd.merge(precalculated_umap, reference_df, on = \"id\")\n",
    "        umap_sample = self.umap_df[[\"x\", \"y\"]].loc[\n",
    "            self.umap_df.id==self.sample.name\n",
    "        ].values\n",
    "        self.umap_df[\"distance\"] = [\n",
    "            np.linalg.norm([z.x, z.y] - umap_sample)\n",
    "            for z in self.umap_df.itertuples()\n",
    "        ]\n",
    "        self.umap_df = self.umap_df.sort_values(by=\"distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c757973",
   "metadata": {},
   "source": [
    "\n",
    "### MinKNOW API Functions\n",
    "Check https://github.com/nanoporetech/minknow_api for reference.\n",
    "\n",
    "The following code requires a patched version of the MinKNOW API. Install it\n",
    "from https://github.com/neuropathbasel/minknow_api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4793fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minknow_manager():\n",
    "    \"\"\"Construct a manager using the host and port provided. This is\n",
    "    used to connect to the MinKNOW service trough the MK API.\n",
    "\n",
    "    minknow_api.manager.Manager:  a wrapper around MinKNOW's Manager\n",
    "        gRPC API with utilities for querying sequencing positions and\n",
    "        offline basecalling tools.\n",
    "    \"\"\"\n",
    "    return Manager(host=THIS_HOST, port=9501, use_tls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minion_positions():\n",
    "    \"\"\"Return MinION devices that are currenty connected to the system.\"\"\"\n",
    "    manager = minknow_manager()\n",
    "    # Find a list of currently available sequencing positions.\n",
    "    positions = manager.flow_cell_positions()\n",
    "    # User could call {posisions.connect()} here to connect to the\n",
    "    # running MinKNOW instance.\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_from_device_id(device_id):\n",
    "    \"\"\"Returns minion position.\"\"\"\n",
    "    position = next(\n",
    "        (pos for pos in minion_positions() if pos.name == device_id),\n",
    "        False,\n",
    "    )\n",
    "    if not position:\n",
    "        raise ValueError(f\"'{device_id}' is not a valid Minion position.\")\n",
    "    connection = position.connect()\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_cell_id(device_id):\n",
    "    \"\"\"Return flow cell ID (if any). Note that some CTCs have an\n",
    "    empty ID string.\n",
    "    \"\"\"\n",
    "    cell_id = \"no_flow_cell\"\n",
    "    positions = minion_positions()\n",
    "    for p in positions:\n",
    "        if device_id in p.name:\n",
    "            connection = p.connect()\n",
    "            cell_id = connection.device.get_flow_cell_info().flow_cell_id\n",
    "    return cell_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args_list):\n",
    "    \"\"\"Build and execute a command line argument for starting a protocol.\n",
    "\n",
    "    Returns:\n",
    "        Parsed arguments to be used when starting a protocol.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\"\"\n",
    "        Run a sequencing protocol in a running MinKNOW instance.\n",
    "        \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--host\",\n",
    "        default=\"localhost\",\n",
    "        help=\"IP address of the machine running MinKNOW (defaults to localhost)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--port\",\n",
    "        help=\"Port to connect to on host (defaults to standard MinKNOW port based on tls setting)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-tls\",\n",
    "        help=\"Disable tls connection\",\n",
    "        default=False,\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Enable debug logging\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sample-id\",\n",
    "        help=\"sample ID to set\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--experiment-group\",\n",
    "        \"--group-id\",\n",
    "        help=\"experiment group (aka protocol group ID) to set\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--position\",\n",
    "        help=\"position on the machine (or MinION serial number) to run the protocol at\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--flow-cell-id\",\n",
    "        metavar=\"FLOW-CELL-ID\",\n",
    "        help=\"ID of the flow-cell on which to run the protocol. (specify this or --position)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kit\",\n",
    "        required=True,\n",
    "        help=\"Sequencing kit used with the flow-cell, eg: SQK-LSK108\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--product-code\",\n",
    "        help=\"Override the product-code stored on the flow-cell and previously user-specified\"\n",
    "        \"product-codes\",\n",
    "    )\n",
    "    # Basecalling arguments\n",
    "    parser.add_argument(\n",
    "        \"--basecalling\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enable base-calling using the default base-calling model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--basecall-config\",\n",
    "        help=\"specify the base-calling config and enable base-calling\",\n",
    "    )\n",
    "    # Barcoding arguments\n",
    "    parser.add_argument(\n",
    "        \"--barcoding\",\n",
    "        action=\"store_true\",\n",
    "        help=\"protocol uses barcoding\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcode-kits\",\n",
    "        nargs=\"+\",\n",
    "        help=\"bar-coding expansion kits used in the experiment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--trim-barcodes\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enable bar-code trimming\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcodes-both-ends\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering (both ends of a strand must have a matching barcode)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--detect-mid-strand-barcodes\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering for bar-codes in the middle of a strand\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score-rear\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score-mid\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    # Alignment arguments\n",
    "    parser.add_argument(\n",
    "        \"--alignment-reference\",\n",
    "        help=\"Specify alignment reference to send to basecaller for live alignment.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bed-file\",\n",
    "        help=\"Specify bed file to send to basecaller.\",\n",
    "    )\n",
    "    # Output arguments\n",
    "    parser.add_argument(\n",
    "        \"--fastq\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables FastQ file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fastq-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one FastQ file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables Fast5 file output, defaulting to 4000 reads per file, this will store raw, \"\n",
    "        \"fastq and trace-table data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one Fast5 file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables BAM file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one BAM file.\",\n",
    "    )\n",
    "    # Read until arguments\n",
    "    parser.add_argument(\n",
    "        \"--read-until-reference\",\n",
    "        type=str,\n",
    "        help=\"Reference file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-bed-file\",\n",
    "        type=str,\n",
    "        help=\"Bed file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-filter\",\n",
    "        type=str,\n",
    "        choices=[\"deplete\", \"enrich\"],\n",
    "        help=\"Filter type to use in read until\",\n",
    "    )\n",
    "    # Experiment arguments\n",
    "    parser.add_argument(\n",
    "        \"--experiment-duration\",\n",
    "        type=float,\n",
    "        default=72,\n",
    "        help=\"time spent sequencing (in hours)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-active-channel-selection\",\n",
    "        action=\"store_true\",\n",
    "        help=\"allow dynamic selection of channels to select pores for sequencing, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mux-scan-period\",\n",
    "        type=float,\n",
    "        default=1.5,\n",
    "        help=\"number of hours before a mux scan takes place, enables active-channel-selection, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"extra_args\",\n",
    "        metavar=\"ARGS\",\n",
    "        nargs=\"*\",\n",
    "        help=\"Additional arguments passed verbatim to the protocol script\",\n",
    "    )\n",
    "    args = parser.parse_args(args_list)\n",
    "    # Further argument checks\n",
    "    # 'Read until' must have a reference and a filter type, if enabled:\n",
    "    if (\n",
    "        args.read_until_filter is not None\n",
    "        or args.read_until_reference is not None\n",
    "        or args.read_until_bed_file is not None\n",
    "    ):\n",
    "        if args.read_until_filter is None:\n",
    "            print(\"Unable to specify read until arguments without a filter type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if args.read_until_reference is None:\n",
    "            print(\"Unable to specify read until arguments without a reference type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    if args.bed_file and not args.alignment_reference:\n",
    "        print(\"Unable to specify '--bed-file' without '--alignment-reference'.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if (args.barcoding or args.barcode_kits) and not (\n",
    "        args.basecalling or args.basecall_config\n",
    "    ):\n",
    "        print(\n",
    "            \"Unable to specify '--barcoding' or '--barcode-kits' without '--basecalling'.\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "    if args.alignment_reference and not (args.basecalling or args.basecall_config):\n",
    "        print(\"Unable to specify '--alignment-reference' without '--basecalling'.\")\n",
    "        sys.exit(1)\n",
    "    if not (args.fast5 or args.fastq):\n",
    "        print(\"No output (fast5 or fastq) specified\")\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_run(\n",
    "    device_id=\"\",\n",
    "    sample_id=\"\",\n",
    "    run_duration=\"\",\n",
    "    start_voltage=\"\",\n",
    "):\n",
    "    \"\"\"Start a run on Mk1b devices and perform several checks concerning\n",
    "    the run protocol.\n",
    "\n",
    "    Code modified from the MinKNOW API on\n",
    "    https://github.com/nanoporetech/minknow_api\n",
    "    (2022-03) created from the sample code at\n",
    "    https://github.com/nanoporetech/minknow_api/blob/master/python/minknow_api/examples/start_protocol.py\n",
    "\n",
    "    We need 'find_protocol' to search for the required protocol given a kit\n",
    "    and product code.\n",
    "    \"\"\"\n",
    "    args_list = [\n",
    "        \"--host\", \"localhost\",\n",
    "        \"--position\", device_id,\n",
    "        \"--sample-id\", sample_id,\n",
    "        \"--experiment-group\", sample_id,\n",
    "        \"--experiment-duration\", run_duration,\n",
    "        \"--basecalling\",\n",
    "        \"--fastq\",\n",
    "        \"--fastq-reads-per-file\", READS_PER_FILE,\n",
    "        \"--fast5\",\n",
    "        \"--fast5-reads-per-file\", READS_PER_FILE,\n",
    "        \"--verbose\",\n",
    "        \"--kit\", \"SQK-RBK004\",\n",
    "        \"--barcoding\",\n",
    "        \"--barcode-kits\", \"SQK-RBK004\",\n",
    "        \"--\",  # Required for so-called extra-arguments.\n",
    "        \"--start_bias_voltage\", start_voltage,\n",
    "    ]\n",
    "\n",
    "    # Parse arguments to be passed to started protocols:\n",
    "    args = parse_args(args_list)\n",
    "\n",
    "    # # Specify --verbose on the command line to get extra details.\n",
    "    # if args.verbose:\n",
    "        # logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "    # Find which positions we are going to start protocol on:\n",
    "    positions = [\n",
    "        pos for pos in minion_positions() if is_position_selected(pos, args)\n",
    "    ]\n",
    "\n",
    "    # At least one position needs to be selected:\n",
    "    if not positions:\n",
    "        print(\n",
    "            \"No positions selected for protocol - specify \"\n",
    "            \"'--position' or '--flow-cell-id'\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "    # Start protocol on the requested postitions:\n",
    "    print(\"Starting protocol on %s positions.\" % len(positions))\n",
    "    run_ids = []\n",
    "\n",
    "    for pos in positions:\n",
    "        # Connect to the sequencing position:\n",
    "        connection = pos.connect()\n",
    "\n",
    "        # Check if a flowcell is available for sequencing\n",
    "        flow_cell_info = connection.device.get_flow_cell_info()\n",
    "        if not flow_cell_info.has_flow_cell:\n",
    "            print(f\"No flow cell present in position {pos}\")\n",
    "            return []\n",
    "\n",
    "        # Select product code:\n",
    "        if args.product_code:\n",
    "            product_code = args.product_code\n",
    "        else:\n",
    "            product_code = flow_cell_info.user_specified_product_code\n",
    "            if not product_code:\n",
    "                product_code = flow_cell_info.product_code\n",
    "\n",
    "        # Find the protocol identifier for the required protocol:\n",
    "        protocol_info = protocols.find_protocol(\n",
    "            connection,\n",
    "            product_code=product_code,\n",
    "            kit=args.kit,\n",
    "            basecalling=args.basecalling,\n",
    "            basecall_config=args.basecall_config,\n",
    "            barcoding=args.barcoding,\n",
    "            barcoding_kits=args.barcode_kits,\n",
    "        )\n",
    "\n",
    "        if not protocol_info:\n",
    "            print(\"Failed to find protocol for position %s\" % (pos.name))\n",
    "            print(\"Requested protocol:\")\n",
    "            print(\"  product-code: %s\" % args.product_code)\n",
    "            print(\"  kit: %s\" % args.kit)\n",
    "            print(\"  basecalling: %s\" % args.basecalling)\n",
    "            print(\"  basecall_config: %s\" % args.basecall_config)\n",
    "            print(\"  barcode-kits: %s\" % args.barcode_kits)\n",
    "            print(\"  barcoding: %s\" % args.barcoding)\n",
    "            print(\"Protocol build error, consult application log.\")\n",
    "            return []\n",
    "\n",
    "        # Store the identifier for later:\n",
    "        protocol_id = protocol_info.identifier\n",
    "\n",
    "        # Now select which arguments to pass to start protocol:\n",
    "        print(\"Starting protocol %s on position %s\" % (protocol_id, pos.name))\n",
    "\n",
    "        # Set up user specified product code if requested:\n",
    "        if args.product_code:\n",
    "            connection.device.set_user_specified_product_code(\n",
    "                code=args.product_code\n",
    "            )\n",
    "\n",
    "        # Build arguments for starting protocol:\n",
    "        basecalling_args = None\n",
    "        if args.basecalling or args.basecall_config:\n",
    "            barcoding_args = None\n",
    "            alignment_args = None\n",
    "            if args.barcode_kits or args.barcoding:\n",
    "                barcoding_args = protocols.BarcodingArgs(\n",
    "                    args.barcode_kits,\n",
    "                    args.trim_barcodes,\n",
    "                    args.barcodes_both_ends,\n",
    "                    args.detect_mid_strand_barcodes,\n",
    "                    args.min_score,\n",
    "                    args.min_score_rear,\n",
    "                    args.min_score_mid,\n",
    "                )\n",
    "\n",
    "            if args.alignment_reference:\n",
    "                alignment_args = protocols.AlignmentArgs(\n",
    "                    reference_files=[args.alignment_reference],\n",
    "                    bed_file=args.bed_file,\n",
    "                )\n",
    "\n",
    "            basecalling_args = protocols.BasecallingArgs(\n",
    "                config=args.basecall_config,\n",
    "                barcoding=barcoding_args,\n",
    "                alignment=alignment_args,\n",
    "            )\n",
    "\n",
    "        read_until_args = None\n",
    "        if args.read_until_filter:\n",
    "            read_until_args = protocols.ReadUntilArgs(\n",
    "                filter_type=args.read_until_filter,\n",
    "                reference_files=[args.read_until_reference],\n",
    "                bed_file=args.read_until_bed_file,\n",
    "                first_channel=None,  # These default to all channels.\n",
    "                last_channel=None,\n",
    "            )\n",
    "\n",
    "        def build_output_arguments(args, name):\n",
    "            if not getattr(args, name):\n",
    "                return None\n",
    "            return protocols.OutputArgs(\n",
    "                reads_per_file=getattr(args, \"%s_reads_per_file\" % name)\n",
    "            )\n",
    "\n",
    "        fastq_arguments = build_output_arguments(args, \"fastq\")\n",
    "        fast5_arguments = build_output_arguments(args, \"fast5\")\n",
    "        bam_arguments = build_output_arguments(args, \"bam\")\n",
    "\n",
    "        # print the protocol parameters\n",
    "        print(\"connection {connection}\")\n",
    "        print(\"protocol_id {protocol_id}\")\n",
    "        print(\"args.sample_id {args.sample_id}\")\n",
    "        print(\"args.experiment_group {args.experiment_group}\")\n",
    "        print(\"basecalling_args {basecalling_args}\")\n",
    "        print(\"read_until_args {read_until_args}\")\n",
    "        print(\n",
    "            \"fastq_arguments {fastq_arguments}\"\n",
    "        )  # fastq_arguments OutputArgs(reads_per_file=400)\n",
    "        print(\n",
    "            \"fast5_arguments {fast5_arguments}\"\n",
    "        )  # fast5_arguments OutputArgs(reads_per_file=400)\n",
    "        print(\"bam_arguments {bam_arguments}\")\n",
    "        print(\n",
    "            \"args.no_active_channel_selection \"\n",
    "            \"{args.no_active_channel_selection}\"\n",
    "        )\n",
    "        print(\"args.mux_scan_period {args.mux_scan_period}\")\n",
    "        print(\"args.experiment_duration {args.experiment_duration}\")\n",
    "        print(\n",
    "            \"args.extra_args {args.extra_args}\"\n",
    "        )  # Any extra args passed.\n",
    "\n",
    "        # Now start the protocol:\n",
    "        run_id = protocols.start_protocol(\n",
    "            connection,\n",
    "            protocol_id,\n",
    "            sample_id=args.sample_id,\n",
    "            experiment_group=args.experiment_group,\n",
    "            basecalling=basecalling_args,\n",
    "            read_until=read_until_args,\n",
    "            fastq_arguments=fastq_arguments,\n",
    "            fast5_arguments=fast5_arguments,\n",
    "            bam_arguments=bam_arguments,\n",
    "            disable_active_channel_selection=args.no_active_channel_selection,\n",
    "            mux_scan_period=args.mux_scan_period,\n",
    "            experiment_duration=args.experiment_duration,\n",
    "            args=args.extra_args,  # Any extra args passed.\n",
    "        )\n",
    "        run_ids.append(run_id)\n",
    "    return run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_run(device_id):\n",
    "    \"\"\"Stop an existing run (if any) for a MinION device and return the\n",
    "    protocol ID.\n",
    "    \"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    protocol = connection.protocol.list_protocol_runs()\n",
    "    protocol_id = protocol.run_ids[-1]\n",
    "    # TODO @HEJU in stopRun wird ber bufferedRunIds geloopt. Notwendig?\n",
    "    try:\n",
    "        connection.protocol.stop_protocol()\n",
    "        return protocol_id\n",
    "    except grpc._channel._InactiveRpcError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f430d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_position_selected(position, args):\n",
    "    \"\"\"Find if the {position} is selected by command line arguments\n",
    "    {args}.\n",
    "    Function from minknow_api demos, start_seq.py\n",
    "    \"\"\"\n",
    "    # First check for name match:\n",
    "    if args.position == position.name:\n",
    "        return True\n",
    "\n",
    "    # Then verify if the flow cell matches:\n",
    "    connected_position = position.connect()\n",
    "    if args.flow_cell_id is not None:\n",
    "        flow_cell_info = connected_position.device.get_flow_cell_info()\n",
    "        if (\n",
    "            flow_cell_info.user_specified_flow_cell_id == args.flow_cell_id\n",
    "            or flow_cell_info.flow_cell_id == args.flow_cell_id\n",
    "        ):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1429c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_run(device_id):\n",
    "    \"\"\"Returns active run id.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    try:\n",
    "        # Error if no acquisition is running, same as with\n",
    "        # acquisitio.current_status(), no acquisition until\n",
    "        # temperature reached\n",
    "        active_run = connection.acquisition.get_current_acquisition_run().run_id\n",
    "    except grpc._channel._InactiveRpcError:\n",
    "        active_run = \"none\"\n",
    "    return active_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_activity(device_id):\n",
    "    \"\"\"Returns device activity. Virtual test runs will be recognized as\n",
    "    active.\n",
    "    \"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    status = connection.acquisition.current_status().status\n",
    "    device_activity = {\n",
    "        STARTING: \"sequencing\",\n",
    "        PROCESSING: \"sequencing\",\n",
    "        FINISHING: \"sequencing\",\n",
    "        READY: \"idle\",\n",
    "    }\n",
    "    return device_activity.get(status, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_device_activity(device_id):\n",
    "    \"\"\"Returns device activity by checking the target temperature.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    target_temp =str(\n",
    "        connection.minion_device.get_settings().temperature_target.min\n",
    "    )\n",
    "    device_activity = {\n",
    "        \"34.0\": \"sequencing\",\n",
    "        \"35.0\": \"idle\",\n",
    "        \"37.0\": \"checking flow cell\",\n",
    "    }\n",
    "    return device_activity.get(target_temp, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279cc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_called_bases(device_id):\n",
    "    \"\"\"Returns number of called bases.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    # Check if device is working.\n",
    "    if connection.acquisition.current_status().status == READY:\n",
    "        return 0\n",
    "    acquisition = connection.acquisition.get_acquisition_info()\n",
    "    num_bases = acquisition.yield_summary.estimated_selected_bases\n",
    "    return num_bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39647b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_status(device_id):\n",
    "    \"\"\"MinKNOW status for device {device_id}.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    current_bases = number_of_called_bases(device_id)\n",
    "    needed_mb = round(NEEDED_NUMBER_OF_BASES // 1e6, 2)\n",
    "    current_mb = round(current_bases / 1e6, 2)\n",
    "    progress = round(100*current_mb/needed_mb, 1)\n",
    "    status = {\n",
    "        \"Real device activity\": real_device_activity(device_id),\n",
    "        \"Active run\": active_run(device_id),\n",
    "        \"Progress\": f\"{progress}% ({current_mb} MB / {needed_mb} MB)\",\n",
    "        \"acquisition.get_acquisition_info().state\": str(\n",
    "            connection.acquisition.get_acquisition_info().state\n",
    "        ),\n",
    "        \"acquisition.current_status()\": str(\n",
    "            connection.acquisition.current_status()\n",
    "        ),\n",
    "        \"minion_device.get_settings().temperature_target.min\": str(\n",
    "            connection.minion_device.get_settings().temperature_target.min\n",
    "        ),\n",
    "        \"device.get_temperature()\": str(\n",
    "            connection.device.get_temperature().minion.heatsink_temperature\n",
    "        ),\n",
    "        \"device.get_bias_voltage()\": str(connection.device.get_bias_voltage()),\n",
    "    }\n",
    "    # Progress is only needed if device is sequencing.\n",
    "    if active_run(device_id) == \"none\":\n",
    "        status.pop(\"Progress\")\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e18225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_state(device_id):\n",
    "    \"\"\"Obtain further information about a particular device / run.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    try:\n",
    "        state = f\"Run state for {device_id}: \"\n",
    "        state += str(connection.protocol.get_current_protocol_run().state)\n",
    "        state += \"/\"\n",
    "        state += str(connection.acquisition.get_acquisition_info().state)\n",
    "    except grpc._channel._InactiveRpcError:\n",
    "        state = f\"No state information in MinKNOW buffer for {device_id}\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e65956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sample_id(device_id):\n",
    "    \"\"\"Get sample ID from MinKNOW by device, only available after data\n",
    "    acquisition has been initiated by MinKNOW.\n",
    "    \"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    try:\n",
    "        sample_id = (\n",
    "            connection.protocol.get_current_protocol_run().user_info.sample_id.value\n",
    "        )\n",
    "    except grpc._channel._InactiveRpcError:\n",
    "        sample_id = (\n",
    "            f\"No sampleId information in MinKNOW buffer for {device_id}\"\n",
    "        )\n",
    "    return sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_yield(device_id):\n",
    "    \"\"\"Get run yield by device. The data of the previous run will remain in\n",
    "    the buffer until acquisition (not just a start) of a new run have been\n",
    "    initiated.\n",
    "    \"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    try:\n",
    "        acq_info = connection.acquisition.get_acquisition_info()\n",
    "        yield_ = f\"Run yield for {device_id} ({acq_info.run_id}):&nbsp;\"\n",
    "        yield_ += str(acq_info.yield_summary)\n",
    "    # TODO this exception has not been tested.\n",
    "    except grpc._channel._InactiveRpcError:\n",
    "        yield_ = f\"No yield information in MinKNOW buffer for {device_id}\"\n",
    "    return yield_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_information(device_id):\n",
    "    \"\"\"Get current run information. Only available after data acquisition\n",
    "    has started.\n",
    "    \"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    try:\n",
    "        info = (f\"Run information for {device_id}<br><br>\"\n",
    "               + str(connection.protocol.get_current_protocol_run()))\n",
    "    except grpc.RpcError:\n",
    "        info = f\"No protocol information in MinKNOW buffer for {device_id}\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a13599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bias_voltage(device_id, voltage):\n",
    "    \"\"\"Change MinKnow bias voltage.\"\"\"\n",
    "    connection = connection_from_device_id(device_id)\n",
    "    previous_voltage = connection.device.get_bias_voltage().bias_voltage\n",
    "    connection.device.set_bias_voltage(bias_voltage=float(voltage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_file_methylation_caller(analysis_dir):\n",
    "    \"\"\"Invokes f5c methylation caller on a single fast5/fastq file and\n",
    "    calculates methylation frequencies and CpG overlaps.\n",
    "\n",
    "    Args:\n",
    "        analysis_dir: Directory containing fast5 and fastq files to be\n",
    "            analyzed. The basename of these files (corresponding to the\n",
    "            run id) must be equal to the name of analysis_dir.\n",
    "            The resulting files of the methylation calling process will\n",
    "            be saved in analysis_dir.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(analysis_dir)\n",
    "    base_path = os.path.join(analysis_dir, file_name)\n",
    "    # Create index file for f5c.\n",
    "    f5c_index = [\n",
    "        F5C, \"index\",\n",
    "        \"-t\", \"1\",\n",
    "        \"--iop\", \"100\",\n",
    "        \"--directory\", analysis_dir,\n",
    "        base_path + \".fastq\",\n",
    "    ]\n",
    "    # Aligns reads to reference genome and sorts resulting bam files\n",
    "    # (4 threads).\n",
    "    seq_align = [\n",
    "        MINIMAP2,\n",
    "        \"-a\",\n",
    "        \"-x\", \"map-ont\",\n",
    "        REFERENCE_GENOME_MMI,\n",
    "        base_path + \".fastq\",\n",
    "        \"-t\", \"4\",\n",
    "        \"|\",\n",
    "        SAMTOOLS, \"sort\",\n",
    "        \"-T\", \"tmp\",\n",
    "        \"-o\", base_path + \"-reads_sorted.bam\",\n",
    "    ]\n",
    "    # Make bam index for samtools.\n",
    "    bam_index = [\n",
    "        SAMTOOLS, \"index\",\n",
    "        base_path + \"-reads_sorted.bam\",\n",
    "    ]\n",
    "    # Methylation caller.\n",
    "    methyl_calling = [\n",
    "        F5C, \"call-methylation\",\n",
    "        #\"--disable-cuda=yes\",   # For debugging on CPU only.\n",
    "        \"-B2000000\", \"-K400\",    # Set B to 2 megabases (GPU) and 0.4 kreads\n",
    "        \"-b\", base_path + \"-reads_sorted.bam\",\n",
    "        \"-g\", REFERENCE_GENOME_FA,\n",
    "        \"-r\", base_path + \".fastq\",\n",
    "        \">\", base_path + \"-result.tsv\",\n",
    "    ]\n",
    "    # Calculate methylation frequencies.\n",
    "    methyl_frequency = [\n",
    "        F5C, \"meth-freq\",\n",
    "        \"-c\", \"2.5\",\n",
    "        \"-s\",\n",
    "        \"-i\", base_path + \"-result.tsv\",\n",
    "        \">\",\n",
    "        base_path + \"-freq.tsv\",\n",
    "    ]\n",
    "    commands = [\n",
    "        f5c_index,\n",
    "        seq_align,\n",
    "        bam_index,\n",
    "        methyl_calling,\n",
    "        methyl_frequency,\n",
    "    ]\n",
    "\n",
    "    def log_subprocess_output(pipe):\n",
    "        \"\"\"Logs subprocess (to file) and also sends output to stdout.\"\"\"\n",
    "        stdout_data, stderr_data = pipe.communicate()\n",
    "        for line in stdout_data.decode().split(\"\\n\"):\n",
    "            logger.info(line)\n",
    "            print(line)\n",
    "        for line in stderr_data.decode().split(\"\\n\"):\n",
    "            logger.info(line)\n",
    "            print(line)\n",
    "\n",
    "    for cmd in commands:\n",
    "        cmd_str = \" \".join(cmd)\n",
    "        process = subprocess.Popen(\n",
    "            cmd_str,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "        )\n",
    "        log_subprocess_output(process)\n",
    "        exit_code = process.wait()\n",
    "        if exit_code != 0:\n",
    "            logger.error(\"Error occured on subprocess '%s'\", cmd[0])\n",
    "    # Calculate CpG overlap.\n",
    "    extract_referenced_cpgs(\n",
    "        base_path + \"-freq.tsv\",\n",
    "        base_path + \"-methoverlap.tsv\",\n",
    "        base_path + \"-methoverlapcount.txt\",\n",
    "    )\n",
    "    # Write empty textfile to signal successful completion.\n",
    "    with open(os.path.join(analysis_dir, \"done.txt\"), \"w\"):\n",
    "        pass\n",
    "    print(f\"Methylation calling on {file_name} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dirs_with_wrong_barcode(sample_name, barcode):\n",
    "    \"\"\"Removes directories with wrong barcode due to change of\n",
    "    the predominant barcode after the first reads.\n",
    "    \"\"\"\n",
    "    output_dirs = [\n",
    "        os.path.join(NANODIP_OUTPUT, sample_name, dir_nm) for dir_nm in\n",
    "        os.listdir(os.path.join(NANODIP_OUTPUT, sample_name))\n",
    "    ]\n",
    "    wrong_barcode_dirs = [\n",
    "        f for f in output_dirs if barcode not in f\n",
    "    ]\n",
    "    for dir_path in wrong_barcode_dirs:\n",
    "        shutil.rmtree(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methylation_caller(sample_name, analyze_one=True):\n",
    "    \"\"\"Searches for callable fast5/fastq files that have not yet been\n",
    "    called and invokes methylation calling. Results will be added to\n",
    "    the NANODIP_OUTPUT directory.\n",
    "\n",
    "    Args:\n",
    "        sample_name: Name of sample to be analyzed.\n",
    "        analyse_one: If True only first fast5/fastq file found\n",
    "                     will be analyzed.\n",
    "    \"\"\"\n",
    "    # At least 2 \"passed\" files need to be present.\n",
    "    barcode = predominant_barcode(sample_name)\n",
    "    remove_dirs_with_wrong_barcode(sample_name, barcode)\n",
    "    fast5_files = [\n",
    "        f for f in files_by_ending(DATA, sample_name, ending=\".fast5\")\n",
    "        if barcode in f\n",
    "    ]\n",
    "    # Analyse in alphanumeric ordering for improved debugging.\n",
    "    fast5_files.sort()\n",
    "    def from_5_to_q(fn):\n",
    "        return fn.replace(\n",
    "            \".fast5\", \".fastq\"\n",
    "        ).replace(\"fast5_pass\", \"fastq_pass\")\n",
    "\n",
    "    # Collect all passed fast5/fastq pairs\n",
    "    fast5q_file_pairs = [\n",
    "        [f, from_5_to_q(f)] for f in fast5_files\n",
    "        if os.path.exists(from_5_to_q(f))\n",
    "    ]\n",
    "\n",
    "    f5c_analysis_dir = os.path.join(NANODIP_OUTPUT, sample_name)\n",
    "    if not os.path.exists(f5c_analysis_dir):\n",
    "        os.mkdir(f5c_analysis_dir)\n",
    "\n",
    "    prev_called = []\n",
    "    curr_called = []\n",
    "    not_called = []\n",
    "\n",
    "    for f5, fq in fast5q_file_pairs:\n",
    "        file_name = os.path.basename(f5).split(\".\")[0]\n",
    "        analysis_dir = os.path.join(f5c_analysis_dir, file_name)\n",
    "        symlink5 = os.path.join(analysis_dir, file_name + \".fast5\")\n",
    "        symlinkq = os.path.join(analysis_dir, file_name + \".fastq\")\n",
    "        if not os.path.exists(analysis_dir):\n",
    "            os.mkdir(analysis_dir)\n",
    "        if not os.path.exists(symlink5):\n",
    "            os.symlink(f5, symlink5)\n",
    "        if not os.path.exists(symlinkq):\n",
    "            os.symlink(fq, symlinkq)\n",
    "        done = os.path.join(analysis_dir, \"done.txt\")\n",
    "        if os.path.exists(done):\n",
    "            prev_called.append(file_name)\n",
    "        else:\n",
    "            not_called.append(\n",
    "                [analysis_dir, file_name]\n",
    "            )\n",
    "    for directory, file_name in not_called:\n",
    "        single_file_methylation_caller(directory)\n",
    "        curr_called.append(file_name)\n",
    "        if analyze_one:\n",
    "            break\n",
    "    num_completed = len(prev_called) + len(curr_called)\n",
    "    num_fastq = len(fast5q_file_pairs)\n",
    "    no_callable_left = num_fastq == num_completed\n",
    "    return {\n",
    "        \"barcode\": barcode,\n",
    "        \"called\": curr_called,\n",
    "        \"num_completed\": num_completed,\n",
    "        \"num_fastq\": num_fastq,\n",
    "        \"no_callable_left\": no_callable_left,\n",
    "        \"time\": date_time_string_now(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f91f8ea",
   "metadata": {},
   "source": [
    "\n",
    "### CherryPy Web UI\n",
    "The browser-based user interface is based on CherryPy, which contains an\n",
    "integrated web server and serves pages locally. Communication between the\n",
    "service and browser typically generates static web pages that may or may not\n",
    "contain automatic self refresh commands. In the case of self-refreshing pages,\n",
    "the browser will re-request a given page with leads to re-execution of the\n",
    "respective python functions. The main handles to these function are located in\n",
    "the Web UI cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37551148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Device:\n",
    "    \"\"\"Container used to store auto-termination status for a single\n",
    "    device.\n",
    "    \"\"\"\n",
    "    def __init__(self, device_id):\n",
    "        self.id = device_id\n",
    "        self.termination_type = \"manually\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"(id={self.id}, termination_type={self.termination_type})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Devices:\n",
    "    \"\"\"List of Device objects, used to store auto-termination status for\n",
    "    all devices.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.list = []\n",
    "\n",
    "    def get(self, device_id):\n",
    "        \"\"\"Appends device {device_id} if necessary and returns it.\"\"\"\n",
    "        device = self.get_device(device_id)\n",
    "        if device:\n",
    "            return device\n",
    "        device = Device(device_id)\n",
    "        self.list.append(device)\n",
    "        return device\n",
    "\n",
    "    def pop(self, device_id):\n",
    "        \"\"\"Removes and returns device.\"\"\"\n",
    "        device = self.get_device(device_id)\n",
    "        if device:\n",
    "            self.list.remove(device)\n",
    "            return device\n",
    "        return None\n",
    "\n",
    "    def get_device(self, device_id):\n",
    "        \"\"\"Returns device with given id. Returns false if id is not found.\"\"\"\n",
    "        return next(\n",
    "            (device for device in self.list if device_id == device.id),\n",
    "            False,\n",
    "        )\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.list)\n",
    "\n",
    "    def __contains__(self, other):\n",
    "        return other in [d.id for d in self]\n",
    "\n",
    "    def __repr__(self):\n",
    "        out = \"[\"\n",
    "        out += \", \".join([str(d) for d in self.list])\n",
    "        out += \"]\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1741f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_epidip_data(sentrix_id, reference_umap):\n",
    "    \"\"\"Downloads UMAP plot coordinates of reference data and CNV plot of\n",
    "    sample with given Sentrix ID.\n",
    "    \"\"\"\n",
    "    umap_coordinates_local = composite_path(\n",
    "        NANODIP_REPORTS,\n",
    "        sentrix_id,\n",
    "        reference_umap[:-5],\n",
    "        ENDING[\"umap_xlsx\"],\n",
    "    )\n",
    "\n",
    "    url = UMAP_LINK % reference_umap\n",
    "    request.urlretrieve(url, umap_coordinates_local)\n",
    "\n",
    "    cnv_local = composite_path(NANODIP_REPORTS, sentrix_id, ENDING[\"cnv_pdf\"])\n",
    "    url = CNV_LINK % sentrix_id\n",
    "    request.urlretrieve(url, cnv_local)\n",
    "\n",
    "    image = convert_from_path(cnv_local)[0]\n",
    "    image.save(cnv_local.replace(\"pdf\", \"png\"), \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9837fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UI:\n",
    "    \"\"\"User interface implemented as CherryPy webserver.\"\"\"\n",
    "    # global variables within the CherryPy Web UI\n",
    "    cnv_sem = threading.Semaphore()\n",
    "    umap_sem = threading.Semaphore()\n",
    "    cpg_sem = threading.Semaphore()\n",
    "    devices = Devices()\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def index(self):\n",
    "        \"\"\"Start page.\"\"\"\n",
    "        total, used, free = shutil.disk_usage(DATA)\n",
    "        sys_stat = {\n",
    "            \"hostname\": socket.gethostname(),\n",
    "            \"disk_total\": total // (2**30),\n",
    "            \"disk_used\": used // (2**30),\n",
    "            \"disk_free\": free // (2**30),\n",
    "            \"memory_free\": round(\n",
    "                psutil.virtual_memory().available * 100\n",
    "                / psutil.virtual_memory().total\n",
    "            ),\n",
    "            \"cpu\": round(psutil.cpu_percent()),\n",
    "            \"cpgs\": 1 - UI.cpg_sem._value,\n",
    "            \"cnvp\": 1 - UI.cnv_sem._value,\n",
    "            \"umap\": 1 - UI.umap_sem._value,\n",
    "        }\n",
    "        # Calculate URLs to avoid hard coding URLs in HTML templates.\n",
    "        return render_template(\n",
    "            \"index.html\",\n",
    "            sys_stat=sys_stat,\n",
    "            url_restart=url_for(UI.restart),\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def restart(self):\n",
    "        \"\"\"Restart CherryPy.\"\"\"\n",
    "        cherrypy.engine.restart()\n",
    "        return render_template(\"restart.html\")\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def status(self):\n",
    "        \"\"\"List all devices with run-status and show UMAP/CMV preview if\n",
    "        available.\n",
    "        \"\"\"\n",
    "        device_ids = [pos.name for pos in minion_positions()]\n",
    "        # Calculate URLs to avoid hard coding URLs in HTML templates.\n",
    "        return render_template(\n",
    "            \"status.html\",\n",
    "            device_ids=device_ids,\n",
    "            url_live_device_status=url_for(UI.status_device),\n",
    "            url_live_plots=url_for(UI.status_plots),\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def status_device(self, device_id):\n",
    "        \"\"\"Lists run-status of device {device_id} and prints button for\n",
    "        terminating run.\n",
    "        \"\"\"\n",
    "        UI.launch_auto_terminator(device_id)\n",
    "        status = None\n",
    "        device = UI.devices.get(device_id)\n",
    "        is_active = active_run(device_id) != \"none\"\n",
    "        try:\n",
    "            status = device_status(device_id)\n",
    "            previous_activity = True\n",
    "        except grpc._channel._InactiveRpcError:\n",
    "            previous_activity = False\n",
    "        return render_template(\n",
    "            \"status_device.html\",\n",
    "            device_id=device_id,\n",
    "            status=status,\n",
    "            flow_cell_id=flow_cell_id(device_id),\n",
    "            sample_id=run_sample_id(device_id),\n",
    "            yield_=run_yield(device_id),\n",
    "            state=run_state(device_id),\n",
    "            previous_activity=previous_activity,\n",
    "            needed_mega_bases=NEEDED_NUMBER_OF_BASES // 1e6,\n",
    "            url_auto_terminator = url_for(UI.set_auto_terminate),\n",
    "            termination_type=device.termination_type,\n",
    "            is_active=is_active,\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def status_plots(self, device_id=\"\"):\n",
    "        \"\"\"Generate a live preview of the data analysis with the current\n",
    "        plots.\n",
    "        \"\"\"\n",
    "        if not device_id:\n",
    "            raise cherrypy.HTTPError(404, \"URL not found\")\n",
    "        # If there is a run that produces data, the run ID will exist.\n",
    "        sample_id = run_sample_id(device_id)\n",
    "\n",
    "        # Chose reference with latest png-UMAP file.\n",
    "        umap_png_files = [\n",
    "            f for f in os.listdir(NANODIP_REPORTS)\n",
    "            if f.endswith(ENDING[\"umap_all_png\"]) and sample_id in f\n",
    "        ]\n",
    "        if not umap_png_files:\n",
    "            # Dummy reference name if no UMAP files are found (happens if\n",
    "            # device is not sequencing and thus no sample_id can be found.\n",
    "            reference = \"none\"\n",
    "        else:\n",
    "            latest_umap_png = max(\n",
    "                [os.path.join(NANODIP_REPORTS, f) for f in umap_png_files],\n",
    "                key=os.path.getmtime,\n",
    "            )\n",
    "            reference = re.search(\n",
    "                sample_id +  \"_(.*?)_\" + ENDING[\"umap_all_png\"],\n",
    "                latest_umap_png\n",
    "            ).group(1)\n",
    "\n",
    "        cnv_plt_path_png = composite_path(\n",
    "            \"reports\", sample_id, ENDING[\"cnv_png\"],\n",
    "        )\n",
    "        cnv_plt_path_html = composite_path(\n",
    "            \"reports\", sample_id, ENDING[\"cnv_html\"],\n",
    "        )\n",
    "        umap_plt_path_png = composite_path(\n",
    "            \"reports\", sample_id, reference, ENDING[\"umap_all_png\"],\n",
    "        )\n",
    "        umap_plt_path_html = composite_path(\n",
    "            \"reports\", sample_id, reference, ENDING[\"umap_all_html\"],\n",
    "        )\n",
    "        return render_template(\n",
    "            \"status_plots.html\",\n",
    "            sample_id=sample_id,\n",
    "            reference=reference,\n",
    "            cnv_plt_path_png=cnv_plt_path_png,\n",
    "            cnv_plt_path_html=cnv_plt_path_html,\n",
    "            umap_plt_path_png=umap_plt_path_png,\n",
    "            umap_plt_path_html=umap_plt_path_html,\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def start(\n",
    "        self,\n",
    "        device_id=\"\",\n",
    "        sample_id=\"\",\n",
    "        run_duration=\"\",\n",
    "        reference_id=\"\",\n",
    "        start_voltage=\"\",\n",
    "    ):\n",
    "        \"\"\"Start sequencing run.\"\"\"\n",
    "        start_now = bool(sample_id) and float(run_duration) >= 0.1\n",
    "        if start_now:\n",
    "            # Delete termination status info of last round.\n",
    "            UI.devices.pop(device_id)\n",
    "            run_ids = start_run(\n",
    "                device_id=device_id,\n",
    "                sample_id=sample_id,\n",
    "                run_duration=run_duration,\n",
    "                start_voltage=start_voltage,\n",
    "            )\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=start_now,\n",
    "                test=False,\n",
    "                sample_id=sample_id,\n",
    "                reference_id=reference_id,\n",
    "                device_id=device_id,\n",
    "                run_id=\" / \".join(run_ids),\n",
    "                run_info=run_information(device_id),\n",
    "            )\n",
    "        positions = [p.name for p in minion_positions()]\n",
    "        idle = [\n",
    "            p for p in positions if real_device_activity(p) == \"idle\"\n",
    "            and flow_cell_id(p) != \"\"\n",
    "        ]\n",
    "        flow_cell = {pos:flow_cell_id(pos) for pos in idle}\n",
    "        return render_template(\n",
    "            \"start.html\",\n",
    "            start_now=start_now,\n",
    "            test=False,\n",
    "            idle=idle,\n",
    "            flow_cell=flow_cell,\n",
    "            references=reference_annotations(),\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def start_test(self, device_id=\"\"):\n",
    "        \"\"\"Start sequencing test run.\"\"\"\n",
    "        if device_id:\n",
    "            sample_id = (date_time_string_now() + \"_TestRun_\"\n",
    "                + flow_cell_id(device_id))\n",
    "            run_ids = start_run(\n",
    "                device_id=device_id,\n",
    "                sample_id=sample_id,\n",
    "                run_duration=\"0.1\",\n",
    "                start_voltage=\"-180\",\n",
    "            )\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=True,\n",
    "                sample_id=sample_id,\n",
    "                reference_id=\"TEST\",\n",
    "                device_id=device_id,\n",
    "                run_id=\" / \".join(run_ids),\n",
    "                run_info=run_information(device_id),\n",
    "            )\n",
    "        positions = [p.name for p in minion_positions()]\n",
    "        idle = [p for p in positions if real_device_activity(p) == \"idle\"\n",
    "            and flow_cell_id(p) != \"\"]\n",
    "        flow_cell = {pos:flow_cell_id(pos) for pos in idle}\n",
    "        return render_template(\n",
    "            \"start.html\",\n",
    "            start_now=False,\n",
    "            test=True,\n",
    "            idle=idle,\n",
    "            flow_cell=flow_cell,\n",
    "            references=reference_annotations(),\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def stop_sequencing(self, device_id=\"\"):\n",
    "        \"\"\"Can be used to manually stop a run.\"\"\"\n",
    "        protocol_id = stop_run(device_id)\n",
    "        if protocol_id is None:\n",
    "            return \"No protocol running, nothing was stopped.\"\n",
    "        return f\"Protocol {protocol_id} stopped on {device_id}.\"\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def list_runs(self):\n",
    "        \"\"\"Lists running and buffered sequencing runs.\"\"\"\n",
    "        mounted_flow_cell_id = {}\n",
    "        current_status = {}\n",
    "        flow_cell = {}\n",
    "        run_ids = {}\n",
    "        device_names = []\n",
    "\n",
    "        for minion in minion_positions():\n",
    "            name = minion.name\n",
    "            connection = minion.connect()\n",
    "            device_names.append(name)\n",
    "            mounted_flow_cell_id[name] = connection.device.get_flow_cell_info(\n",
    "                ).flow_cell_id\n",
    "            # READY, STARTING, sequencing/mux = PROCESSING, FINISHING;\n",
    "            # Pause = PROCESSING\n",
    "            current_status[name] = connection.acquisition.current_status()\n",
    "            protocols = connection.protocol.list_protocol_runs()\n",
    "            run_ids[name] = protocols.run_ids\n",
    "            for run_id in run_ids[name]:\n",
    "                run_info = connection.protocol.get_run_info(run_id=run_id)\n",
    "                flow_cell[(name, run_id)] = run_info.flow_cell.flow_cell_id\n",
    "\n",
    "        return render_template(\n",
    "            \"list_runs.html\",\n",
    "            device_names=device_names,\n",
    "            host=CHERRYPY_HOST,\n",
    "            mounted_flow_cell_id=mounted_flow_cell_id,\n",
    "            current_status=current_status,\n",
    "            flow_cell=flow_cell,\n",
    "            run_ids=run_ids,\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def results(self):\n",
    "        \"\"\"Lists all files in NANODIP_REPORTS.\"\"\"\n",
    "        files = get_all_results()\n",
    "        urls = {f:f\"reports/{f}\" for f in files}\n",
    "        return render_template(\n",
    "            \"results.html\",\n",
    "            files=files,\n",
    "            urls=urls,\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analysis(\n",
    "        self,\n",
    "        func=\"\",\n",
    "        sample_name=\"\",\n",
    "        reference_name=\"\",\n",
    "        new=\"False\",\n",
    "    ):\n",
    "        \"\"\"Creates an overview of all samples and provides the analysis\n",
    "        tools (CpG methylation calling, CNV plot and UMAP plot).\n",
    "        \"\"\"\n",
    "        if func == \"\":\n",
    "            analysis_runs = [\n",
    "                run for run in get_runs() if not any(\n",
    "                    pattern in run for pattern in ANALYSIS_EXCLUSION_PATTERNS\n",
    "                )\n",
    "            ]\n",
    "            annotations = reference_annotations()\n",
    "            # Calculate URLs to avoid hard coding URLs in HTML templates.\n",
    "            url_cnv = {}\n",
    "            url_cnv_new = {}\n",
    "            url_cpgs = {}\n",
    "            url_pdf = {}\n",
    "            url_umap = {}\n",
    "            url_umap_new = {}\n",
    "            for run in analysis_runs:\n",
    "                url_cnv[run] = url_for(\n",
    "                    UI.analysis, func=\"cnv\", sample_name=run,\n",
    "                )\n",
    "                url_cnv_new[run] = url_for(\n",
    "                    UI.analysis, func=\"cnv\", sample_name=run, new=True,\n",
    "                )\n",
    "                url_cpgs[run] = url_for(\n",
    "                    UI.analysis, func=\"cpgs\", sample_name=run,\n",
    "                )\n",
    "                for annotation in annotations:\n",
    "                    url_umap_new[(run,annotation)] = url_for(\n",
    "                        UI.analysis,\n",
    "                        func=\"umap\",\n",
    "                        sample_name=run,\n",
    "                        reference_name=annotation,\n",
    "                        new=True,\n",
    "                    )\n",
    "                    url_umap[(run,annotation)] = url_for(\n",
    "                        UI.analysis,\n",
    "                        func=\"umap\",\n",
    "                        sample_name=run,\n",
    "                        reference_name=annotation,\n",
    "                    )\n",
    "                    url_pdf[(run,annotation)] = url_for(\n",
    "                        UI.make_pdf,\n",
    "                        sample_name=run,\n",
    "                        reference_name=annotation,\n",
    "                    )\n",
    "            return render_template(\n",
    "                \"analysis_start.html\",\n",
    "                analysis_runs=analysis_runs,\n",
    "                annotations=annotations,\n",
    "                url_cnv=url_cnv,\n",
    "                url_cnv_new=url_cnv_new,\n",
    "                url_cpgs=url_cpgs,\n",
    "                url_pdf=url_pdf,\n",
    "                url_umap=url_umap,\n",
    "                url_umap_new=url_umap_new,\n",
    "            )\n",
    "        if func == \"cnv\":\n",
    "            genome = Genome()\n",
    "            genes = genome.genes.name.to_list()\n",
    "            return render_template(\n",
    "                \"analysis_cnv.html\",\n",
    "                url_cnv=url_for(UI.cnv),\n",
    "                sample_name=sample_name,\n",
    "                genes=genes,\n",
    "                new=new,\n",
    "            )\n",
    "        if func == \"umap\":\n",
    "            return render_template(\n",
    "                \"analysis_umap.html\",\n",
    "                url_umap=url_for(UI.umap),\n",
    "                sample_name=sample_name,\n",
    "                reference_name=reference_name,\n",
    "                new=new,\n",
    "                first_use = not binary_reference_data_exists(),\n",
    "            )\n",
    "        if func == \"cpgs\":\n",
    "            return render_template(\n",
    "                \"analysis_cpg.html\",\n",
    "                url_cpgs=url_for(UI.cpgs),\n",
    "                start_time=date_time_string_now(),\n",
    "                sample_name=sample_name,\n",
    "            )\n",
    "        raise cherrypy.HTTPError(404, \"URL not found\")\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def cnv(self, sample_name, genes=\"\", new=\"False\"):\n",
    "        \"\"\"Creates CNV plot and returns it as JSON.\"\"\"\n",
    "        UI.cnv_sem.acquire()\n",
    "        try:\n",
    "            cnv_data = CNVData(sample_name)\n",
    "        except FileNotFoundError:\n",
    "            raise cherrypy.HTTPError(405, \"URL not allowed\")\n",
    "\n",
    "        if not cnv_data.files_on_disk() or new == \"True\":\n",
    "            try:\n",
    "                cnv_data.make_cnv_plot()\n",
    "            except ValueError:\n",
    "                UI.cnv_sem.release()\n",
    "                raise cherrypy.HTTPError(405, \"No data to plot.\")\n",
    "        else:\n",
    "            cnv_data.read_from_disk()\n",
    "        UI.cnv_sem.release()\n",
    "        return cnv_data.plot_cnv_and_genes([genes])\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def umap(self, sample_name, reference_name, close_up=\"\", new=\"False\"):\n",
    "        \"\"\"Creates UMAP plot and returns it as JSON.\"\"\"\n",
    "        UI.umap_sem.acquire()\n",
    "        try:\n",
    "            umap_data = UMAPData(sample_name, reference_name)\n",
    "        except FileNotFoundError:\n",
    "            raise cherrypy.HTTPError(405, \"URL not allowed\")\n",
    "        if not umap_data.files_on_disk() or new == \"True\":\n",
    "            try:\n",
    "                umap_data.make_umap_plot()\n",
    "            except ValueError:\n",
    "                UI.umap_sem.release()\n",
    "                raise cherrypy.HTTPError(405, \"No data to plot.\")\n",
    "        else:\n",
    "            umap_data.read_from_disk()\n",
    "        UI.umap_sem.release()\n",
    "        if close_up == \"True\":\n",
    "            return umap_data.cu_plot_json\n",
    "        return umap_data.plot_json\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def make_pdf(self, sample_name=None, reference_name=None):\n",
    "        \"\"\"Generates PDF report.\"\"\"\n",
    "        path_cgp = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, reference_name, ENDING[\"cpg_cnt\"]\n",
    "        )\n",
    "        path_reads = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, ENDING[\"aligned_reads\"]\n",
    "        )\n",
    "        try:\n",
    "            with open(path_cgp, \"r\") as f:\n",
    "                overlap_cnt = f.read()\n",
    "            with open(path_reads, \"r\") as f:\n",
    "                read_numbers = f.read()\n",
    "        except FileNotFoundError:\n",
    "            overlap_cnt = 0\n",
    "            read_numbers = 0\n",
    "        cnv_path = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, ENDING[\"cnv_png\"]\n",
    "        )\n",
    "        umap_path = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, reference_name, ENDING[\"umap_top_png\"],\n",
    "        )\n",
    "        pie_chart_path = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, reference_name, ENDING[\"pie\"]\n",
    "        )\n",
    "\n",
    "        html_report = render_template(\n",
    "            \"pdf_report.html\",\n",
    "            sample_name=sample_name,\n",
    "            sys_name=socket.gethostname(),\n",
    "            date=date_time_string_now(),\n",
    "            barcode=predominant_barcode(sample_name),\n",
    "            reads=read_numbers,\n",
    "            cpg_overlap_cnt=overlap_cnt,\n",
    "            reference=reference_name,\n",
    "            cnv_path=cnv_path,\n",
    "            umap_path=umap_path,\n",
    "            pie_chart_path=pie_chart_path,\n",
    "        )\n",
    "        report_path = composite_path(\n",
    "            NANODIP_REPORTS, sample_name, reference_name, ENDING[\"report\"],\n",
    "        )\n",
    "        server_report_path = composite_path(\n",
    "            \"reports\", sample_name, reference_name, ENDING[\"report\"],\n",
    "        )\n",
    "        convert_html_to_pdf(html_report, report_path)\n",
    "        raise cherrypy.HTTPRedirect(server_report_path)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def set_auto_terminate(self, device_id=\"\", termination_type=\"\"):\n",
    "        \"\"\"Sets auto termination status.\"\"\"\n",
    "        device = UI.devices.get(device_id)\n",
    "        if termination_type in [\"terminated\", \"manually\", \"auto\"]:\n",
    "            device.termination_type = termination_type\n",
    "            logger.info(\n",
    "                \"Auto terminate status of %s set to %s\",\n",
    "                device_id,\n",
    "                device.termination_type,\n",
    "            )\n",
    "        else:\n",
    "            raise cherrypy.HTTPError(\n",
    "                404, \"Invalid termination type: '{termination_type}'\"\n",
    "            )\n",
    "        if termination_type == \"terminated\":\n",
    "            stop_run(device.id)\n",
    "\n",
    "    def launch_auto_terminator(device_id=\"\"):\n",
    "        \"\"\"Terminates the current run if auto terminator is set.\"\"\"\n",
    "        device = UI.devices.get(device_id)\n",
    "        if (\n",
    "            device.termination_type == \"auto\" and\n",
    "            number_of_called_bases(device.id) > NEEDED_NUMBER_OF_BASES\n",
    "        ):\n",
    "            stop_run(device.id)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def cpgs(self, sample_name=\"\"):\n",
    "        \"\"\"Invokes methylation calling and returns statistics.\"\"\"\n",
    "        UI.cpg_sem.acquire()\n",
    "        stats = methylation_caller(sample_name)\n",
    "        UI.cpg_sem.release()\n",
    "        return json.dumps(stats)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def change_voltage(self, device_id=\"\", voltage=\"\"):\n",
    "        \"\"\"Change bias voltage.\"\"\"\n",
    "        set_bias_voltage(device_id, voltage)\n",
    "        return render_template(\n",
    "            \"change_voltage.html\",\n",
    "            voltage=voltage,\n",
    "        )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def epidip_report(\n",
    "        self,\n",
    "        sentrix_id=None,\n",
    "        reference_id=None,\n",
    "        reference_umap=None,\n",
    "    ):\n",
    "        \"\"\"Create report for reference case {sentrix_id} with precalculated\n",
    "        umap coordinates.\n",
    "        \"\"\"\n",
    "        if sentrix_id and reference_id and reference_umap:\n",
    "            download_epidip_data(sentrix_id, reference_umap)\n",
    "            umap_data = UMAPData(sentrix_id, reference_id)\n",
    "            umap_data.read_precalculated_umap_matrix(reference_umap)\n",
    "            umap_data.draw_pie_chart()\n",
    "            umap_data.draw_scatter_plots()\n",
    "            umap_data.save_to_disk()\n",
    "            UI.make_pdf(\n",
    "                self, sample_name=sentrix_id, reference_name=reference_id\n",
    "            )\n",
    "        else:\n",
    "            return render_template(\n",
    "                \"epidip_report.html\",\n",
    "                reference_umap=reference_umap,\n",
    "                epidip_umaps=EPIDIP_UMAP_COORDINATE_FILES,\n",
    "                references=reference_annotations(),\n",
    "            )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def about(self):\n",
    "        \"\"\"About Page.\"\"\"\n",
    "        return render_template(\"about.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70122787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_webserver():\n",
    "    \"\"\"Start CherryPy Webserver.\"\"\"\n",
    "    if DEBUG_MODE:\n",
    "        #Set access logging\n",
    "        cherrypy.log.screen = True\n",
    "        cherrypy.config.update({'log.screen': True})\n",
    "    else:\n",
    "        #Set access logging\n",
    "        cherrypy.log.screen = False\n",
    "        cherrypy.config.update({'log.screen': False})\n",
    "        cherrypy.config.update({ \"environment\": \"embedded\" })\n",
    "    cherrypy.log.access_file = composite_path(NANODIP_REPORTS, \"cherrypy.log\")\n",
    "    cherrypy.log.error_file = composite_path(NANODIP_REPORTS, \"cherrypy.log\")\n",
    "\n",
    "    print(f\"NanoDiP server running at http://{CHERRYPY_HOST}:{CHERRYPY_PORT}\")\n",
    "\n",
    "    cherrypy_config = {\n",
    "        '/favicon.ico': {\n",
    "            'tools.staticfile.on': True,\n",
    "            'tools.staticfile.filename': BROWSER_FAVICON,\n",
    "        },\n",
    "        '/reports': {\n",
    "            'tools.staticdir.on': True,\n",
    "            'tools.staticdir.dir': NANODIP_REPORTS,\n",
    "        },\n",
    "        '/static': {\n",
    "            'tools.staticdir.on': True,\n",
    "            'tools.staticdir.dir': os.path.join(os.getcwd(), \"static\"),\n",
    "        },\n",
    "    }\n",
    "    cherrypy.quickstart(UI(), \"/\", cherrypy_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging options\n",
    "logging.basicConfig(\n",
    "    filename=\"/data/nanodip_reports/nanodip.log\",\n",
    "    # stream=sys.stdout,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(levelname)s %(filename)s,%(lineno)d [%(asctime)s]: %(message)s\",\n",
    "    filemode=\"w\",\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sanity_check()\n",
    "    start_webserver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7dffa",
   "metadata": {},
   "source": [
    "\n",
    "### ^^^ LIVE LOG ABOVE ^^^\n",
    "All CherryPy access will be logged here, including live progress bars for\n",
    "computationally intense analyses. Detailed access logging is turned off by\n",
    "default (accessLogging is False), but can be turned on, e.g., for debugging,\n",
    "in the configuration section at the beginning of this notebook. While it is not\n",
    "required to have at look at these during normal operation, information\n",
    "contained in the log may be helpful in troubleshooting. Line numbers in error\n",
    "messages indicated here typically match those given in the respective Jupyter\n",
    "Notebook cells.\n",
    "\n",
    "To preserve these messages, halt the Python kernel, save and close the notebook\n",
    "to send it for support. This makes sure that the code as well as the error\n",
    "messages will be preserved.\n",
    "\n",
    "To launch the user interface, wait until you see a pink log entry that the web\n",
    "server has started, then navigate to http://localhost:8080.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
