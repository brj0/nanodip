{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b2abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99582f39",
   "metadata": {},
   "source": [
    "\n",
    "## NanoDiP all-in-one Jupyter Notebook\n",
    "*J. Hench, S. Frank, and C. Hultschig, Neuropathology, IfP Basel, 2021*\n",
    "\n",
    "This software is provided free of charge and warranty; by using it you agree\n",
    "to do this on your own risk. The authors shall not be held liable for any\n",
    "damage caused by this software. We have assembled this and tested it to the\n",
    "best of our knowledge.\n",
    "\n",
    "The purpose of NanoDiP (Nanopore Digital Pathology) is to compare low-coverage\n",
    "Nanopore sequencing data from natively extracted DNA sequencing runs against\n",
    "a flexibly adaptable collection of 450K/850K Illumina Infinium Methylation\n",
    "array data. These data have to be preprocessed into binary beta value files;\n",
    "this operation is performed in R (uses minfi to read raw array data) and\n",
    "outputs bindary float files (one per dataset). These beta values files (e.g.,\n",
    "204949770141_R03C01_betas_filtered.bin) are named according to the array ID\n",
    "(Sentrix ID) followed by the suffix. A collection of betas_filtered.bin files\n",
    "can be provided in a static manner and XLSX (Microsoft Excel) tables can be\n",
    "used to select a subset thereof alongside a user-defined annotation. The\n",
    "corresponding datasets will be loaded into memory and then serve as the\n",
    "reference cohort to which the Nanopore data are compared by dimension reduction\n",
    "(UMAP). This comparison is optimized for speed and low resource consumption so\n",
    "that it can run on the computer that operates the sequencer. The sequencing run\n",
    "is initiated through the MinKNOW API by this application. Basecalling and\n",
    "methylation calling occur as background tasks outside this Jupyter Notebook.\n",
    "User interaction occurs through a web interface based on CherryPy which has\n",
    "been tested on Chromium web browser. It is advisable to run it locally, there\n",
    "are no measures to secure the generated website.\n",
    "\n",
    "In order to use this application properly please make sure to be somewhat\n",
    "familiar with Jupyter Notebook. To run the software, press the button called\n",
    "*restart the kernel, re-run the whole notebook (with dialog)* and confirm\n",
    "execution. Then, in Chromium Browser, navigate to http://localhost:8080/ and\n",
    "preferably bookmark this location for convenience. In case of errors, you may\n",
    "just again click the same button *restart the kernel, re-run the whole notebook\n",
    "(with dialog)*.\n",
    "___\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "* Tested with Python 3.7.5; 3.8.8 fails to load minknow_api in jupyter\n",
    "  notebook.\n",
    "* Verified to run on Ubuntu 18.04/Jetpack on ARMv8 and x86_64 CPUs; not\n",
    "  tested on Windows and Mac OS. The latter two platforms are unsupported, we\n",
    "  do not intend to support them.\n",
    "* **CAUTION**: Requires a *patched* version of minknow api, file\n",
    "  `[VENV]/lib/python3.7/site-packages/minknow_api/tools/protocols.py`.\n",
    "  Without the patch, the generated fast5 sequencing data will be unreadable\n",
    "  with f5c or nanopolish (wrong compression algorithm, which is the default in\n",
    "  the MinKNOW backend).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb778d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify running Python version (should be 3.7.5) and adjust jupyter notebook.\n",
    "import IPython\n",
    "import os\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb26295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set display witdth to 100%\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "os.system('python --version')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333299e5",
   "metadata": {},
   "source": [
    "\n",
    "## Multithreading Options\n",
    "Depending on the number of parallel threads/cores of the underlying hardware,\n",
    "threading options for multithreaded modules need to be set as\n",
    "environment-specific parameters. One way to do so is through the *os* module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution-wide multithreading options, set according to your hardware. Jetson\n",
    "# AGX: suggest \"2\" needs to be set before importing other modules that query\n",
    "# these parameters\n",
    "import os\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3474bf",
   "metadata": {},
   "source": [
    "\n",
    "## Modules\n",
    "This section imports the required modules that should have been installed via\n",
    "pip. Other package managers have not been tested. To install packages, use the\n",
    "setup script provided with this software or, alternatively, install them one\n",
    "by one, ideally in a virtual python environment. Note that the MinKNOW API\n",
    "requires manual patching after installation with pip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minknow_api.manager import Manager\n",
    "from minknow_api.tools import protocols\n",
    "from numba import jit\n",
    "from plotly.io import write_json, from_json\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import bisect\n",
    "import cherrypy\n",
    "import csv\n",
    "import datetime\n",
    "import fnmatch\n",
    "import jinja2\n",
    "import logging\n",
    "import math\n",
    "import minknow_api.device_pb2\n",
    "import minknow_api.statistics_pb2\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import psutil\n",
    "import pysam\n",
    "import re\n",
    "import shutil\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import xhtml2pdf.pisa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd204a",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n",
    "Below are system-specific parameters that may or may not require adaptation.\n",
    "Many variable names are self-explanatory. The key difference between\n",
    "Nanopore setups are between devices provided by ONT (MinIT incl. running the\n",
    "MinIT distribution on a NVIDIA Jetson developer kit such as the AGX Xavier,\n",
    "GridION) and the typical Ubuntu-based MinKNOW version on x86_64 computers. The\n",
    "raw data are written into a `/data` directory on ONT-based devices while they\n",
    "are found in `/var/lib/minknow/data` on x86_64 installations. Make sure to\n",
    "adapt your `DATA` accordingly. There are furthermore permission\n",
    "issues and special folders / files in the MinKNOW data directory. These files\n",
    "/ folders should be excluded from analysis through `EXCLUDED_FROM_ANALYSIS` so\n",
    "that only real run folders will be parsed. Finally, the `NANODIP_OUTPUT` is the\n",
    "place in which the background methylation and alignment process will place its\n",
    "results by replicating the directory hierarchy of the MinKNOW data location.\n",
    "It will not duplicate the data, and these data will be much smaller than raw\n",
    "run data. They can be placed anywhere in the file tree, but also inside the\n",
    "MinKNOW data path within a sub-folder. If the latter is the case, make sure to\n",
    "apply appropriate read/write permissions. Final reports and figures generated\n",
    "by NanoDiP are written into `NANODIP_REPORTS`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04481a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NANODIP_VERSION = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaae928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "DATA = \"/data\"\n",
    "NANODIP_OUTPUT = os.path.join(DATA, \"nanodip_output\")\n",
    "NANODIP_REPORTS = os.path.join(DATA, \"nanodip_reports\")\n",
    "REFERENCE_DATA = \"/applications/reference_data\"\n",
    "BETA_VALUES = os.path.join(REFERENCE_DATA, \"betaEPIC450Kmix_bin\")\n",
    "ANNOTATIONS = os.path.join(REFERENCE_DATA, \"reference_annotations\")\n",
    "ANNOTATIONS_ABBREVIATIONS_BASEL = \"/applications/reference_data/reference_annotations/mc_anno_ifp_basel.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gdc.cancer.gov/resources-tcga-users/tcga-code-tables/tcga-study-abbreviations\n",
    "ANNOTATIONS_ABBREVIATIONS_TCGA = \"/applications/reference_data/reference_annotations/tcga_study_abbreviations.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference data\n",
    "ILUMINA_CG_MAP = os.path.join(REFERENCE_DATA, \"minimap_data/hg19_HumanMethylation450_15017482_v1-2_cgmap.tsv\")\n",
    "REFERENCE_METHYLATION_DATA = os.path.join(REFERENCE_DATA, \"EPIC450K\")\n",
    "REFERENCE_METHYLATION = os.path.join(REFERENCE_METHYLATION_DATA, \"methylation.bin\")\n",
    "REFERENCE_CPG_SITES = os.path.join(REFERENCE_METHYLATION_DATA, \"cpg_sites.csv\")\n",
    "REFERENCE_SPECIMENS = os.path.join(REFERENCE_METHYLATION_DATA, \"specimens.csv\")\n",
    "REFERENCE_METHYLATION_SHAPE = os.path.join(REFERENCE_METHYLATION_DATA, \"shape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f020bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genome reference data\n",
    "CHROMOSOMES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19_chromosomes.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae418ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human reference genome in fa/minimap2 mmi format.\n",
    "REFERENCE_GENOME_FA = \"/applications/reference_data/minimap_data/hg19.fa\"\n",
    "REFERENCE_GENOME_MMI = \"/applications/reference_data/minimap_data/hg19_20201203.mmi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barcode strings, currently kit SQK-RBK004.\n",
    "BARCODE_NAMES = [\n",
    "    \"barcode01\",\"barcode02\",\"barcode03\",\n",
    "    \"barcode04\",\"barcode05\",\"barcode06\",\n",
    "    \"barcode07\",\"barcode08\",\"barcode09\",\n",
    "    \"barcode10\",\"barcode11\",\"barcode12\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf585e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HG19 Gene data\n",
    "# https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/genes/hg19.refGene.gtf.gz\n",
    "GENES_RAW = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19.refGene.gtf\")\n",
    "GENES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"hg19_genes.csv\")\n",
    "RELEVANT_GENES = os.path.join(REFERENCE_DATA, \"hg19_cnv\", \"relevant_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387064cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta values above cutoff will be interpreted as methylated.\n",
    "METHYLATION_CUTOFF = 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basecalled bases until run termination occurs.\n",
    "NEEDED_NUMBER_OF_BASES = 150_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67717548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL prefix/suffix to load PDF with CNV plot for a given Sentrix ID.\n",
    "CNV_URL_PREFIX = \"http://s1665.rootserver.io/umapplot01/\"\n",
    "CNV_URL_SUFFIX = \"_CNV_IFPBasel_annotations.pdf\"\n",
    "\n",
    "CNV_GRID = \"/applications/tmp/grid.json\" # TODO to /tmp/nanodip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reference cases to be shown in subplot including copy\n",
    "# number profile links (not advisable >200, plotly will become really\n",
    "# slow)\n",
    "UMAP_PLOT_TOP_MATCHES = 100\n",
    "\n",
    "PLOTLY_RENDER_MODE = \"webgl\"\n",
    "\n",
    "ANALYSIS_EXCLUSION_PATTERNS = [\"_TestRun_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of files and folders in DATA to be exluded from analysis.\n",
    "EXCLUDED_FROM_ANALYSIS = [\n",
    "    \".Trash-1000\",\n",
    "    \"core-dump-db\",\n",
    "    \"intermediate\",\n",
    "    \"lost+found\",\n",
    "    \"minimap_data\",\n",
    "    \"nanodip_output\",\n",
    "    \"nanodip_reports\",\n",
    "    \"nanodip_tmp\",\n",
    "    \"non-ont\",\n",
    "    \"pings\",                              \n",
    "    \"playback_raw_runs\",\n",
    "    \"queued_reads\",\n",
    "    \"raw_for_playback\",\n",
    "    \"reads\",\n",
    "    \"user_scripts\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file name sections that identify past runs.\n",
    "RESULT_ENDINGS = {\n",
    "    \"cnv_png\": \"_CNVplot.png\",\n",
    "    \"ranking\": \"_NanoDiP_ranking.pdf\",\n",
    "    \"report\": \"_NanoDiP_report.pdf\",\n",
    "    \"umap_all\": \"_UMAP_all.html\",\n",
    "    \"umap_top\": \"_UMAP_top.html\",\n",
    "}\n",
    "\n",
    "ENDINGS = {\n",
    "    **RESULT_ENDINGS,\n",
    "    \"aligned_reads\": \"_alignedreads.txt\",\n",
    "    \"cnv_bins_json\": \"_CNV_binsplot.json\",\n",
    "    \"cnv_html\": \"_CNVplot.html\",\n",
    "    \"cnv_json\": \"_CNVplot.json\",\n",
    "    \"cpg_cnt\":\"_cpgcount.txt\",\n",
    "    \"genes\": \"_genes.csv\",\n",
    "    \"methyl\": \"_methyl_overlap.npy\",\n",
    "    \"reads_csv\": \"_reads.csv\",\n",
    "    \"relevant_genes\": \"_relevant_genes.csv\",\n",
    "    \"umap_all_json\": \"_UMAP_all.json\",\n",
    "    \"umap_csv\": \"_UMAP.csv\",\n",
    "    \"umap_top_json\": \"_UMAP_top.json\",\n",
    "}\n",
    "\n",
    "DEBUG_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0=low log verbosity, 1=high log verbosity (with timestamps, for benchmarking and debugging)\n",
    "VERBOSITY = 0 # TODO replace logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Host and port on which the NanoDiP UI will be served\n",
    "CHERRYPY_HOST = \"localhost\"\n",
    "THIS_HOST = \"localhost\"\n",
    "CHERRYPY_PORT = 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The web browser favicon file for this application.\n",
    "BROWSER_FAVICON = \"/applications/nanodip/favicon.ico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location where image files for the web application are stored.\n",
    "IMAGES =\"/applications/nanodip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a37850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of reads per file. 400 works well on the Jetson AGX. Higher numbers\n",
    "# increase batch size and RAM usage, lower numbers use more I/O resouces due\n",
    "# to more frequent reloading of alignment reference.\n",
    "READS_PER_FILE = \"400\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to binaries for methylation calling.\n",
    "F5C = \"/applications/f5c/f5c\"\n",
    "MINIMAP2 = \"/applications/nanopolish/minimap2/minimap2\"\n",
    "SAMTOOLS = \"/applications/samtools/samtools\"\n",
    "RSCRIPT = \"/applications/R-4.0.3/bin/Rscript\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO del: R script that reads CpGs into simplified text file (absolute path)\n",
    "READ_CPG_RSCRIPT=\"/applications/nanodip/readCpGs_mod02.R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac32eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_referenced_cpgs(sample_methylation,\n",
    "                            output_overlap,\n",
    "                            output_overlap_cnt):\n",
    "    \"\"\"Extract ilumina CpG sites including methylation status from sample.\n",
    "    Args:\n",
    "        sample_methylation: methylation file of sample\n",
    "        output_overlap: file path of CpG overlap\n",
    "        output_overlap_cnt: file path of CpG overlap count\n",
    "    \"\"\"\n",
    "    reference_cpgs = pd.read_csv(\n",
    "        ILUMINA_CG_MAP,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"ilmnid\",\"chromosome\",\"strand\",\"start\"],\n",
    "    )\n",
    "    sample_cpgs = pd.read_csv(\n",
    "        sample_methylation,\n",
    "        delimiter=\"\\t\",\n",
    "    )\n",
    "    cpgs = pd.merge(sample_cpgs, reference_cpgs, on=[\"chromosome\", \"start\"])\n",
    "    # Extract singelton CpG's\n",
    "    cpgs = cpgs.loc[cpgs[\"num_cpgs_in_group\"] == 1]\n",
    "    cpgs = cpgs.loc[\n",
    "       (~cpgs[\"chromosome\"].isin([\"chrX\", \"chrY\"])) # TODO is this necessary?\n",
    "       & (~cpgs[\"ilmnid\"].duplicated())\n",
    "    ]\n",
    "    cpgs[\"is_methylated\"] = 0\n",
    "    cpgs.loc[cpgs[\"methylated_frequency\"] > 0.5 ,\"is_methylated\"] = 1\n",
    "    # Write overlap Data Frame\n",
    "    cpgs[[\"ilmnid\", \"is_methylated\"]].to_csv(\n",
    "        output_overlap, header=False, index=False, sep=\"\\t\")\n",
    "    # Write number of CpG's\n",
    "    with open(output_overlap_cnt, \"w\") as f:\n",
    "        f.write(f\"{len(cpgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897726fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_template(template_name, **context):\n",
    "    loader = jinja2.FileSystemLoader(\"templates\")\n",
    "    template = jinja2.Environment(\n",
    "        loader=loader).get_template(template_name)\n",
    "    return template.render(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_html_to_pdf(source_html, output_file):\n",
    "    \"\"\"Create PDF from html-string.\"\"\"\n",
    "    with open(output_file, \"w+b\") as f:\n",
    "        pisa_status = xhtml2pdf.pisa.CreatePDF(source_html, dest=f)\n",
    "    return pisa_status.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cb2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time_string_now():\n",
    "    \"\"\"Return current date and time as a string to create timestamps.\"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e4ddc",
   "metadata": {},
   "source": [
    "\n",
    "    nanodip.data\n",
    "    ------------\n",
    "    \n",
    "    Data containers for sample, reference-data and reference-genome/gene\n",
    "    data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_reference_data_exists():\n",
    "    \"\"\"Check if the binary form of the reference data was already created.\"\"\"\n",
    "    return (\n",
    "        os.path.exists(REFERENCE_METHYLATION_DATA) and\n",
    "        os.path.exists(REFERENCE_METHYLATION) and\n",
    "        os.path.exists(REFERENCE_CPG_SITES) and\n",
    "        os.path.exists(REFERENCE_SPECIMENS) and\n",
    "        os.path.exists(REFERENCE_METHYLATION_SHAPE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_reference_data(input_dir=BETA_VALUES,\n",
    "                               output_dir=REFERENCE_METHYLATION_DATA,\n",
    "                               cutoff=METHYLATION_CUTOFF):\n",
    "    \"\"\"Create binary methylation files from raw reference data.\n",
    "\n",
    "    Args:\n",
    "        input_dir: Directory of reference data as float arrays-\n",
    "            files.\n",
    "        output_dir: Output dir containing binary array-file.\n",
    "        cutoff: Empirical cutoff value for methylated\n",
    "            (round to 1) and unmethylated (round to 0) CpGs.\n",
    "    \"\"\"\n",
    "    print(\"The binary reference data is generated. Takes 5-10 minutes.\")\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    specimens = [f for f in os.listdir(input_dir)\n",
    "                 if f.endswith(\".bin\")]\n",
    "\n",
    "    # Get shape parameters of output_data\n",
    "    path0 = os.path.join(input_dir, specimens[0])\n",
    "    with open(path0, \"r\") as f:\n",
    "        beta_values_0 = np.fromfile(f, dtype=float)\n",
    "    shape = (len(specimens), len(beta_values_0))\n",
    "\n",
    "    methylation_data = np.empty(shape, dtype=bool)\n",
    "\n",
    "    for i, specimen in enumerate(tqdm(specimens, desc=\"Reading reference\")):\n",
    "        specimen_path = os.path.join(input_dir, specimen)\n",
    "\n",
    "        with open(specimen_path, \"rb\") as f:\n",
    "            beta_values = np.fromfile(f, dtype=float)\n",
    "            methylation_data[i] = np.digitize(\n",
    "                beta_values,\n",
    "                bins=[cutoff]\n",
    "            ).astype(bool)\n",
    "\n",
    "    # write methylation data as binary\n",
    "    methylation_file = os.path.join(output_dir, \"methylation.bin\")\n",
    "    methylation_data.tofile(methylation_file)\n",
    "\n",
    "    # write shape parameters\n",
    "    shape_file = os.path.join(output_dir, \"shape.csv\")\n",
    "    with open(shape_file, \"w\") as f:\n",
    "        f.write(\"%s\\n %s\" % shape)\n",
    "\n",
    "    # write reference specimens\n",
    "    specimens_file = os.path.join(output_dir, \"specimens.csv\")\n",
    "    specimen_names = [s[:-len(\"_betas_filtered.bin\")] for s in specimens]\n",
    "    with open(specimens_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(specimen_names))\n",
    "\n",
    "    # write reference cpg sites\n",
    "    index_file = os.path.join(output_dir, \"cpg_sites.csv\")\n",
    "    with open(os.path.join(input_dir, \"index.csv\")) as f:\n",
    "        index = f.read()\n",
    "    with open(index_file, \"w\") as f:\n",
    "        f.write(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_reference_data_if_needed():\n",
    "    if not binary_reference_data_exists():\n",
    "        make_binary_reference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceData:\n",
    "    \"\"\"Container of reference data and metadata.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        make_binary_reference_data_if_needed()\n",
    "        self.name = name\n",
    "        self.annotation = self.get_annotation()\n",
    "        with open(REFERENCE_CPG_SITES, \"r\") as f:\n",
    "        # save as Dictionary to allow fast index lookup\n",
    "            self.cpg_sites = {cpg:i for i, cpg in enumerate(\n",
    "                f.read().splitlines()\n",
    "            )}\n",
    "\n",
    "        with open(REFERENCE_SPECIMENS) as f:\n",
    "            self.specimens = f.read().splitlines()\n",
    "\n",
    "        # determine if there are entries in the annotation without corresponding\n",
    "        # methylation binary file\n",
    "        self.annotated_specimens = list(\n",
    "            set(self.annotation[\"id\"]) & set(self.specimens)\n",
    "        )\n",
    "\n",
    "        # Save as dictionary to allow fast hash lookup.\n",
    "        index = {s:i for i, s in enumerate(self.specimens)}\n",
    "        self.annotated_specimens_index = [index[a]\n",
    "            for a in self.annotated_specimens]\n",
    "        self.annotated_specimens_index.sort()\n",
    "\n",
    "        # Save as dictionary to allow fast hash lookup.\n",
    "        methyl_dict = {i:mc for i, mc in\n",
    "            zip(self.annotation.id, self.annotation.methylation_class)\n",
    "        }\n",
    "        self.specimen_ids = [self.specimens[i]\n",
    "            for i in self.annotated_specimens_index]\n",
    "        self.methylation_class = [methyl_dict[s] for s in self.specimen_ids]\n",
    "        self.description = ReferenceData.get_description(\n",
    "            self.methylation_class\n",
    "        ) \n",
    "\n",
    "    def get_description(methylation_classes):\n",
    "        \"\"\"Returns a description of the methylation class.\"\"\"\n",
    "        abbr_df = pd.read_csv(ANNOTATIONS_ABBREVIATIONS_BASEL)\n",
    "        abbr = {\n",
    "            mc:desc for mc, desc in \n",
    "            zip(abbr_df.MethylClassStr, abbr_df.MethylClassShortDescr)\n",
    "        }\n",
    "        non_trivial_abbr = abbr.copy()\n",
    "        non_trivial_abbr.pop(\"-\")\n",
    "        tcga_df = pd.read_csv(ANNOTATIONS_ABBREVIATIONS_TCGA, delimiter=\"\\t\")\n",
    "        tcga = {r[0]:r[1] for _, r in tcga_df.iterrows()}\n",
    "        def description(mc):\n",
    "            mc = mc.upper()\n",
    "            # Exact match\n",
    "            if mc in abbr:\n",
    "                return abbr[mc]\n",
    "            # Else choose longest substring from Basel-Annotations/TCGA\n",
    "            basel_substring = [a for a in non_trivial_abbr if a in mc]\n",
    "            basel_substring.sort(key=lambda x: len(x))\n",
    "            tcga_substring = [a for a in tcga if a in mc]\n",
    "            tcga_substring.sort(key=lambda x: len(x))\n",
    "            # Prefer Basel Annotation\n",
    "            if (\n",
    "                basel_substring and (\n",
    "                    not tcga_substring or\n",
    "                    len(basel_substring[-1]) >= len(tcga_substring[-1])\n",
    "                )\n",
    "            ):\n",
    "                return abbr[basel_substring[-1]]\n",
    "            if tcga_substring:\n",
    "                return tcga[tcga_substring[-1]]\n",
    "            # No proper annotation for \"PITUI\"\n",
    "            if mc == \"PITUI\":\n",
    "                return \"Pituicytoma\"\n",
    "            else:\n",
    "                return \"\"\n",
    "        mc_description = [\n",
    "            description(mc).capitalize() for mc in methylation_classes\n",
    "        ]\n",
    "        return mc_description\n",
    "\n",
    "    def get_annotation(self):\n",
    "        \"\"\"Reads annotation as csv file from disk, and returns is as\n",
    "        pd.DataFrame. If csv is missing or file not up to date, annotation\n",
    "        is read from original excel file (slow) and csv file is written to\n",
    "        disk.\n",
    "        \"\"\"\n",
    "        path_csv = os.path.join(ANNOTATIONS, self.name + \".csv\")\n",
    "        path_xlsx = os.path.join(ANNOTATIONS, self.name + \".xlsx\")\n",
    "        if not os.path.exists(path_csv):\n",
    "            csv_exists_and_up_to_date = False\n",
    "        else:\n",
    "            csv_exists_and_up_to_date = (\n",
    "                os.path.getmtime(path_csv) > os.path.getmtime(path_xlsx)\n",
    "            )\n",
    "        if csv_exists_and_up_to_date:\n",
    "            return pd.read_csv(path_csv)\n",
    "        annotation = pd.read_excel(\n",
    "            path_xlsx,\n",
    "            header=None,\n",
    "            names=[\"id\", \"methylation_class\", \"custom_text\"],\n",
    "        )\n",
    "        annotation.to_csv(path_csv, index=False)\n",
    "        return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15750654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceGenome:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.chrom = pd.read_csv(CHROMOSOMES,\n",
    "                                 delimiter=\"\\t\",\n",
    "                                 index_col=False)\n",
    "        self.chrom[\"offset\"] = [0] + np.cumsum(self.chrom[\"len\"]).tolist()[:-1]\n",
    "        self.chrom[\"center\"] = self.chrom[\"offset\"] + self.chrom[\"len\"]//2\n",
    "        self.chrom[\"centromere_offset\"] = (self.chrom[\"offset\"]\n",
    "            + (self.chrom[\"centromere_start\"] + self.chrom[\"centromere_end\"])//2)\n",
    "        self.length = (self.chrom[\"offset\"].iloc[-1]\n",
    "                     + self.chrom[\"len\"].iloc[-1])\n",
    "        if not os.path.exists(GENES):\n",
    "            self.write_genes_csv()\n",
    "        self.set_genes()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self.chrom.itertuples()\n",
    "\n",
    "    def set_genes(self):\n",
    "        \"\"\"Read and set genes from csv file.\"\"\"\n",
    "        self.genes = pd.read_csv(\n",
    "            GENES,\n",
    "            delimiter=\"\\t\",\n",
    "        )\n",
    "\n",
    "    def write_genes_csv(self):\n",
    "        \"\"\"Write csv gene list with one selected transcript per gene.\"\"\"\n",
    "        genes = pd.read_csv(\n",
    "            GENES_RAW,\n",
    "            delimiter=\"\\t\",\n",
    "            names=[\"seqname\", \"source\", \"feature\", \"start\", \"end\",\n",
    "                   \"score\", \"strand\", \"frame\", \"attribute\"],\n",
    "            usecols=[\"seqname\", \"feature\", \"start\", \"end\", \"attribute\"]\n",
    "        )\n",
    "        genes = genes.loc[\n",
    "            (genes[\"feature\"] == \"transcript\")\n",
    "            & (genes[\"seqname\"].isin(self.chrom.name))\n",
    "        ]\n",
    "        genes[\"name\"] = genes.attribute.apply(\n",
    "            lambda x: re.search('gene_name(.*)\"(.*)\"', x).group(2)\n",
    "        )\n",
    "        genes[\"transcript\"] = genes.attribute.apply(\n",
    "            lambda x: re.search(\n",
    "                'transcript_id(.*)\"(.*)\"(.*)gene_name(.*)', x\n",
    "                ).group(2)\n",
    "        )\n",
    "        genes = genes.drop_duplicates(subset=[\"name\", \"seqname\"], keep=\"first\")\n",
    "        genes = genes.sort_values(\"name\")\n",
    "        genes[\"loc\"] = genes.apply(\n",
    "            lambda z: (\n",
    "                  z[\"seqname\"]\n",
    "                + \":\"\n",
    "                + \"{:,}\".format(z[\"start\"])\n",
    "                + \"-\"\n",
    "                + \"{:,}\".format(z[\"end\"])\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "        # Make data comapitle with pythonic notation\n",
    "        genes[\"end\"] += 1\n",
    "        offset = {i.name:i.offset for i in self}\n",
    "        genes[\"start\"] = genes.apply(\n",
    "            lambda z: offset[z[\"seqname\"]] + z[\"start\"],\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"end\"] = genes.apply(\n",
    "            lambda z: offset[z[\"seqname\"]] + z[\"end\"],\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"midpoint\"] = (genes[\"start\"] + genes[\"end\"]) // 2\n",
    "        with open(RELEVANT_GENES, \"r\") as f:\n",
    "            relevant_genes = f.read().splitlines()\n",
    "        genes[\"relevant\"] = genes.name.apply(lambda x: x in relevant_genes)\n",
    "        genes[\"len\"] = genes[\"end\"] - genes[\"start\"]\n",
    "        genes[[\"name\", \"seqname\", \"start\", \"end\",\n",
    "               \"len\", \"midpoint\", \"relevant\", \"transcript\",\n",
    "               \"loc\",\n",
    "        ]].to_csv(GENES, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleData:\n",
    "    \"\"\"Container of sample data.\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.cpg_sites = SampleData.get_read_cpgs(name)\n",
    "        self.cpg_overlap = None\n",
    "        self.cpg_overlap_index = None\n",
    "        self.reads = None\n",
    "\n",
    "    def set_reads(self):\n",
    "        \"\"\"Calculate all read start and end positions.\"\"\"\n",
    "        genome = ReferenceGenome()\n",
    "        bam_files = []\n",
    "        sample_path = os.path.join(NANODIP_OUTPUT, self.name)\n",
    "        for root, _, files in os.walk(sample_path):\n",
    "            bam_files.extend(\n",
    "                [os.path.join(root, f)\n",
    "                for f in files if f.endswith(\".bam\")]\n",
    "            )\n",
    "        read_positions = []\n",
    "        for f in bam_files:\n",
    "            samfile = pysam.AlignmentFile(f, \"rb\")\n",
    "            for chrom in genome:\n",
    "                for read in samfile.fetch(chrom.name):\n",
    "                    read_positions.append([\n",
    "                        read.reference_start + chrom.offset,\n",
    "                        # reference_end equals first position after alignment\n",
    "                        # consistent with python notations.\n",
    "                        read.reference_end + chrom.offset,\n",
    "                    ])\n",
    "                    assert (read.reference_length != 0), \"Empty read\"\n",
    "        self.reads = read_positions\n",
    "\n",
    "    def get_read_cpgs(name):\n",
    "        \"\"\"Get all Ilumina methylation sites with methylaton status\n",
    "        within a samples reads.\n",
    "\n",
    "        Args:\n",
    "            name: sample name to be analysed\n",
    "\n",
    "        Returns:\n",
    "            Pandas Data Frame containing the reads Ilumina cpg_sites and\n",
    "            methylation status.\n",
    "        \"\"\"\n",
    "\n",
    "        sample_path = os.path.join(NANODIP_OUTPUT, name)\n",
    "\n",
    "        if not os.path.exists(sample_path):\n",
    "            raise FileNotFoundError(sample_path)\n",
    "\n",
    "        cpg_files = []\n",
    "        for root, _, files in os.walk(sample_path):\n",
    "            cpg_files.extend(\n",
    "                [os.path.join(root, f)\n",
    "                for f in files if f.endswith(\"methoverlap.tsv\")]\n",
    "            )\n",
    "\n",
    "        methylation_info = pd.DataFrame()\n",
    "\n",
    "        for f in cpg_files:\n",
    "            # Some fast5 files do not contain any CpGs.\n",
    "            try:\n",
    "                cpgs = pd.read_csv(f, delimiter=\"\\t\", header=None,\n",
    "                                   names=[\"cpg_site\", \"methylation\"])\n",
    "                methylation_info = methylation_info.append(cpgs)\n",
    "            except FileNotFoundError:\n",
    "                logger.exception(\"empty file encountered, skipping\")\n",
    "\n",
    "        return methylation_info\n",
    "\n",
    "    def set_cpg_overlap(self, reference):\n",
    "        \"\"\"Calculate CpG overlap data between sample and reference.\n",
    "\n",
    "        Some probes have been skipped from the reference set, e.g. sex\n",
    "        chromosomes.\n",
    "        \"\"\" #TODO is this true?\n",
    "        self.cpg_overlap = set(self.cpg_sites[\"cpg_site\"]).intersection(\n",
    "            reference.cpg_sites.keys())\n",
    "\n",
    "        self.cpg_overlap_index = [reference.cpg_sites[f]\n",
    "            for f in self.cpg_overlap]\n",
    "        self.cpg_overlap_index.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d42439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_reference_methylation(reference_index, cpg_index):\n",
    "    \"\"\"Extract and return methylation information matrix from reference data.\n",
    "\n",
    "    Args:\n",
    "        reference_index: Index of references to extract from reference\n",
    "            data.\n",
    "        cpg_index: Index of CpG's to extract from CpG data.\n",
    "\n",
    "    Returns:\n",
    "        Numpy array matrix containing submatrix of reference data\n",
    "        with rows=reference_index and columns=cpg_index.\n",
    "    \"\"\"\n",
    "\n",
    "    make_binary_reference_data_if_needed()\n",
    "    shape = [len(reference_index), len(cpg_index)]\n",
    "    delta_offset = np.diff(reference_index, prepend=-1) - 1\n",
    "    reference_matrix = np.empty(shape, dtype=bool)\n",
    "\n",
    "    with open(REFERENCE_METHYLATION_SHAPE, \"r\") as f:\n",
    "        number_of_cpgs = [int(s) for s in f.read().splitlines()][1]\n",
    "\n",
    "    with open(REFERENCE_METHYLATION, \"rb\") as f:\n",
    "        for i, d in enumerate(delta_offset):\n",
    "            reference_matrix[i] = np.fromfile(\n",
    "                f, dtype=bool, offset=d*number_of_cpgs, count=number_of_cpgs\n",
    "            )[cpg_index]\n",
    "    return reference_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_methylation(sample, reference):\n",
    "    \"\"\"Extract and return methylation information matrix from overlap of sample\n",
    "    CpG's with annotated reference data.\n",
    "    \"\"\"\n",
    "\n",
    "    reference_index = reference.annotated_specimens_index\n",
    "    cpg_index = sample.cpg_overlap_index\n",
    "    result = _get_reference_methylation(reference_index, cpg_index)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fcf10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_methylation(sample, reference):\n",
    "    \"\"\"Calculate sample methylation info from reads.\n",
    "\n",
    "    Args:\n",
    "        sample: Sample data set.\n",
    "        reference: Reference data set.\n",
    "        cpg_ovelrap: Set containing intersection of cpg sites in cpg_sample\n",
    "            and reference_cpg_site.\n",
    "    Returns:\n",
    "        Numpy array containing sample Methylation information.\n",
    "    \"\"\"\n",
    "\n",
    "    sample_methylation = np.full(len(reference.cpg_sites), 0, dtype=bool)\n",
    "    sample_mean_methylation = sample.cpg_sites.groupby(\n",
    "        \"cpg_site\",\n",
    "        as_index=False).mean()\n",
    "\n",
    "    for _, row in sample_mean_methylation.iterrows():\n",
    "        cpg = row[\"cpg_site\"]\n",
    "        if cpg in sample.cpg_overlap:\n",
    "            i = reference.cpg_sites[cpg]\n",
    "            sample_methylation[i] = row[\"methylation\"] > \\\n",
    "                                    METHYLATION_CUTOFF\n",
    "    sample_methylation = sample_methylation[sample.cpg_overlap_index]\n",
    "    return sample_methylation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9c02d",
   "metadata": {},
   "source": [
    "\n",
    "    nanodip.plots\n",
    "    -------------\n",
    "\n",
    "    Create Methylation UMAP plot.\n",
    "    Create Copy Number Variation plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_plot_from_data(sample, reference, umap_data_frame, close_up):\n",
    "    \"\"\"Create and return umap plot from UMAP data.\n",
    "\n",
    "    Args:\n",
    "        sample: sample data\n",
    "        reference: reference data\n",
    "        umap_data_frame: pandas data frame containing umap info. First\n",
    "            row corresponds to sample.\n",
    "        close_up: bool to indicate if only top matches should be plotted.\n",
    "    \"\"\"\n",
    "    umap_sample = umap_data_frame.iloc[0]\n",
    "    umap_title = f\"UMAP for {sample.name} against {reference.name}, \"\\\n",
    "        + f\"{len(reference.annotated_specimens)} reference cases, \"\\\n",
    "        + f\"{len(sample.cpg_overlap)} CpGs\"\n",
    "    if close_up:\n",
    "        umap_title = \"Close-up \" + umap_title\n",
    "    umap_plot = px.scatter(\n",
    "        umap_data_frame,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        labels={\"x\":\"UMAP 0\", \"y\":\"UMAP 1\", \"color\":\"WHO class\"},\n",
    "        title=umap_title,\n",
    "        color=\"methylation_class\",\n",
    "        hover_name=\"id\",\n",
    "        hover_data=[\"description\"],\n",
    "        render_mode=PLOTLY_RENDER_MODE,\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "    umap_plot.add_annotation(\n",
    "        x=umap_sample[\"x\"],\n",
    "        y=umap_sample[\"y\"],\n",
    "        text=sample.name,\n",
    "        showarrow=True,\n",
    "        arrowhead=1,\n",
    "    )\n",
    "    umap_plot.update_yaxes(\n",
    "        scaleanchor = \"x\",\n",
    "        scaleratio = 1,\n",
    "        mirror=True,\n",
    "    )\n",
    "    umap_plot.update_xaxes(\n",
    "        mirror=True,\n",
    "    )\n",
    "\n",
    "    # If close-up add hyperlinks for all references and draw circle\n",
    "    if close_up:\n",
    "        umap_plot.update_traces(marker=dict(size=5))\n",
    "        # Add hyperlinks\n",
    "        for _, row in umap_data_frame.iloc[1:].iterrows():\n",
    "            umap_plot.add_annotation(\n",
    "                x=row[\"x\"],\n",
    "                y=row[\"y\"],\n",
    "                text=\"<a href='\" + CNV_URL_PREFIX + row[\"id\"]\n",
    "                    + CNV_URL_SUFFIX\n",
    "                    + \"' target='_blank'>&nbsp;</a>\",\n",
    "                showarrow=False,\n",
    "                arrowhead=1,\n",
    "            )\n",
    "        # Draw circle\n",
    "        radius = umap_data_frame[\"distance\"].iloc[-1]\n",
    "        umap_plot.add_shape(\n",
    "            type=\"circle\",\n",
    "            x0=umap_sample[\"x\"] - radius,\n",
    "            y0=umap_sample[\"y\"] - radius,\n",
    "            x1=umap_sample[\"x\"] + radius,\n",
    "            y1=umap_sample[\"y\"] + radius,\n",
    "            line_color=\"black\",\n",
    "            line_width=0.5,\n",
    "        )\n",
    "    return umap_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0caa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_data_frame(sample, reference):\n",
    "    \"\"\"Create UMAP methylation analysis matrix.\n",
    "\n",
    "    Args:\n",
    "        sample: sample to analyse\n",
    "        reference: reference data\n",
    "    \"\"\"\n",
    "    import umap #TODO move to beginning\n",
    "\n",
    "    logger.info(\n",
    "        f\"UMAP Plot initiated for {sample.name} and reference {reference.name}.\"\n",
    "    )\n",
    "    logger.info(f\"Reference Annotation:\\n{reference.annotation}\")\n",
    "    logger.info(f\"Reference CpG Sites No:\\n{len(reference.cpg_sites)}\")\n",
    "    logger.info(f\"Reference Specimens No:\\n{len(reference.specimens)}\")\n",
    "    logger.info(\n",
    "        f\"Reference Annotated specimens: {len(reference.annotated_specimens)}\"\n",
    "    )\n",
    "    logger.info(f\"Sample CpG Sites No:\\n{len(sample.cpg_sites)}\")\n",
    "    logger.info(f\"Sample CpG overlap No before:\\n{sample.cpg_overlap}\")\n",
    "\n",
    "    # Calculate overlap of sample CpG's with reference CpG's (some probes have\n",
    "    # been skipped from the reference set, e.g. sex chromosomes).\n",
    "    sample.set_cpg_overlap(reference)\n",
    "    logger.info(f\"Sample read. CpG overlap No after:\\n{len(sample.cpg_overlap)}\")\n",
    "\n",
    "    if not sample.cpg_overlap:\n",
    "        logger.info(\"UMAP done. No Matrix created, no overlapping data.\")\n",
    "        raise ValueError(\"Sample has no overlapping CpG's with reference.\")\n",
    "\n",
    "    # Extract reference and sample methylation according to CpG overlap.\n",
    "    reference_methylation = get_reference_methylation(sample,\n",
    "                                                      reference)\n",
    "    logger.info(f\"\"\"Reference methylation extracted:\n",
    "                {reference_methylation}\"\"\")\n",
    "    sample_methylation = get_sample_methylation(sample, reference)\n",
    "    logger.info(f\"\"\"Sample methylation extracted:\n",
    "                {sample_methylation}\"\"\")\n",
    "    logger.info(\"UMAP algorithm initiated.\")\n",
    "\n",
    "    # Calculate UMAP Nx2 Matrix. Time intensive (~1min).\n",
    "    methyl_overlap = np.vstack([sample_methylation, reference_methylation])\n",
    "    umap_2d = umap.UMAP(verbose=True).fit_transform(methyl_overlap)\n",
    "\n",
    "    # Free memory\n",
    "    del reference_methylation\n",
    "    del sample_methylation\n",
    "\n",
    "    logger.info(\"UMAP algorithm done.\")\n",
    "\n",
    "    umap_sample = umap_2d[0]\n",
    "    umap_df = pd.DataFrame({\n",
    "        \"distance\": [np.linalg.norm(z - umap_sample) for z in umap_2d],\n",
    "        \"methylation_class\":  [sample.name] + reference.methylation_class,\n",
    "        \"description\":  [\"undetermined\"] + reference.description,\n",
    "        \"id\": [sample.name] + reference.specimen_ids,\n",
    "        \"x\": umap_2d[:,0],\n",
    "        \"y\": umap_2d[:,1],\n",
    "    })\n",
    "\n",
    "    logger.info(\"UMAP done. Matrix created.\")\n",
    "\n",
    "    return (methyl_overlap, umap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_edges(n_bins, genome):\n",
    "    \"\"\"Returns sequence of {n_bin} equal sized bins on chromosomes. Every bin is\n",
    "    limited to one chromosome.\"\"\"\n",
    "    if n_bins < 100:\n",
    "        raise ValueError(\"Binwidth too small.\")\n",
    "    edges = np.linspace(0, genome.length, num=n_bins + 1).astype(int)\n",
    "    # limit bins to only one chromosome\n",
    "    for chrom_edge in genome.chrom.offset:\n",
    "        i_nearest = np.abs(edges - chrom_edge).argmin()\n",
    "        edges[i_nearest] = chrom_edge\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnv(read_positions, genome):\n",
    "    \"\"\"Return CNV.\"\"\"\n",
    "    expected_reads_per_bin = 30\n",
    "    n_bins = len(read_positions)//expected_reads_per_bin\n",
    "    read_start_positions = [i[0] for i in read_positions]\n",
    "\n",
    "    copy_numbers, bin_edges = np.histogram(\n",
    "        read_start_positions, bins=get_bin_edges(n_bins, genome), range=[0, genome.length]\n",
    "    )\n",
    "\n",
    "    bin_midpoints = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "    expected_reads = np.diff(bin_edges) * len(read_positions) / genome.length\n",
    "    cnv = [(x - e)/e for x, e in zip(copy_numbers, expected_reads)]\n",
    "    return bin_midpoints, copy_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78284569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnv_grid(genome):\n",
    "    \"\"\"Makes chromosome grid layout for CNV Plot and saves it on disk. If \n",
    "    available grid is read from disk.\n",
    "    \"\"\"\n",
    "    # Check if grid exists and return if available.\n",
    "    grid_path = CNV_GRID\n",
    "    if os.path.exists(grid_path):\n",
    "        with open(grid_path, \"r\") as f:\n",
    "            grid = from_json(f.read())\n",
    "        return grid\n",
    "        \n",
    "    grid = go.Figure()\n",
    "    grid.update_layout(\n",
    "        coloraxis_showscale=False,\n",
    "        xaxis = dict(\n",
    "            linecolor=\"black\",\n",
    "            linewidth=1,\n",
    "            mirror=True,\n",
    "            range=[0, genome.length],\n",
    "            showgrid=False,\n",
    "            ticklen=10,\n",
    "            tickmode=\"array\",\n",
    "            ticks=\"outside\",\n",
    "            tickson=\"boundaries\",\n",
    "            ticktext=genome.chrom.name,\n",
    "            tickvals=genome.chrom.center,\n",
    "            zeroline=False,\n",
    "        ),\n",
    "        yaxis = dict(\n",
    "            linecolor=\"black\",\n",
    "            linewidth=1,\n",
    "            mirror=True,\n",
    "            showline=True,\n",
    "        ),\n",
    "        width=1700,\n",
    "        height=900,\n",
    "        template=\"simple_white\",\n",
    "    )\n",
    "    # Vertical line: centromere.\n",
    "    for i in genome.chrom.centromere_offset:\n",
    "        grid.add_vline(x=i, line_color=\"black\",\n",
    "                           line_dash=\"dot\", line_width=1)\n",
    "    # Vertical line: shromosomes.\n",
    "    for i in genome.chrom.offset.tolist() + [genome.length]:\n",
    "        grid.add_vline(x=i, line_color=\"black\", line_width=1)\n",
    "    # Save to disk\n",
    "    grid.write_json(grid_path)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea671f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnv_plot_from_data(data_x, data_y, E_y, sample_name, read_num, genome):\n",
    "    \"\"\"Create CNV plot from CNV data.\n",
    "\n",
    "    Args:\n",
    "        data_x: x-Values to plot.\n",
    "        data_y: y-Values to plot.\n",
    "        E_y: expected y-Value.\n",
    "        sample_name: Name of sample.\n",
    "        read_num: Number of read reads.\n",
    "        genome: Reference Genome.\n",
    "    \"\"\"\n",
    "    grid = cnv_grid(genome)\n",
    "    # Expected value: horizontal line.\n",
    "    grid.add_hline(y=E_y, line_color=\"black\", line_width=1)\n",
    "    cnv_plot = px.scatter(\n",
    "        x=data_x,\n",
    "        y=data_y,\n",
    "        labels={\n",
    "            \"x\":f\"Number of mapped reads: {read_num}\",\n",
    "            \"y\":f\"Copy numbers per {round(genome.length/(len(data_x) * 1e6), 2)} MB\"\n",
    "        },\n",
    "        title=f\"Sample ID: {sample_name}\",\n",
    "        color=data_y,\n",
    "        range_color=[E_y*0, E_y*2],\n",
    "        color_continuous_scale=\"Portland\",\n",
    "        render_mode=PLOTLY_RENDER_MODE,\n",
    "    )\n",
    "    cnv_plot.update_traces(\n",
    "        hovertemplate=\"Copy Numbers = %{y} <br>\",\n",
    "    )\n",
    "    cnv_plot.update_layout(\n",
    "        grid.layout,\n",
    "        yaxis_range = [-0.5, 2*E_y],\n",
    "    )\n",
    "    return cnv_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1f37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_reads(read_start_pos, interval):\n",
    "    \"\"\"Return the number of starting sequences whithin interval. Reads must\n",
    "    be sorted in ascending order.\"\"\"\n",
    "    left, right = interval\n",
    "    i_left = bisect.bisect_left(read_start_pos, left)\n",
    "    i_right = bisect.bisect_left(read_start_pos, right)\n",
    "    return len(read_start_pos[i_left:i_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnv_plot(sample, bin_midpoints, cnv, genome):\n",
    "    \"\"\"Create a genome-wide copy number plot and save data on dist.\"\"\"\n",
    "    logger.info(f\"CNVP start\")\n",
    "    logger.info(f\"Read positions:\\n{sample.reads[:100]}\")\n",
    "\n",
    "    logger.info(f\"Bin midpoints:\\n{bin_midpoints}\")\n",
    "    logger.info(f\"CNV:\\n{cnv}\")\n",
    "\n",
    "    avg_read_per_bin = len(sample.reads) // len(bin_midpoints)\n",
    "\n",
    "    cnv_plot = cnv_plot_from_data(\n",
    "        data_x=bin_midpoints,\n",
    "        data_y=cnv,\n",
    "        E_y = avg_read_per_bin,\n",
    "        sample_name=sample.name,\n",
    "        read_num=len(sample.reads),\n",
    "        genome=genome,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"CNVP done\")\n",
    "    return cnv_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMAPData:\n",
    "    \"\"\"Umap data container and methods for invoking umap plot algorithm.\"\"\"\n",
    "    def __init__(self, sample_name, reference_name):\n",
    "        self.sample_name = sample_name\n",
    "        self.reference_name = reference_name\n",
    "        self.path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            f\"{sample_name}_{reference_name}\",\n",
    "        )\n",
    "\n",
    "    def make_umap_plot(self):\n",
    "        \"\"\"Invoke umap plot algorithm and save to disk.\"\"\"\n",
    "        self.sample = SampleData(self.sample_name)\n",
    "        self.reference = ReferenceData(self.reference_name) # time: 3.6s\n",
    "        self.methyl_overlap, self.umap_df = umap_data_frame(\n",
    "            self.sample, self.reference\n",
    "        )\n",
    "        self.plot = umap_plot_from_data(\n",
    "            self.sample,\n",
    "            self.reference,\n",
    "            self.umap_df,\n",
    "            close_up=False,\n",
    "        )\n",
    "        logger.info(\"UMAP plot generated.\")\n",
    "        self.cu_umap_df = self.umap_df.sort_values(\n",
    "            by=\"distance\"\n",
    "        )[:UMAP_PLOT_TOP_MATCHES + 1]\n",
    "        self.cu_plot = umap_plot_from_data(\n",
    "            self.sample,\n",
    "            self.reference,\n",
    "            self.cu_umap_df,\n",
    "            close_up=True,\n",
    "        )\n",
    "        logger.info(\"UMAP close-up plot generated.\")\n",
    "\n",
    "        # Convert to json.\n",
    "        self.plot_json = self.plot.to_json()\n",
    "        self.cu_plot_json = self.cu_plot.to_json()\n",
    "\n",
    "        self.save_to_disk()\n",
    "\n",
    "    def save_ranking_report(self):\n",
    "        \"\"\"Save pdf containing the nearest neighbours from umap analyis.\"\"\"\n",
    "        rows = [row for _, row in self.cu_umap_df.iterrows()]\n",
    "\n",
    "        html_report = render_template(\"umap_report.html\", rows=rows)\n",
    "\n",
    "        file_path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            \"%s_%s%s\" % (self.sample_name,\n",
    "                         self.reference_name,\n",
    "                         ENDINGS[\"ranking\"],\n",
    "                        ),\n",
    "        )\n",
    "        convert_html_to_pdf(html_report, file_path)\n",
    "\n",
    "        file_path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            \"%s%s\" % (self.sample_name, ENDINGS[\"cpg_cnt\"]),\n",
    "        )\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(\"%s\" % len(self.sample.cpg_overlap))\n",
    "\n",
    "    def save_to_disk(self):\n",
    "        # Save Methylation Matrix.\n",
    "        file_path = os.path.join(NANODIP_REPORTS,\n",
    "            \"%s_%s%s\" % (self.sample_name,\n",
    "                         self.reference_name,\n",
    "                         ENDINGS[\"methyl\"])\n",
    "        )\n",
    "        np.save(file_path, self.methyl_overlap)\n",
    "\n",
    "        # Save UMAP Matrix.\n",
    "        file_path = os.path.join(NANODIP_REPORTS,\n",
    "            \"%s_%s%s\" % (self.sample_name,\n",
    "                         self.reference_name,\n",
    "                         ENDINGS[\"umap_csv\"])\n",
    "        )\n",
    "        self.umap_df.to_csv(file_path, index=False)\n",
    "\n",
    "        # Write UMAP plot to disk.\n",
    "        file_path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            f\"%s_%s%s\" % (self.sample_name, self.reference_name,\n",
    "                          ENDINGS[\"umap_all\"]),\n",
    "        )\n",
    "        self.plot.write_html(file_path, config=dict({\"scrollZoom\": True}))\n",
    "        self.plot.write_json(file_path[:-4] + \"json\")\n",
    "        self.plot.write_image(file_path[:-4] + \"png\") # Time consumption 1.8s\n",
    "\n",
    "        # Write UMAP close-up plot to disk.\n",
    "        file_path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            f\"%s_%s%s\" % (self.sample_name, self.reference_name,\n",
    "                          ENDINGS[\"umap_top\"]),\n",
    "        )\n",
    "        self.cu_plot.write_html(file_path, config=dict({\"scrollZoom\": True}))\n",
    "        self.cu_plot.write_json(file_path[:-4] + \"json\")\n",
    "        self.cu_plot.write_image(file_path[:-4] + \"png\") # Time consumption 0.9s\n",
    "\n",
    "        # Save close up ranking report.\n",
    "        self.save_ranking_report() # Time consumption 0.4s\n",
    "\n",
    "\n",
    "    def files_on_disk(self):\n",
    "        methyl_overlap_path = os.path.join(NANODIP_REPORTS,\n",
    "            \"%s_%s%s\" % (self.sample_name,\n",
    "                         self.reference_name,\n",
    "                         ENDINGS[\"methyl\"])\n",
    "        )\n",
    "        plot_path = self.path + ENDINGS[\"umap_all_json\"]\n",
    "        cu_plot_path = self.path + ENDINGS[\"umap_top_json\"]\n",
    "\n",
    "        return (os.path.exists(plot_path) and\n",
    "                os.path.exists(cu_plot_path) and\n",
    "                os.path.exists(methyl_overlap_path))\n",
    "\n",
    "    def read_from_disk(self):\n",
    "        methyl_overlap_path = os.path.join(NANODIP_REPORTS,\n",
    "            \"%s_%s%s\" % (self.sample_name,\n",
    "                         self.reference_name,\n",
    "                         ENDINGS[\"methyl\"])\n",
    "        )\n",
    "        plot_path = self.path + ENDINGS[\"umap_all_json\"]\n",
    "        cu_plot_path = self.path + ENDINGS[\"umap_top_json\"]\n",
    "\n",
    "        # Read UMAP plot as json.\n",
    "        with open(plot_path, \"r\") as f:\n",
    "            self.plot_json = f.read()\n",
    "        #self.plot = from_json(self.plot_json)\n",
    "\n",
    "        # Read UMAP close-up plot as json.\n",
    "        with open(cu_plot_path, \"r\") as f:\n",
    "            self.cu_plot_json = f.read()\n",
    "        #self.cu_plot = from_json(self.cu_plot_json)\n",
    "\n",
    "        # Read Methylation Matrix.\n",
    "        self.methyl_overlap = np.load(methyl_overlap_path,\n",
    "            allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51439e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TODO():\n",
    "    path = umap_output_path(sample, reference, close_up=True)\n",
    "    with open(path[\"html\"], \"w\") as f:\n",
    "        f.write(\"<html><body>No data to plot.</body></html>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNVData:\n",
    "    \"\"\"CNV data container and methods for invoking cnv plot algorithm.\"\"\"\n",
    "    genome = ReferenceGenome()\n",
    "    def __init__(self, sample_name):\n",
    "        self.sample_name = sample_name\n",
    "        self.path = os.path.join(NANODIP_REPORTS, f\"{sample_name}\")\n",
    "\n",
    "    def read_from_disk(self):\n",
    "        plot_path = self.path + ENDINGS[\"cnv_json\"]\n",
    "        genes_path = self.path + ENDINGS[\"genes\"]\n",
    "        with open(plot_path, \"r\") as f:\n",
    "            self.plot_json = f.read()\n",
    "        self.plot = from_json(self.plot_json)\n",
    "        self.genes = pd.read_csv(genes_path)\n",
    "\n",
    "    def files_on_disk(self):\n",
    "        plot_path = self.path + ENDINGS[\"cnv_json\"]\n",
    "        genes_path = self.path + ENDINGS[\"genes\"]\n",
    "        return (\n",
    "            os.path.exists(plot_path) and \n",
    "            os.path.exists(genes_path)\n",
    "        )\n",
    "\n",
    "    def make_cnv_plot(self):\n",
    "        self.sample = SampleData(self.sample_name)\n",
    "        self.sample.set_reads() # time consumption 2.5s\n",
    "        self.bin_midpoints, self.cnv = get_cnv(\n",
    "            self.sample.reads,\n",
    "            CNVData.genome,\n",
    "        )\n",
    "        self.plot = get_cnv_plot(\n",
    "            sample=self.sample,\n",
    "            bin_midpoints=self.bin_midpoints,\n",
    "            cnv=self.cnv,\n",
    "            genome=CNVData.genome,\n",
    "        )\n",
    "        self.plot_json = self.plot.to_json()\n",
    "        self.genes = self.gene_cnv(\n",
    "            CNVData.genome.length // len(self.bin_midpoints)\n",
    "        )\n",
    "        self.relevant_genes = self.genes.loc[self.genes.relevant]\n",
    "        self.save_to_disk()\n",
    "\n",
    "    def save_to_disk(self):\n",
    "        self.plot.write_html(\n",
    "            self.path + ENDINGS[\"cnv_html\"],\n",
    "            config=dict({\"scrollZoom\": True}),\n",
    "        )\n",
    "        write_json(self.plot, self.path + ENDINGS[\"cnv_json\"])\n",
    "        if not os.path.exists(self.path + ENDINGS[\"cnv_png\"]):\n",
    "            # time consuming operation (1.96s)\n",
    "            self.plot.write_image(\n",
    "                self.path + ENDINGS[\"cnv_png\"], width=1280, height=720\n",
    "            )\n",
    "        with open(self.path + ENDINGS[\"aligned_reads\"], \"w\") as f:\n",
    "            f.write(\"%s\" % len(self.sample.reads))\n",
    "        with open(self.path + ENDINGS[\"reads_csv\"], \"w\") as f:\n",
    "            write = csv.writer(f)\n",
    "            write.writerows(self.sample.reads)\n",
    "        self.genes.to_csv(self.path + ENDINGS[\"genes\"], index=False)\n",
    "        self.relevant_genes.to_csv(\n",
    "            self.path + ENDINGS[\"relevant_genes\"],\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    def gene_cnv(self, bin_width):\n",
    "        genes = CNVData.genome.genes\n",
    "        genes[\"interval\"] = list(zip(genes.start, genes.end))\n",
    "        read_start_pos = [i[0] for i in self.sample.reads]\n",
    "        read_start_pos.sort()\n",
    "        num_reads = len(read_start_pos)\n",
    "        genes[\"cn_obs\"] = genes.interval.apply(\n",
    "            lambda z: number_of_reads(read_start_pos, z)\n",
    "        )\n",
    "        genes[\"cn_norm\"] = genes.apply(\n",
    "            lambda z: z[\"cn_obs\"]/z[\"len\"] * bin_width, # TODO exp/norm not compatible\n",
    "            axis=1,\n",
    "        )\n",
    "        genes[\"cn_exp\"] = genes.apply(\n",
    "            lambda z: len(self.sample.reads)*z[\"len\"]/CNVData.genome.length,\n",
    "            axis=1,\n",
    "        )\n",
    "        genes = genes.sort_values(by=\"cn_obs\", ascending=False)\n",
    "        return genes\n",
    "\n",
    "    def get_gene_positions(self, genes):\n",
    "        gene_pos = self.genes.loc[self.genes.name.isin(genes)]\n",
    "        return gene_pos\n",
    "\n",
    "    def plot_cnv_and_genes(self, gene_names):\n",
    "        genes = self.get_gene_positions(gene_names)\n",
    "        plot = go.Figure(self.plot)\n",
    "        plot.add_trace(\n",
    "            go.Scatter(\n",
    "                customdata=genes[[\n",
    "                    \"name\",          # 0\n",
    "                    \"loc\",           # 1\n",
    "                    \"transcript\",    # 2\n",
    "                    \"len\",           # 3\n",
    "                ]],\n",
    "                hovertemplate=(\n",
    "                    \"Copy numbers = %{y} <br>\"\n",
    "                    \"<b> %{customdata[0]} </b> <br>\"\n",
    "                    \"%{customdata[1]} \"\n",
    "                    \"(hg19 %{customdata[2]}) <br>\"\n",
    "                    \"%{customdata[3]} bases <br>\"\n",
    "                ),\n",
    "                name=\"\",\n",
    "                marker_color=\"rgba(0,0,0,1)\",\n",
    "                mode=\"markers+text\",\n",
    "                marker_symbol=\"diamond\",\n",
    "                textfont_color=\"rgba(0,0,0,1)\",\n",
    "                showlegend=False,\n",
    "                text=genes.name,\n",
    "                textposition=\"top center\",\n",
    "                x=genes.midpoint,\n",
    "                y=genes.cn_obs,\n",
    "            ))\n",
    "        return plot.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc588df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and cofigure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(levelname)s %(asctime)s %(lineno)d - %(message)s\")\n",
    "file_handler = logging.FileHandler(\n",
    "    os.path.join(NANODIP_REPORTS, \"nanodip.log\"),\n",
    "    \"w\",\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## output to console\n",
    "# stream_handler = logging.StreamHandler()\n",
    "# logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa2662",
   "metadata": {},
   "source": [
    "\n",
    "# No user editable code below\n",
    "Do not modify the cells below unless you would like to patch errors or create\n",
    "something new.\n",
    "\n",
    "## Sections\n",
    "1. Generic Functions\n",
    "2. MinKNOW API Functions\n",
    "3. CNV Plotter\n",
    "4. UMAP Methylation Plotter\n",
    "5. User Interface Functions\n",
    "6. Report Generator\n",
    "7. CherryPy Web UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a2382",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Generic Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b57fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logpr(v,logstring): # logging funcion that reads verbosity parameter\n",
    "    if v==1:\n",
    "        print(str(datetime.datetime.now())+\": \"+str(logstring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs():\n",
    "    \"\"\"Return list of run folders from MinKNOW data directory sorted by\n",
    "    modification time.\"\"\"\n",
    "    runs = []\n",
    "    for f in os.listdir(DATA):\n",
    "        if f not in EXCLUDED_FROM_ANALYSIS:\n",
    "            file_path = os.path.join(DATA, f)\n",
    "            mod_time = os.path.getmtime(file_path)\n",
    "            if os.path.isdir(file_path):\n",
    "                runs.append([f, mod_time])\n",
    "    # sort based on modif. date\n",
    "    runs.sort(key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    # Remove date after sorting\n",
    "    return [x[0] for x in runs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbcd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predominant_barcode(sample_name):\n",
    "    \"\"\"Returns the predominante barcode within all fast5 files.\"\"\"\n",
    "    fast5_files = []\n",
    "    for root, _, files in os.walk(os.path.join(DATA, sample_name)):\n",
    "        fast5_files.extend(\n",
    "            [os.path.join(root, f) for f in files if f.endswith(\".fast5\")]\n",
    "        )\n",
    "    barcode_hits=[]\n",
    "    for barcode in BARCODE_NAMES:\n",
    "        barcode_hits.append(\n",
    "            len([f for f in fast5_files if barcode in f])\n",
    "        )\n",
    "    max_barcode = max(barcode_hits)\n",
    "    if max_barcode > 1:\n",
    "        predominant_barcode = BARCODE_NAMES[barcode_hits.index(max_barcode)]\n",
    "    else:\n",
    "        predominant_barcode = \"undetermined\"\n",
    "    return predominant_barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference_annotations():\n",
    "    \"\"\"Return list of all reference annotation files (MS Excel XLSX format).\"\"\"\n",
    "    annotations = []\n",
    "    for r in os.listdir(ANNOTATIONS):\n",
    "        if r.endswith(\".xlsx\"):\n",
    "            annotations.append(r)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO del\n",
    "# write the filename of the UMAP reference for the\n",
    "def writeReferenceDefinition(sampleId,referenceFile):\n",
    "    # current run into a text file\n",
    "    with open(NANODIP_REPORTS+'/'+sampleId+'_selected_reference.txt', 'w') as f:\n",
    "        f.write(referenceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_reference_name(sample_id,reference_name):\n",
    "    \"\"\"Write the filename of the UMAP reference for the current run into\n",
    "    a text file.\"\"\"\n",
    "    path = os.path.join(\n",
    "        NANODIP_REPORTS, sample_id + \"_selected_reference.txt\"\n",
    "    )\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(reference_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6708011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readReferenceDefinition(sampleId): # read the filename of the UMAP reference for the current sample\n",
    "    try:\n",
    "        with open(NANODIP_REPORTS+'/'+sampleId+'_selected_reference.txt', 'r') as f:\n",
    "            referenceFile=f.read()\n",
    "    except:\n",
    "        referenceFile=\"\"\n",
    "    return referenceFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRunTmpFile(sampleId,deviceId):\n",
    "    # current run into a text file\n",
    "    with open(NANODIP_REPORTS+'/'+sampleId+'_'+deviceId+'_runinfo.tmp', 'a') as f:\n",
    "        try:\n",
    "            runId=getActiveRun(deviceId)\n",
    "        except:\n",
    "            runId=\"none\"\n",
    "        ro=getThisRunOutput(deviceId,sampleId,runId)\n",
    "        readCount=ro[0]\n",
    "        bascalledBases=ro[1]\n",
    "        overlapCpGs=getOverlapCpGs(sampleId)\n",
    "        f.write(str(int(time.time()))+\"\\t\"+\n",
    "                str(readCount)+\"\\t\"+\n",
    "                str(bascalledBases)+\"\\t\"+\n",
    "                str(overlapCpGs)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRunTmpFile(sampleId):\n",
    "    print(\"readRunTmpFile not ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0640db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverlapCpGs(sampleName):\n",
    "    methoverlapPath=NANODIP_OUTPUT+\"/\"+sampleName # collect matching CpGs from sample\n",
    "    methoverlapTsvFiles=[] # find all *methoverlap.tsv files\n",
    "    for root, dirnames, filenames in os.walk(methoverlapPath):\n",
    "        for filename in fnmatch.filter(filenames, '*methoverlap.tsv'):\n",
    "            methoverlapTsvFiles.append(os.path.join(root, filename))\n",
    "    methoverlap=[]\n",
    "    first=True\n",
    "    for f in methoverlapTsvFiles:\n",
    "        try: # some fast5 files do not contain any CpGs\n",
    "            m=pd.read_csv(f, delimiter='\\t', header=None, index_col=0)\n",
    "            if first:\n",
    "                methoverlap=m\n",
    "                first=False\n",
    "            else:\n",
    "                methoverlap=methoverlap.append(m)\n",
    "        except:\n",
    "            logpr(VERBOSITY,\"empty file encountered, skipping\")\n",
    "    return len(methoverlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bde74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f5cOneFast5(sampleId,analyzeOne=True):\n",
    "    analyzedCount=0\n",
    "    thisRunDir=DATA+\"/\"+sampleId\n",
    "    pattern = '*.fast5'\n",
    "    fileList = []\n",
    "    for dName, sdName, fList in os.walk(thisRunDir): # Walk through directory\n",
    "        for fileName in fList:\n",
    "            if fnmatch.fnmatch(fileName, pattern): # Match search string\n",
    "                fileList.append(os.path.join(dName, fileName))\n",
    "    calledList=[]\n",
    "    completedCount=0\n",
    "    maxBcCount=1 # at least 2 \"passed\" files (>1) need to be present\n",
    "    targetBc=\"undetermined\"\n",
    "    for bc in BARCODE_NAMES:\n",
    "        thisBc=0\n",
    "        for f in fileList:\n",
    "            if bc in f:\n",
    "                if \"_pass_\" in f:\n",
    "                    thisBc+=1\n",
    "        if thisBc > maxBcCount:\n",
    "            maxBcCount=thisBc\n",
    "            targetBc=bc\n",
    "    f5cAnalysisDir=NANODIP_OUTPUT+\"/\"+sampleId\n",
    "    if os.path.exists(f5cAnalysisDir)==False:\n",
    "        os.mkdir(f5cAnalysisDir)\n",
    "    thisBcFast5=[]\n",
    "    thisBcFastq=[]\n",
    "    for f in fileList:\n",
    "        if targetBc in f:\n",
    "            q=f.replace(\".fast5\",\"\").replace(\"fast5_pass\",\"fastq_pass\")+\".fastq\"\n",
    "            if os.path.exists(q): # check if accompanying fastq exists\n",
    "                thisBcFast5.append(f)\n",
    "                thisBcFastq.append(q)\n",
    "                thisBcFileName=f.split(\"/\")\n",
    "                thisBcFileName=thisBcFileName[len(thisBcFileName)-1].replace(\".fast5\",\"\") # get name prefix (to be the analysis subdir name later)\n",
    "                thisAnalysisDir=f5cAnalysisDir+\"/\"+thisBcFileName\n",
    "                if os.path.exists(thisAnalysisDir)==False:\n",
    "                    os.mkdir(thisAnalysisDir)\n",
    "                target5=thisAnalysisDir+\"/\"+thisBcFileName+\".fast5\"\n",
    "                targetq=thisAnalysisDir+\"/\"+thisBcFileName+\".fastq\"\n",
    "                if os.path.exists(target5)==False:\n",
    "                    os.symlink(f,target5)             # fast5 symlink\n",
    "                if os.path.exists(targetq)==False:\n",
    "                    os.symlink(q,targetq)             #fastq symlink\n",
    "                if os.path.exists(thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlapcount.txt\")==False:\n",
    "                    if (analyzeOne==True and analyzedCount==0) or analyzeOne==False:\n",
    "                        cmd=F5C+\" index -t 1 --iop 100 -d \"+thisAnalysisDir+\" \"+targetq\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) #index, call methylation and get methylation frequencies\n",
    "                        p.wait()\n",
    "                        cmd=MINIMAP2+\" -a -x map-ont \"+REFERENCE_GENOME_MMI+\" \"+targetq+\" -t 4 | \"+SAMTOOLS+\" sort -T tmp -o \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # get sorted BAM (4 threads)\n",
    "                        p.wait()\n",
    "                        cmd=SAMTOOLS+\" index \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # index BAM\n",
    "                        p.wait()\n",
    "                        cmd=F5C+\" call-methylation -B2000000 -K400 -b \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-reads_sorted.bam -g \"+REFERENCE_GENOME_FA+\" -r \"+targetq+\" > \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-result.tsv\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) # set B to 2 megabases (GPU) and 0.4 kreads\n",
    "                        p.wait()\n",
    "                        cmd=F5C+\" meth-freq -c 2.5 -s -i \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-result.tsv > \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-freq.tsv\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "                        p.wait()\n",
    "                        cmd=RSCRIPT+\" \"+READ_CPG_RSCRIPT+\" \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-freq.tsv \"+ILUMINA_CG_MAP+\" \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlap.tsv \"+thisAnalysisDir+\"/\"+thisBcFileName+\"-methoverlapcount.txt\"\n",
    "                        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "                        p.wait()\n",
    "                        calledList.append(thisBcFileName)\n",
    "                        analyzedCount+=1\n",
    "                else:\n",
    "                    completedCount+=1\n",
    "    return \"Target = \"+targetBc+\"<br>Methylation called for \"+str(calledList)+\". \"+str(completedCount+analyzedCount)+\"/\"+str(len(thisBcFast5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c9fd4",
   "metadata": {},
   "source": [
    "\n",
    "### 2. MinKNOW API Functions\n",
    "Check https://github.com/nanoporetech/minknow_api for reference.\n",
    "\n",
    "The following code requires a patched version of the MinKNOW API, install it\n",
    "from https://github.com/neuropathbasel/minknow_api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a manager using the host + port provided. This is used to connect to\n",
    "def mkManager():\n",
    "    return Manager(host=THIS_HOST, port=9501, use_tls=False) # the MinKNOW service trough the MK API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799592dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listMinionPositions(): # list MinION devices that are currenty connected to the system\n",
    "    manager = mkManager()\n",
    "    positions = manager.flow_cell_positions() # Find a list of currently available sequencing positions.\n",
    "    return(positions)   # User could call {pos.connect()} here to connect to the running MinKNOW instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listMinionExperiments(): # list all current and previous runs in the MinKNOW buffer, lost after MinKNOW restart\n",
    "    manager=mkManager()\n",
    "    htmlHost=\"<b>Host: \"+THIS_HOST+\"</b><br><table border='1'><tr>\"\n",
    "    positions=manager.flow_cell_positions() # Find a list of currently available sequencing positions.\n",
    "    htmlPosition=[]\n",
    "    for p in positions:\n",
    "        htmlPosinfo=\"<b>-\"+str(p)+\"</b><br>\"\n",
    "        connection = p.connect()\n",
    "        mountedFlowCellID=connection.device.get_flow_cell_info().flow_cell_id # return the flow cell info\n",
    "        htmlPosinfo=htmlPosinfo+\"--mounted flow cell ID: <b>\" + mountedFlowCellID +\"</b><br>\"\n",
    "        htmlPosinfo=htmlPosinfo+\"---\"+str(connection.acquisition.current_status())+\"<br>\" # READY, STARTING, sequencing/mux = PROCESSING, FINISHING; Pause = PROCESSING\n",
    "        protocols = connection.protocol.list_protocol_runs()\n",
    "        bufferedRunIds = protocols.run_ids\n",
    "        for b in bufferedRunIds:\n",
    "            htmlPosinfo=htmlPosinfo+\"--run ID: \" + b +\"<br>\"\n",
    "            run_info = connection.protocol.get_run_info(run_id=b)\n",
    "            htmlPosinfo=htmlPosinfo+\"---with flow cell ID: \" + run_info.flow_cell.flow_cell_id +\"<br>\"\n",
    "        htmlPosition.append(htmlPosinfo)\n",
    "    hierarchy = htmlHost\n",
    "    for p in htmlPosition:\n",
    "        hierarchy=hierarchy + \"<td valign='top'><tt>\"+p+\"</tt></td>\"\n",
    "    hierarchy=hierarchy+\"</table>\"\n",
    "    return(hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFlowCellID(thisDeviceId): # determine flow cell ID (if any). Note that some CTCs have an empty ID string.\n",
    "    mountedFlowCellID=\"no_flow_cell\"\n",
    "    manager=mkManager()\n",
    "    positions=manager.flow_cell_positions() # Find a list of currently available sequencing positions.\n",
    "    for p in positions:\n",
    "        if thisDeviceId in str(p):\n",
    "            connection = p.connect()\n",
    "            mountedFlowCellID=connection.device.get_flow_cell_info().flow_cell_id # return the flow cell info\n",
    "    return mountedFlowCellID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8245d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell starts a run on Mk1b devices and perform several checks concerning\n",
    "# the run protocol.\n",
    "\n",
    "# modified from the MinKNOW API on https://github.com/nanoporetech/minknow_api (2021-06)\n",
    "# created from the sample code at\n",
    "# https://github.com/nanoporetech/minknow_api/blob/master/python/examples/start_protocol.py\n",
    "# minknow_api.manager supplies \"Manager\" a wrapper around MinKNOW's Manager\n",
    "# gRPC API with utilities for querying sequencing positions + offline\n",
    "# basecalling tools.\n",
    "# from minknow_api.manager import Manager\n",
    "\n",
    "# We need 'find_protocol' to search for the required protocol given a kit +\n",
    "# product code.\n",
    "# from minknow_api.tools import protocols\n",
    "def parse_args():\n",
    "    \"\"\"Build and execute a command line argument for starting a protocol.\n",
    "\n",
    "    Returns:\n",
    "        Parsed arguments to be used when starting a protocol.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"\"\"\n",
    "        Run a sequencing protocol in a running MinKNOW instance.\n",
    "        \"\"\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--host\",\n",
    "        default=\"localhost\",\n",
    "        help=\"IP address of the machine running MinKNOW (defaults to localhost)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--port\",\n",
    "        help=\"Port to connect to on host (defaults to standard MinKNOW port based on tls setting)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-tls\", help=\"Disable tls connection\", default=False, action=\"store_true\"\n",
    "    )\n",
    "    parser.add_argument(\"--verbose\", action=\"store_true\", help=\"Enable debug logging\")\n",
    "\n",
    "    parser.add_argument(\"--sample-id\", help=\"sample ID to set\")\n",
    "    parser.add_argument(\n",
    "        \"--experiment-group\",\n",
    "        \"--group-id\",\n",
    "        help=\"experiment group (aka protocol group ID) to set\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--position\",\n",
    "        help=\"position on the machine (or MinION serial number) to run the protocol at\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--flow-cell-id\",\n",
    "        metavar=\"FLOW-CELL-ID\",\n",
    "        help=\"ID of the flow-cell on which to run the protocol. (specify this or --position)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kit\",\n",
    "        required=True,\n",
    "        help=\"Sequencing kit used with the flow-cell, eg: SQK-LSK108\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--product-code\",\n",
    "        help=\"Override the product-code stored on the flow-cell and previously user-specified\"\n",
    "        \"product-codes\",\n",
    "    )\n",
    "    # BASECALL ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--basecalling\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enable base-calling using the default base-calling model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--basecall-config\",\n",
    "        help=\"specify the base-calling config and enable base-calling\",\n",
    "    )\n",
    "    # BARCODING ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--barcoding\", action=\"store_true\", help=\"protocol uses barcoding\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcode-kits\",\n",
    "        nargs=\"+\",\n",
    "        help=\"bar-coding expansion kits used in the experiment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--trim-barcodes\", action=\"store_true\", help=\"enable bar-code trimming\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--barcodes-both-ends\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering (both ends of a strand must have a matching barcode)\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--detect-mid-strand-barcodes\",\n",
    "        action=\"store_true\",\n",
    "        help=\"bar-code filtering for bar-codes in the middle of a strand\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-score-rear\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--min-score-mid\",\n",
    "        type=float,\n",
    "        default=0.0,\n",
    "        help=\"read selection based on bar-code accuracy\",\n",
    "    )\n",
    "    # ALIGNMENT ARGUMENTS\n",
    "    parser.add_argument(\n",
    "        \"--alignment-reference\",\n",
    "        help=\"Specify alignment reference to send to basecaller for live alignment.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bed-file\", help=\"Specify bed file to send to basecaller.\",\n",
    "    )\n",
    "    # Output arguments\n",
    "    parser.add_argument(\n",
    "        \"--fastq\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables FastQ file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fastq-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one FastQ file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables Fast5 file output, defaulting to 4000 reads per file, this will store raw, \"\n",
    "        \"fastq and trace-table data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast5-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one Fast5 file.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam\",\n",
    "        action=\"store_true\",\n",
    "        help=\"enables BAM file output, defaulting to 4000 reads per file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bam-reads-per-file\",\n",
    "        type=int,\n",
    "        default=4000,\n",
    "        help=\"set the number of reads combined into one BAM file.\",\n",
    "    )\n",
    "    # Read until\n",
    "    parser.add_argument(\n",
    "        \"--read-until-reference\", type=str, help=\"Reference file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-bed-file\", type=str, help=\"Bed file to use in read until\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--read-until-filter\",\n",
    "        type=str,\n",
    "        choices=[\"deplete\", \"enrich\"],\n",
    "        help=\"Filter type to use in read until\",\n",
    "    )\n",
    "    # Experiment\n",
    "    parser.add_argument(\n",
    "        \"--experiment-duration\",\n",
    "        type=float,\n",
    "        default=72,\n",
    "        help=\"time spent sequencing (in hours)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--no-active-channel-selection\",\n",
    "        action=\"store_true\",\n",
    "        help=\"allow dynamic selection of channels to select pores for sequencing, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mux-scan-period\",\n",
    "        type=float,\n",
    "        default=1.5,\n",
    "        help=\"number of hours before a mux scan takes place, enables active-channel-selection, \"\n",
    "        \"ignored for Flongle flow-cells\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"extra_args\",\n",
    "        metavar=\"ARGS\",\n",
    "        nargs=\"*\",\n",
    "        help=\"Additional arguments passed verbatim to the protocol script\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    # Further argument checks\n",
    "    # Read until must have a reference and a filter type, if enabled:\n",
    "    if (\n",
    "        args.read_until_filter is not None\n",
    "        or args.read_until_reference is not None\n",
    "        or args.read_until_bed_file is not None\n",
    "    ):\n",
    "        if args.read_until_filter is None:\n",
    "            print(\"Unable to specify read until arguments without a filter type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if args.read_until_reference is None:\n",
    "            print(\"Unable to specify read until arguments without a reference type.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    if args.bed_file and not args.alignment_reference:\n",
    "        print(\"Unable to specify `--bed-file` without `--alignment-reference`.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if (args.barcoding or args.barcode_kits) and not (\n",
    "        args.basecalling or args.basecall_config\n",
    "    ):\n",
    "        print(\n",
    "            \"Unable to specify `--barcoding` or `--barcode-kits` without `--basecalling`.\"\n",
    "        )\n",
    "        sys.exit(1)\n",
    "    if args.alignment_reference and not (args.basecalling or args.basecall_config):\n",
    "        print(\"Unable to specify `--alignment-reference` without `--basecalling`.\")\n",
    "\n",
    "        sys.exit(1)\n",
    "    if not (args.fast5 or args.fastq):\n",
    "        print(\"No output (fast5 or fastq) specified\")\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08200f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_position_selected(position, args):\n",
    "    \"\"\"Find if the {position} is selected by command line arguments {args}.\"\"\"\n",
    "\n",
    "    # First check for name match:\n",
    "    if args.position == position.name:\n",
    "        return True\n",
    "\n",
    "    # Then verify if the flow cell matches:\n",
    "    connected_position = position.connect()\n",
    "    if args.flow_cell_id is not None:\n",
    "        flow_cell_info = connected_position.device.get_flow_cell_info()\n",
    "        if (\n",
    "            flow_cell_info.user_specified_flow_cell_id == args.flow_cell_id\n",
    "            or flow_cell_info.flow_cell_id == args.flow_cell_id\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db912119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startRun():\n",
    "    \"\"\"Entrypoint to start protocol example\"\"\"\n",
    "    # Parse arguments to be passed to started protocols:\n",
    "    run_id=\"\"\n",
    "    args = parse_args()\n",
    "    #args = parse_args(minknowApiShellArgumentString.split())\n",
    "\n",
    "    # Specify --verbose on the command line to get extra details about\n",
    "    if args.verbose:\n",
    "        logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "    # Construct a manager using the host + port provided:\n",
    "    #manager = Manager(host=args.host, port=args.port, use_tls=not args.no_tls)\n",
    "    manager=mkManager()\n",
    "    errormessage=\"\"\n",
    "\n",
    "    # Find which positions we are going to start protocol on:\n",
    "    positions = manager.flow_cell_positions()\n",
    "    filtered_positions = list(\n",
    "        filter(lambda pos: is_position_selected(pos, args), positions)\n",
    "    )\n",
    "\n",
    "    # At least one position needs to be selected:\n",
    "    if not filtered_positions:\n",
    "        errormessage=\"No positions selected for protocol - specify `--position` or `--flow-cell-id`\"\n",
    "    else:\n",
    "        protocol_identifiers = {}\n",
    "        for pos in filtered_positions:\n",
    "            # Connect to the sequencing position:\n",
    "            position_connection = pos.connect()\n",
    "\n",
    "            # Check if a flowcell is available for sequencing\n",
    "            flow_cell_info = position_connection.device.get_flow_cell_info()\n",
    "            if not flow_cell_info.has_flow_cell:\n",
    "                errormessage=\"No flow cell present in position \"+str(pos)\n",
    "            else:\n",
    "                # Select product code:\n",
    "                if args.product_code:\n",
    "                    product_code = args.product_code\n",
    "                else:\n",
    "                    product_code = flow_cell_info.user_specified_product_code\n",
    "                    if not product_code:\n",
    "                        product_code = flow_cell_info.product_code\n",
    "\n",
    "                # Find the protocol identifier for the required protocol:\n",
    "                protocol_info = protocols.find_protocol(\n",
    "                    position_connection,\n",
    "                    product_code=product_code,\n",
    "                    kit=args.kit,\n",
    "                    basecalling=args.basecalling,\n",
    "                    basecall_config=args.basecall_config,\n",
    "                    barcoding=args.barcoding,\n",
    "                    barcoding_kits=args.barcode_kits,\n",
    "                )\n",
    "\n",
    "                if not protocol_info:\n",
    "                    print(\"Failed to find protocol for position %s\" % (pos.name))\n",
    "                    print(\"Requested protocol:\")\n",
    "                    print(\"  product-code: %s\" % args.product_code)\n",
    "                    print(\"  kit: %s\" % args.kit)\n",
    "                    print(\"  basecalling: %s\" % args.basecalling)\n",
    "                    print(\"  basecall_config: %s\" % args.basecall_config)\n",
    "                    print(\"  barcode-kits: %s\" % args.barcode_kits)\n",
    "                    print(\"  barcoding: %s\" % args.barcoding)\n",
    "                    errormessage=\"Protocol build error, consult application log.\"\n",
    "                else:\n",
    "                    # Store the identifier for later:\n",
    "                    protocol_identifiers[pos.name] = protocol_info.identifier\n",
    "\n",
    "                    # Start protocol on the requested postitions:\n",
    "                    print(\"Starting protocol on %s positions\" % len(filtered_positions))\n",
    "                    for pos in filtered_positions:\n",
    "\n",
    "                        # Connect to the sequencing position:\n",
    "                        position_connection = pos.connect()\n",
    "\n",
    "                        # Find the protocol identifier for the required protocol:\n",
    "                        protocol_identifier = protocol_identifiers[pos.name]\n",
    "\n",
    "                        # Now select which arguments to pass to start protocol:\n",
    "                        print(\"Starting protocol %s on position %s\" % (protocol_identifier, pos.name))\n",
    "\n",
    "                        # Set up user specified product code if requested:\n",
    "                        if args.product_code:\n",
    "                            position_connection.device.set_user_specified_product_code(\n",
    "                                code=args.product_code\n",
    "                            )\n",
    "\n",
    "                        # Build arguments for starting protocol:\n",
    "                        basecalling_args = None\n",
    "                        if args.basecalling or args.basecall_config:\n",
    "                            barcoding_args = None\n",
    "                            alignment_args = None\n",
    "                            if args.barcode_kits or args.barcoding:\n",
    "                                barcoding_args = protocols.BarcodingArgs(\n",
    "                                    args.barcode_kits,\n",
    "                                    args.trim_barcodes,\n",
    "                                    args.barcodes_both_ends,\n",
    "                                    args.detect_mid_strand_barcodes,\n",
    "                                    args.min_score,\n",
    "                                    args.min_score_rear,\n",
    "                                    args.min_score_mid,\n",
    "                                )\n",
    "\n",
    "                            if args.alignment_reference:\n",
    "                                alignment_args = protocols.AlignmentArgs(\n",
    "                                    reference_files=[args.alignment_reference], bed_file=args.bed_file,\n",
    "                                )\n",
    "\n",
    "                            basecalling_args = protocols.BasecallingArgs(\n",
    "                                config=args.basecall_config,\n",
    "                                barcoding=barcoding_args,\n",
    "                                alignment=alignment_args,\n",
    "                            )\n",
    "\n",
    "                        read_until_args = None\n",
    "                        if args.read_until_filter:\n",
    "                            read_until_args = protocols.ReadUntilArgs(\n",
    "                                filter_type=args.read_until_filter,\n",
    "                                reference_files=[args.read_until_reference],\n",
    "                                bed_file=args.read_until_bed_file,\n",
    "                                first_channel=None,  # These default to all channels.\n",
    "                                last_channel=None,\n",
    "                            )\n",
    "\n",
    "                        def build_output_arguments(args, name):\n",
    "                            if not getattr(args, name):\n",
    "                                return None\n",
    "                            return protocols.OutputArgs(\n",
    "                                reads_per_file=getattr(args, \"%s_reads_per_file\" % name)\n",
    "                            )\n",
    "\n",
    "                        fastq_arguments = build_output_arguments(args, \"fastq\")\n",
    "                        fast5_arguments = build_output_arguments(args, \"fast5\")\n",
    "                        bam_arguments = build_output_arguments(args, \"bam\")\n",
    "\n",
    "                        # print the protocol parameters\n",
    "                        print(\"position_connection \"+str(position_connection))\n",
    "                        print(\"protocol_identifier \"+str(protocol_identifier))\n",
    "                        print(\"args.sample_id \"+str(args.sample_id))\n",
    "                        print(\"args.experiment_group \"+str(args.experiment_group))\n",
    "                        print(\"basecalling_args \"+str(basecalling_args))\n",
    "                        print(\"read_until_args \"+str(read_until_args))\n",
    "                        print(\"fastq_arguments \"+str(fastq_arguments)) #fastq_arguments OutputArgs(reads_per_file=400)\n",
    "                        print(\"fast5_arguments \"+str(fast5_arguments)) #fast5_arguments OutputArgs(reads_per_file=400)\n",
    "                        print(\"bam_arguments \"+str(bam_arguments))\n",
    "                        print(\"args.no_active_channel_selection\"+str(args.no_active_channel_selection))\n",
    "                        print(\"args.mux_scan_period\"+str(args.mux_scan_period))\n",
    "                        print(\"args.experiment_duration \"+str(args.experiment_duration))\n",
    "                        print(\"args.extra_args \"+str(args.extra_args))  # Any extra args passed.\n",
    "\n",
    "                        # Now start the protocol:\n",
    "                        run_id = protocols.start_protocol(\n",
    "                            position_connection,\n",
    "                            protocol_identifier,\n",
    "                            sample_id=args.sample_id,\n",
    "                            experiment_group=args.experiment_group,\n",
    "                            basecalling=basecalling_args,\n",
    "                            read_until=read_until_args,\n",
    "                            fastq_arguments=fastq_arguments,\n",
    "                            fast5_arguments=fast5_arguments,\n",
    "                            bam_arguments=bam_arguments,\n",
    "                            disable_active_channel_selection=args.no_active_channel_selection,\n",
    "                            mux_scan_period=args.mux_scan_period,\n",
    "                            experiment_duration=args.experiment_duration,\n",
    "                            args=args.extra_args,  # Any extra args passed.\n",
    "                        )\n",
    "\n",
    "                        #print(\"Started protocol %s\" % run_id)\n",
    "    return errormessage+run_id # one of them should be \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c401b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopRun(minionId): # stop an existing run (if any) for a MinION device\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == minionId, positions))\n",
    "    # Connect to the grpc port for the position:\n",
    "    connection = filtered_positions[0].connect()\n",
    "    protocols = connection.protocol.list_protocol_runs()\n",
    "    bufferedRunIds = protocols.run_ids\n",
    "    thisMessage=\"No protocol running, nothing was stopped.\"\n",
    "    c=0\n",
    "    for b in bufferedRunIds:\n",
    "        try:\n",
    "            connection.protocol.stop_protocol()\n",
    "            thisMessage=\"Protocol \"+b+\" stopped on \"+minionId+\".\"\n",
    "        except:\n",
    "            c=c+1\n",
    "    return thisMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from minknow_api demos, start_seq.py\n",
    "def is_position_selected(position, args):\n",
    "    \"\"\"Find if the {position} is selected by command line arguments {args}.\"\"\"\n",
    "    if args.position == position.name: # First check for name match:\n",
    "        return True\n",
    "    connected_position = position.connect()  # Then verify if the flow cell matches:\n",
    "    if args.flow_cell_id is not None:\n",
    "        flow_cell_info = connected_position.device.get_flow_cell_info()\n",
    "        if (flow_cell_info.user_specified_flow_cell_id == args.flow_cell_id\n",
    "            or flow_cell_info.flow_cell_id == args.flow_cell_id):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b355ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinKnowApiStatus(deviceString): # MinKNOW status per device\n",
    "    replyString=\"\"\n",
    "    testHost=\"localhost\"\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    # determine if anything is running and the kind of run, via set temperature\n",
    "    replyString=replyString+\"acquisition.get_acquisition_info().state: \"+str(connection.acquisition.get_acquisition_info().state)+\"<br>\"\n",
    "    replyString=replyString+\"acquisition.current_status(): \"+str(connection.acquisition.current_status())+\"<br>\"\n",
    "    replyString=replyString+\"minion_device.get_settings().temperature_target.min: \"+str(connection.minion_device.get_settings().temperature_target.min)+\"<br>\"\n",
    "    replyString=replyString+\"device.get_temperature(): \" + str(connection.device.get_temperature().minion.heatsink_temperature)+\"<br>\"\n",
    "    replyString=replyString+\"device.get_bias_voltage(): \" + str(connection.device.get_bias_voltage())+\"<br>\"\n",
    "    return replyString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58680585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActiveRun(deviceString):\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        activeRun=connection.acquisition.get_current_acquisition_run().run_id # error if no acquisition is running, same as with acquisitio.current_status(), no acquisition until temperature reached\n",
    "    except:\n",
    "        activeRun=\"none\"\n",
    "    return activeRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a92145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRealDeviceActivity(deviceString):            # seq. runs: 34 degC and flow cell checks 37 degC target\n",
    "    manager=mkManager()                             # temperatures seem to be the only way to determine if\n",
    "    positions = list(manager.flow_cell_positions()) # a device has been started\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    targetTemp=str(connection.minion_device.get_settings().temperature_target.min)\n",
    "    returnValue=\"\"\n",
    "    if targetTemp==\"34.0\":\n",
    "        returnValue=\"sequencing\"\n",
    "    elif targetTemp==\"37.0\":\n",
    "        returnValue=\"checking flow cell\"\n",
    "    elif targetTemp==\"35.0\":\n",
    "        returnValue=\"idle\"\n",
    "    return returnValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d157dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunState(deviceString): # obtain further information about a particular device / run\n",
    "    manager=mkManager()\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        thisRunState=\"Run state for \"+deviceString+\": \"\n",
    "        thisRunState=thisRunState+str(connection.protocol.get_current_protocol_run().state)+\"/\"\n",
    "        thisRunState=thisRunState+str(connection.acquisition.get_acquisition_info().state)\n",
    "    except:\n",
    "        thisRunState=\"No state information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunSampleID(deviceString): # get SampleID from MinKNOW by device, only available after data\n",
    "    manager=mkManager()               # acquisition as been initiated by MinKNOW.\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        thisRunSampleID=connection.protocol.get_current_protocol_run().user_info.sample_id.value\n",
    "    except:\n",
    "        thisRunSampleID=\"No sampleId information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunSampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ab892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunYield(deviceString): # get run yield by device. The data of the previous run will remain\n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        acqinfo=connection.acquisition.get_acquisition_info()\n",
    "        thisRunYield=\"Run yield for \"+deviceString+\"(\"+acqinfo.run_id+\"):&nbsp;\"\n",
    "        thisRunYield=thisRunYield+str(acqinfo.yield_summary)\n",
    "    except:\n",
    "        thisRunYield=\"No yield information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunYield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunOutput(deviceString,sampleName,runId): # get run yield by device, sampleName, runId\n",
    "    thisRunOutput=[-1,-1] # defaults in case of error / missing information\n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    readCount=-3\n",
    "    calledBases=-3\n",
    "    if getThisRunSampleID(deviceString)==sampleName: # check that runID and sampleID match\n",
    "        readCount=-4\n",
    "        calledBases=-4\n",
    "        if connection.acquisition.get_current_acquisition_run().run_id==runId:\n",
    "            if connection.acquisition.current_status()!=\"status: READY\": # i.e., working\n",
    "                try:\n",
    "                    acq=connection.acquisition.get_acquisition_info()\n",
    "                    readCount=acq.yield_summary.basecalled_pass_read_count\n",
    "                    calledBases=acq.yield_summary.basecalled_pass_bases\n",
    "                except:\n",
    "                    readCount=-5\n",
    "                    calledBases=-5\n",
    "    thisRunOutput=[readCount,calledBases]\n",
    "    return thisRunOutput # shall be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunEstimatedOutput(deviceString,sampleName,runId): # get run yield by device, sampleName, runId\n",
    "    thisRunOutput=[-1,-1] # defaults in case of error / missing information\n",
    "    manager=mkManager()            # in the buffer until acquisition (not just a start) of a new run\n",
    "    positions = list(manager.flow_cell_positions()) # have been initiated.\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    readCount=-3\n",
    "    calledBases=-3\n",
    "    if getThisRunSampleID(deviceString)==sampleName: # check that runID and sampleID match\n",
    "        readCount=-4\n",
    "        calledBases=-4\n",
    "        if connection.acquisition.get_current_acquisition_run().run_id==runId:\n",
    "            if connection.acquisition.current_status()!=\"status: READY\": # i.e., working\n",
    "                try:\n",
    "                    acq=connection.acquisition.get_acquisition_info()\n",
    "                    readCount=acq.yield_summary.basecalled_pass_read_count\n",
    "                    calledBases=acq.yield_summary.estimated_selected_bases\n",
    "                except:\n",
    "                    readCount=-5\n",
    "                    calledBases=-5\n",
    "    thisRunOutput=[readCount,calledBases]\n",
    "    return thisRunOutput # shall be a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThisRunInformation(deviceString): # get current run information. Only available after data acquisition\n",
    "    manager=mkManager()                  # has started.\n",
    "    positions = list(manager.flow_cell_positions())\n",
    "    filtered_positions = list(filter(lambda pos: pos.name == deviceString, positions))\n",
    "    connection = filtered_positions[0].connect() # Connect to the grpc port for the position\n",
    "    try:\n",
    "        thisRunInfo=\"Run information for \"+deviceString+\"<br><br>\"+str(connection.protocol.get_current_protocol_run())\n",
    "    except:\n",
    "        thisRunInfo=\"No protocol information in MinKNOW buffer for \"+deviceString\n",
    "    return thisRunInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thisRunWatcherTerminator(deviceString,sampleName):\n",
    "    realRunId=getActiveRun(deviceString) #\n",
    "    currentBases=getThisRunEstimatedOutput(deviceString,sampleName,realRunId)[1]\n",
    "    currentBasesString=str(round(currentBases/1e6,2))\n",
    "    wantedBasesString=str(round(NEEDED_NUMBER_OF_BASES/1e6,2))\n",
    "    myString=\"<html><head>\"\n",
    "    myString=myString+\"<title>\"+currentBasesString+\"/\"+wantedBasesString+\"MB:\"+sampleName+\"</title>\"\n",
    "    if currentBases < NEEDED_NUMBER_OF_BASES: # don't refresh after showing the STOP state\n",
    "        myString=myString+\"<meta http-equiv='refresh' content='10'>\"\n",
    "    myString=myString+\"</head><body>\"\n",
    "    myString=myString+\"<b>Automatic run terminator</b> for sample <b>\"+sampleName+ \"</b>, run ID=\"+realRunId+\" on \"+deviceString+\" when reaching \"+wantedBasesString+\" MB, now \"+currentBasesString+\" MB\"\n",
    "    myString=myString+\"<hr>\"\n",
    "    myString=myString+\"Last refresh at \"+date_time_string_now()+\".<hr>\"\n",
    "    if currentBases > NEEDED_NUMBER_OF_BASES:\n",
    "        stopRun(deviceString)\n",
    "        myString=myString+\"STOPPED at \"+date_time_string_now()\n",
    "    elif currentBases==0:\n",
    "        myString=myString+\"IDLE / MUX / ETC\"\n",
    "    else:\n",
    "        myString=myString+\"RUNNING\"\n",
    "    myString=myString+\"</body></html>\"\n",
    "    return myString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d9e0b",
   "metadata": {},
   "source": [
    "\n",
    "### 3. CNV Plotter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c11072",
   "metadata": {},
   "source": [
    "\n",
    "### 4. UMAP Methylation Plotter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e946bef",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Report Generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c17cb89",
   "metadata": {},
   "source": [
    "\n",
    "### 6. User Interface Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b6e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO changed\n",
    "# String patterns in sample names that exclude data from downstream analysis,\n",
    "# e.g., test runs\n",
    "def analysis_launch_table():\n",
    "    \"\"\"Presents a html table from which analyses can be started in a post-hoc\n",
    "    manner.\"\"\"\n",
    "    analysis_runs = [run for run in get_runs() if\n",
    "        not any(pattern in run for pattern in ANALYSIS_EXCLUSION_PATTERNS)]\n",
    "    annotations = reference_annotations()\n",
    "    table = f\"\"\"\n",
    "        <tt>\n",
    "        <font size='-2'>\n",
    "        <table border=1>\n",
    "        <thead>\n",
    "        <tr>\n",
    "            <th align='left'><b>Sample ID </b></th>\n",
    "            <th align='left'><b>CpGs</b></th>\n",
    "            <th align='left'><b>CNV</b></th>\"\"\"\n",
    "    for a in annotations:\n",
    "        table += f\"\"\"\n",
    "            <th align='left'>\n",
    "                <b>UMAP against<br>{a.replace(\".xlsx\", \"\")}</b>\n",
    "            </th>\"\"\"\n",
    "    table += \"\"\"\n",
    "        </tr>\n",
    "        </thead>\n",
    "        <tbody>\"\"\"\n",
    "    for _, run in enumerate(analysis_runs):\n",
    "        table += f\"\"\"\n",
    "        <tr>\n",
    "            <td>{run}</td>\n",
    "            <td>\n",
    "            <a href='./analysisLauncher?functionName=methylationPoller&sampleName={run}&refAnno=None'\n",
    "            target='_blank' rel='noopener noreferrer' title='{run}: CpGs'>\n",
    "                get CpGs\n",
    "            </a>\n",
    "            </td>\n",
    "            <td>\n",
    "            <a href='./analysisLauncher?functionName=cnvplot&sampleName={run}&refAnno=None'\n",
    "                target='_blank' rel='noopener noreferrer' title='{run}: CNV'>\n",
    "                    plot CNV\n",
    "            </a>\n",
    "            </td>\"\"\"\n",
    "        for a in annotations:\n",
    "            table += f\"\"\"\n",
    "            <td>\n",
    "            <a href='./analysisLauncher?functionName=umapplot&sampleName={run}&refAnno={a}'\n",
    "            target='_blank' rel='noopener noreferrer'\n",
    "            title='{run}: {a.replace(\".xlsx\", \"\")}'>\n",
    "                plot UMAP\n",
    "            </a>&nbsp;\n",
    "            <a href='./makePdf?sampleName={run}&refAnno={a}' target='_blank'\n",
    "            rel='noopener noreferrer' title='{run}: {a.replace(\".xlsx\", \"\")}'>\n",
    "                make PDF\n",
    "            </a>\n",
    "            </td>\"\"\"\n",
    "        table += \"\"\"\n",
    "        </tr>\"\"\"\n",
    "    table += \"\"\"\n",
    "        </tbody>\n",
    "        </table>\n",
    "        </font>\n",
    "        </tt>\"\"\"\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce81368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results():\n",
    "    \"\"\"Return list of all analysis result files in report directory sorted\n",
    "    by modification time.\"\"\"\n",
    "    files = []\n",
    "    for f in os.listdir(NANODIP_REPORTS):\n",
    "        for e in RESULT_ENDINGS.values():\n",
    "            if f.endswith(e):\n",
    "                mod_time = os.path.getmtime(\n",
    "                    os.path.join(NANODIP_REPORTS, f)\n",
    "                )\n",
    "                files.append([f, mod_time])\n",
    "    files.sort(key=lambda x: (x[1], x[0]), reverse=True)\n",
    "    return [f[0] for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def livePage(deviceString): # generate a live preview of the data analysis with the current PNG figures\n",
    "    thisSampleID=getThisRunSampleID(deviceString) # if there is a run that produces data, the run ID will exist\n",
    "    thisSampleRef=readReferenceDefinition(thisSampleID).replace(\".xlsx\", \"\")\n",
    "    cnvPlotPath=\"reports/\"+thisSampleID+\"_CNVplot.png\"\n",
    "    umapAllPlotPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_all.png\"\n",
    "    umapAllPlotlyPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_all.html\"\n",
    "    umapTopPlotPath=\"reports/\"+thisSampleID+\"_\"+thisSampleRef+\"_UMAP_top.png\"\n",
    "    ht=\"<html><body><tt>sample ID: \"+thisSampleID+\" with reference \"+thisSampleRef+\"</tt><br>\"\n",
    "    ht=ht+\"<a href='\"+cnvPlotPath+\"' target='_blank'><img align='Top' src='\"+cnvPlotPath+\"' width='50%' alt='CNV plot will appear here'></a>\"\n",
    "    ht=ht+\"<a href='\"+umapAllPlotlyPath+\"' target='_blank'><img align='Top' src='\"+umapAllPlotPath+\"' width='50%' alt='UMAP plot will appear here'></a>\"\n",
    "    ht=ht+\"</tt></table><body></html>\"\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def methcallLivePage(sampleName): # generate a self-refreshing page to invoke methylation calling\n",
    "    ht=\"<html><head><title>MethCaller: \"+sampleName+\"</title>\"\n",
    "    ht=ht+\"<meta http-equiv='refresh' content='3'></head><body>\"\n",
    "    ht=ht+\"last refresh and console output at \"+date_time_string_now()+\"<hr>shell output<br><br><tt>\"\n",
    "    #ht=ht+calculateMethylationAndBamFromFast5Fastq(sampleName)\n",
    "    ht=ht+f5cOneFast5(sampleName,analyzeOne=True)\n",
    "    ht=ht+\"</tt></body></html>\"\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79466e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO changed\n",
    "def menuheader(current_page, autorefresh=0):\n",
    "    \"\"\"Generate a universal website header for the UI pages that\n",
    "    contains a simple main menu.\"\"\"\n",
    "    menu = {\n",
    "        \"index\":[\n",
    "            \"Overview\",\n",
    "            \"General system information\",\n",
    "        ],\n",
    "        \"listPositions\":[\n",
    "            \"Mk1b Status\",\n",
    "            \"Live status of all connected Mk1b devices\",\n",
    "        ],\n",
    "        \"startSequencing\":[\n",
    "            \"Start seq.\",\n",
    "            \"Start a sequencing run on an idle Mk1b device\",\n",
    "        ],\n",
    "        \"startTestrun\":[\n",
    "            \"Start test run\",\n",
    "            \"Start a test seq. run on an idle Mk1b device to verify that the previous flow cell wash was successful.\",\n",
    "        ],\n",
    "        \"listExperiments\":[\n",
    "            \"Seq. runs\",\n",
    "            \"List all buffered runs. Will be purged upon MinKNOW backend restart.\",\n",
    "        ],\n",
    "        \"listRuns\":[\n",
    "            \"Results\",\n",
    "            \"List all completed analysis results\",\n",
    "        ],\n",
    "        \"analyze\":[\n",
    "            \"Analyze\",\n",
    "            \"Launch data analyses manually, e.g. for retrospective analysis\",\n",
    "        ],\n",
    "        \"about\":[\n",
    "            \"About NanoDiP\",\n",
    "            \"Version, etc.\",\n",
    "        ],\n",
    "    }\n",
    "    html = f\"\"\"\n",
    "        <html>\n",
    "        <head>\n",
    "        <title>\n",
    "            NanoDiP Version {NANODIP_VERSION}\n",
    "        </title>\"\"\"\n",
    "    if autorefresh > 0:\n",
    "        html += f\"<meta http-equiv='refresh' content='{autorefresh}'>\"\n",
    "    html += \"\"\"\n",
    "        </head>\n",
    "        <body>\n",
    "        <table border=0 cellpadding=2>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <img src='img/EpiDiP_Logo_01.png' width='40px' height='40px'>\n",
    "            </td>\"\"\"\n",
    "    for key, value in menu.items():\n",
    "        selected_color = \"#E0E0E0\" if current_page == key else \"white\"\n",
    "        html += f\"\"\"\n",
    "            <td bgcolor='{selected_color}'>\n",
    "                <b>\n",
    "                <a href='{key}' title='{value[1]}'> {value[0]}\n",
    "                </a>\n",
    "                </b>\n",
    "            </td>\"\"\"\n",
    "    html += f\"\"\"\n",
    "        </tr>\n",
    "        </table>\n",
    "        <br>\"\"\"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def68c7",
   "metadata": {},
   "source": [
    "\n",
    "### 6. CherryPy Web UI\n",
    "The browser-based user interface is based on CherryPy, which contains an\n",
    "intergrated web server and serves pages locally. Communication between the\n",
    "service and browser typically generates static web pages that may or may not\n",
    "contain automatic self refresh commands. In the case of self-refreshing pages,\n",
    "the browser will re-request a given page with leads to re-execution of the\n",
    "respective python functions. The main handles to these function are located in\n",
    "the Web UI cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInterface(object):\n",
    "    \"\"\"The CherryPy Web UI Webserver class defines entrypoints and\n",
    "    function calls.\"\"\"\n",
    "    # global variables within the CherryPy Web UI\n",
    "    cpgQueue = 0 # TODO use mutex instead\n",
    "    umapQueue = 0\n",
    "    cnvpQueue = 0\n",
    "    cnv_lock = mp.Lock()\n",
    "    umap_lock = mp.Lock()\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def index(self):\n",
    "        total, used, free = shutil.disk_usage(DATA)\n",
    "        sys_stat = {\n",
    "            \"hostname\": socket.gethostname(),\n",
    "            \"disk_total\": total // (2**30),\n",
    "            \"disk_used\": used // (2**30),\n",
    "            \"disk_free\": free // (2**30),\n",
    "            \"memory_free\": round(\n",
    "                psutil.virtual_memory().available * 100\n",
    "                / psutil.virtual_memory().total\n",
    "            ),\n",
    "            \"cpu\": round(psutil.cpu_percent()),\n",
    "            \"cpgs\": UserInterface.cpgQueue,\n",
    "            \"cnvp\": len([p for p in mp.active_children() if p.name == \"cnv\"]),\n",
    "            \"umap\": len([p for p in mp.active_children() if p.name == \"umap\"]),\n",
    "        }\n",
    "        return render_template(\"index.html\", sys_stat=sys_stat)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def old(self):\n",
    "        \"\"\"Titlepage.\"\"\"\n",
    "        html = menuheader('index', 15)\n",
    "        html += \"<tt><b>Computer:</b> \"\n",
    "        html += str(socket.gethostname())\n",
    "        html += \"</tt><br><br>\"\n",
    "        return html\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def restart(self):\n",
    "        cherrypy.engine.restart()\n",
    "        return render_template(\"restart.html\")\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def reset_queue(self, queue_name=\"\"):\n",
    "        html = menuheader('index', 15)\n",
    "        if queue_name:\n",
    "            if queue_name == \"cpg\":\n",
    "                UserInterface.cpgQueue = 0\n",
    "            if queue_name == \"umap\":\n",
    "                UserInterface.umapQueue = 0\n",
    "            if queue_name == \"cnvp\":\n",
    "                UserInterface.cnvpQueue = 0\n",
    "            html += queue_name + \" queue reset\"\n",
    "        return html\n",
    "\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def listPositions(self):\n",
    "        myString=menuheader(1,10)\n",
    "        positions=listMinionPositions()\n",
    "        for pos in positions:\n",
    "            n=str(pos.name) # pos.state does not tell much other than that the device is connected with USB (\"running\")\n",
    "            myString=myString+\"<br><iframe src='DeviceStatusLive?deviceString=\"+n+\"' height='200' width='600' title='\"+n+\"' border=3></iframe>\"\n",
    "            myString=myString+\"<iframe src='AnalysisStatusLive?deviceString=\"+n+\"' height='200' width='600' title='\"+n+\"' border=3></iframe>\"\n",
    "            myString=myString+\"<br><a href='DeviceStatusLive?deviceString=\"+n+\"' target='_blank' title='Click to open device status page in new tab or window'>\"+n+\"</a>\"\n",
    "            myString=myString+\", live state: \"+getRealDeviceActivity(n)\n",
    "            activeRun=getActiveRun(n)\n",
    "            myString=myString+\", active run: \"+getActiveRun(n)\n",
    "            if activeRun!=\"none\":\n",
    "                myString=myString+\" <a href='launchAutoTerminator?sampleName=\"+getThisRunSampleID(n)+\"&deviceString=\"+n+\"' target='_blank'>\"\n",
    "                myString=myString+\"<br>Click this link to launch automatic run terminator after\"+str(round(NEEDED_NUMBER_OF_BASES/1e6))+\" MB.</a>\"\n",
    "                myString=myString+\"<br><font color=''#ff0000'><a href='stopSequencing?deviceId=\"+n+\"' title='Clicking this will terminate the current run immediately! Use with care!'>terminate manually</a></font>\"\n",
    "            myString=myString+\"<br><br>\"\n",
    "        myString=myString+\"</body></html>\"\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def status(self):\n",
    "        positions = [str(pos.name) for pos in listMinionPositions()]\n",
    "        print(\"--------------\", positions)\n",
    "        return render_template(\n",
    "            \"status.html\",\n",
    "            positions=positions,\n",
    "            mega_bases=NEEDED_NUMBER_OF_BASES // 1e6)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def startSequencing(self,deviceId=\"\",sampleId=\"\",runDuration=\"\",referenceFile=\"\"):\n",
    "        myString=menuheader(2,0)\n",
    "        if sampleId:\n",
    "            if float(runDuration)>=0.1:\n",
    "                sys.argv = ['',\n",
    "                            '--host','localhost',\n",
    "                            '--position',deviceId,\n",
    "                            '--sample-id',sampleId,\n",
    "                            '--experiment-group',sampleId,\n",
    "                            '--experiment-duration',runDuration,\n",
    "                            '--basecalling',\n",
    "                            '--fastq',\n",
    "                            '--fastq-reads-per-file',READS_PER_FILE,\n",
    "                            '--fast5',\n",
    "                            '--fast5-reads-per-file',READS_PER_FILE,\n",
    "                            '--verbose',\n",
    "                            '--kit','SQK-RBK004',\n",
    "                            '--barcoding',\n",
    "                            '--barcode-kits','SQK-RBK004']\n",
    "                realRunId=startRun()\n",
    "                writeReferenceDefinition(sampleId,referenceFile)\n",
    "                myString=myString+\"sequencing run started for \"+sampleId+\" on \"+deviceId+\" as \"+realRunId+\" with reference \"+referenceFile\n",
    "                myString=myString+\"<hr>\"+getThisRunInformation(deviceId)\n",
    "                myString=myString+\"<hr><a href='launchAutoTerminator?sampleName=\"+sampleId+\"&deviceString=\"+deviceId+\"'>\"\n",
    "                myString=myString+\"Click this link to launch automatic run terminator after\"+str(round(NEEDED_NUMBER_OF_BASES/1e6))+\" MB.</a> \"\n",
    "                myString=myString+\"If you do not start the run terminator, you will have to terminate the run manually, or it will stop after the predefined time.\"\n",
    "        else:\n",
    "            myString=myString+'''<form action=\"startSequencing\" method=\"GET\">\n",
    "                Select an idle Mk1b:&nbsp;<select name=\"deviceId\" id=\"deviceId\">'''\n",
    "            positions=listMinionPositions()\n",
    "            for pos in positions:\n",
    "                thisPos=pos.name\n",
    "                if getRealDeviceActivity(thisPos)==\"idle\":\n",
    "                    if getFlowCellID(thisPos)!=\"\":\n",
    "                        myString=myString+'<option value=\"'+thisPos+'\">'+thisPos+': '+getFlowCellID(thisPos)+'</option>'\n",
    "            myString=myString+'''\n",
    "                </select>&nbsp; and enter the sample ID:&nbsp;<input type=\"text\" name=\"sampleId\" />\n",
    "                &nbsp;for&nbsp;<input type=\"text\" name=\"runDuration\" value=\"72\" />&nbsp;hours.\n",
    "                &nbsp;Reference set&nbsp;<select name=\"referenceFile\" id=\"referenceFile\">'''\n",
    "            for ref in reference_annotations():\n",
    "                myString=myString+'<option value=\"'+ref+'\">'+ref+'</option>'\n",
    "            myString=myString+'&nbsp;<input type=\"submit\" value=\"start sequencing now\"/></form>'\n",
    "        return myString\n",
    "\n",
    "\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def start(self, device_id=\"\", sample_id=\"\",\n",
    "              run_duration=\"\", reference_id=\"\"):\n",
    "        start_now = sample_id and float(run_duration) >= 0.1\n",
    "        if start_now:\n",
    "            sys.argv = [\n",
    "                \"\",\n",
    "                \"--host\", \"localhost\",\n",
    "                \"--position\", device_id,\n",
    "                \"--sample-id\", sample_id,\n",
    "                \"--experiment-group\", sample_id,\n",
    "                \"--experiment-duration\", run_duration,\n",
    "                \"--basecalling\",\n",
    "                \"--fastq\",\n",
    "                \"--fastq-reads-per-file\", READS_PER_FILE,\n",
    "                \"--fast5\",\n",
    "                \"--fast5-reads-per-file\", READS_PER_FILE,\n",
    "                \"--verbose\",\n",
    "                \"--kit\", \"SQK-RBK004\",\n",
    "                \"--barcoding\",\n",
    "                \"--barcode-kits\", \"SQK-RBK004\",\n",
    "            ]\n",
    "            run_id = startRun()\n",
    "            write_reference_name(sample_id, reference_id)\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=start_now,\n",
    "                test=False,\n",
    "                sample_id=sample_id,\n",
    "                reference_id=reference_id,\n",
    "                device_id=device_id,\n",
    "                run_id=run_id,\n",
    "                mega_bases=NEEDED_NUMBER_OF_BASES // 1e6,\n",
    "                run_info=getThisRunInformation(device_id),\n",
    "            )\n",
    "        else:\n",
    "            positions = [p.name for p in listMinionPositions()]\n",
    "            idle = [p for p in positions if getRealDeviceActivity(p) == \"idle\"\n",
    "                and getFlowCellID(p) != \"\"]\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=start_now,\n",
    "                test=False,\n",
    "                idle=idle,\n",
    "                references=reference_annotations(),\n",
    "            )\n",
    "\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def startTestrun(self,deviceId=\"\"):\n",
    "        myString=menuheader('startTestrun', 0)\n",
    "        if deviceId:\n",
    "            sampleId=date_time_string_now()+\"_TestRun_\"+getFlowCellID(deviceId)\n",
    "            sys.argv = ['',\n",
    "                        '--host','localhost',\n",
    "                        '--position',deviceId,\n",
    "                        '--sample-id',sampleId,\n",
    "                        '--experiment-group',sampleId,\n",
    "                        '--experiment-duration','0.1',\n",
    "                        '--basecalling',\n",
    "                        '--fastq',\n",
    "                        '--fastq-reads-per-file',READS_PER_FILE,\n",
    "                        '--fast5',\n",
    "                        '--fast5-reads-per-file',READS_PER_FILE,\n",
    "                        '--verbose',\n",
    "                        '--kit','SQK-RBK004',\n",
    "                        '--barcoding',\n",
    "                        '--barcode-kits','SQK-RBK004']\n",
    "            realRunId=startRun()\n",
    "            myString=myString+\"sequencing run started for \"+sampleId+\" on \"+deviceId+\" as \"+realRunId\n",
    "            myString=myString+\"<hr>\"+getThisRunInformation(deviceId)\n",
    "        else:\n",
    "            myString=myString+'''<form action=\"startTestrun\" method=\"GET\">\n",
    "                Select an idle Mk1b:&nbsp;<select name=\"deviceId\" id=\"deviceId\">'''\n",
    "            positions=listMinionPositions()\n",
    "            for pos in positions:\n",
    "                thisPos=pos.name\n",
    "                if getRealDeviceActivity(thisPos)==\"idle\":\n",
    "                    if getFlowCellID(thisPos)!=\"\":\n",
    "                        myString=myString+'<option value=\"'+thisPos+'\">'+thisPos+': '+getFlowCellID(thisPos)+'</option>'\n",
    "            myString=myString+'''\n",
    "                </select>&nbsp;<input type=\"submit\" value=\"start test run now (0.1h)\"/></form>'''\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def test_run(self, device_id=\"\"):\n",
    "        if device_id:\n",
    "            sample_id = (date_time_string_now() + \"_TestRun_\"\n",
    "                + getFlowCellID(device_id))\n",
    "            sys.argv = [\n",
    "                \"\",\n",
    "                \"--host\", \"localhost\",\n",
    "                \"--position\", device_id,\n",
    "                \"--sample-id\", sample_id,\n",
    "                \"--experiment-group\", sample_id,\n",
    "                \"--experiment-duration\", \"0.1\",\n",
    "                \"--basecalling\",\n",
    "                \"--fastq\",\n",
    "                \"--fastq-reads-per-file\", READS_PER_FILE,\n",
    "                \"--fast5\",\n",
    "                \"--fast5-reads-per-file\", READS_PER_FILE,\n",
    "                \"--verbose\",\n",
    "                \"--kit\", \"SQK-RBK004\",\n",
    "                \"--barcoding\",\n",
    "                \"--barcode-kits\", \"SQK-RBK004\",\n",
    "            ]\n",
    "            run_id = startRun()\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=True,\n",
    "                sample_id=sample_id,\n",
    "                reference_id=\"TEST\",\n",
    "                device_id=device_id,\n",
    "                run_id=run_id,\n",
    "                mega_bases=NEEDED_NUMBER_OF_BASES // 1e6,\n",
    "                run_info=getThisRunInformation(device_id),\n",
    "            )\n",
    "        else:\n",
    "            positions = [p.name for p in listMinionPositions()]\n",
    "            idle = [p for p in positions if getRealDeviceActivity(p) == \"idle\"\n",
    "                and getFlowCellID(p) != \"\"]\n",
    "            return render_template(\n",
    "                \"start.html\",\n",
    "                start_now=False,\n",
    "                test=True,\n",
    "                idle=idle,\n",
    "                references=reference_annotations(),\n",
    "            )\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def stopSequencing(self, deviceId=\"\"):\n",
    "        myString=menuheader('listPositions', 0)\n",
    "        myString=myString + stopRun(deviceId)\n",
    "        myString=myString + \"<br><br>Click on any menu item to proceed.\"\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def listExperiments(self):\n",
    "        myString=menuheader('listExperiments', 10)\n",
    "        myString=myString+\"Running and buffered experiments:<br>\"\n",
    "        experiments=listMinionExperiments()\n",
    "        myString=myString+experiments\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def list_runs(self):\n",
    "        status = {}\n",
    "        mounted_flow_cell_id = {}\n",
    "        current_status = {}\n",
    "        flow_cell_id = {}\n",
    "        buffered_run_ids = {}\n",
    "\n",
    "        manager = mkManager()\n",
    "        # Find a list of currently available sequencing positions.\n",
    "        positions = manager.flow_cell_positions()\n",
    "\n",
    "        for p in positions:\n",
    "            connection = p.connect()\n",
    "            # return the flow cell info\n",
    "            mounted_flow_cell_id[p] = connection.device.get_flow_cell_info(\n",
    "                ).flow_cell_id\n",
    "            # READY, STARTING, sequencing/mux = PROCESSING, FINISHING;\n",
    "            # Pause = PROCESSING\n",
    "            current_status[p] = connection.acquisition.current_status()\n",
    "            protocols = connection.protocol.list_protocol_runs()\n",
    "            buffered_run_ids[p] = protocols.run_ids\n",
    "            for b in buffered_run_ids[p]:\n",
    "                run_info = connection.protocol.get_run_info(run_id=b)\n",
    "                flow_cell_id[(p, b)] = run_info.flow_cell.flow_cell_id\n",
    "        return render_template(\n",
    "            \"list_runs.html\",\n",
    "            positions=positions,\n",
    "            host=CHERRYPY_HOST,\n",
    "            status=status,\n",
    "            mounted_flow_cell_id=mounted_flow_cell_id,\n",
    "            current_status=current_status,\n",
    "            flow_cell_id=flow_cell_id,\n",
    "            buffered_run_ids=buffered_run_ids,\n",
    "        )\n",
    "\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def results(self):\n",
    "        files = get_all_results()\n",
    "        return render_template(\"results.html\", files=files)\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analyze(self):\n",
    "        myString=menuheader('analyze',0)\n",
    "        myString=myString+analysis_launch_table()\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analysis(self, func=\"\", samp=\"\", ref=\"\", new=\"False\"):\n",
    "        if func == \"\":\n",
    "            analysis_runs = [run for run in get_runs() if not any(pattern in run\n",
    "                for pattern in ANALYSIS_EXCLUSION_PATTERNS)]\n",
    "            annotations = [a.replace(\".xlsx\", \"\")\n",
    "                for a in reference_annotations()]\n",
    "            return render_template(\n",
    "                \"analysis_start.html\",\n",
    "                analysis_runs=analysis_runs,\n",
    "                annotations=annotations,\n",
    "            )\n",
    "        if func == \"cnv\":\n",
    "            genome = ReferenceGenome()\n",
    "            genes = genome.genes.name.to_list()\n",
    "            return render_template(\n",
    "                \"analysis_cnv.html\",\n",
    "                sample_name=samp,\n",
    "                genes=genes,\n",
    "                new=new,\n",
    "            )\n",
    "        if func == \"umap\":\n",
    "            return render_template(\n",
    "                \"analysis_umap.html\",\n",
    "                sample_name=samp,\n",
    "                reference_name=ref,\n",
    "                new=new,\n",
    "                first_use = not binary_reference_data_exists(),\n",
    "            )\n",
    "        else:\n",
    "            raise cherrypy.HTTPError(404, \"URL not found\")\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def cnv(self, samp, genes=\"\", new=\"False\"):\n",
    "        t0=time.time()\n",
    "        print(\"NEW**********************\",new)\n",
    "        try:\n",
    "            cnv_plt_data = CNVData(samp)\n",
    "        except FileNotFoundError:\n",
    "            raise cherrypy.HTTPError(405, \"URL not allowed\")\n",
    "\n",
    "        def make_plot(cnv_data, lock):\n",
    "            \"\"\"Plot function for multiprocessing.\"\"\"\n",
    "            lock.acquire()\n",
    "            if not cnv_data.files_on_disk() or new == \"True\":\n",
    "                cnv_data.make_cnv_plot()\n",
    "            lock.release()\n",
    "\n",
    "        proc = mp.Process(\n",
    "            target=make_plot,\n",
    "            args=(cnv_plt_data, UserInterface.cnv_lock),\n",
    "            name=\"cnv\",\n",
    "        )\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "        cnv_plt_data.read_from_disk()\n",
    "        print(\"CNV=====================\", time.time()-t0)\n",
    "\n",
    "        return cnv_plt_data.plot_cnv_and_genes([genes])\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def umap(self, samp, ref, close_up=\"\", new=\"False\"):\n",
    "        t0=time.time()\n",
    "        try:\n",
    "            umap_data = UMAPData(samp, ref)\n",
    "        except FileNotFoundError:\n",
    "            raise cherrypy.HTTPError(405, \"URL not allowed\")\n",
    "\n",
    "        def make_plot(plt_data, lock):\n",
    "            \"\"\"Plot function for multiprocessing.\"\"\"\n",
    "            lock.acquire()\n",
    "            if not plt_data.files_on_disk() or new == \"True\":\n",
    "                plt_data.make_umap_plot()\n",
    "            lock.release()\n",
    "\n",
    "        proc = mp.Process(\n",
    "            target=make_plot,\n",
    "            args=(umap_data, UserInterface.umap_lock),\n",
    "            name=\"umap\",\n",
    "        )\n",
    "        proc.start()\n",
    "        proc.join()\n",
    "        umap_data.read_from_disk()\n",
    "\n",
    "        if close_up == \"True\":\n",
    "            return umap_data.cu_plot_json\n",
    "\n",
    "        return umap_data.plot_json\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def umapplot(self, sampleName=None, refAnno=None):\n",
    "        html = \"\"\n",
    "        if sampleName and refAnno:\n",
    "            while UserInterface.umapQueue > 0:\n",
    "                time.sleep(2)\n",
    "            UserInterface.umapQueue += 1\n",
    "            reference_name = refAnno.replace(\".xlsx\", \"\")\n",
    "            try:\n",
    "                make_umap_plot(sampleName, reference_name)\n",
    "                html_error = \"\"\n",
    "            except: #TODO which exception?\n",
    "                html_error = \"\"\"\n",
    "                    <b>\n",
    "                    <font color='#FF0000'>ERROR OCCURRED, PLEASE RELOAD TAB\n",
    "                    </font>\n",
    "                    </b>\"\"\"\n",
    "            html += f\"\"\"\n",
    "                <html>\n",
    "                <head>\n",
    "                <title>\n",
    "                    {sampleName} against {refAnno} at {date_time_string_now()}\n",
    "                </title>\n",
    "                <meta http-equiv='refresh' content='1;\n",
    "                    URL=reports/{sampleName}_{reference_name}_UMAP_all.html'>\"\n",
    "                </head>\n",
    "                <body>\n",
    "                {html_error}\n",
    "                Loading UMAP plot. If it fails,\n",
    "                <a href='reports/{sampleName}_{reference_name}_UMAP_all.html'>\n",
    "                    click here to load plot\n",
    "                </a>.\n",
    "                </body>\n",
    "                </html>\"\"\"\n",
    "            UserInterface.umapQueue -= 1\n",
    "        return html\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def make_pdf(self, samp=None, ref=None):\n",
    "        path = os.path.join(NANODIP_REPORTS, samp + \"_cpgcount.txt\")\n",
    "        with open(path, \"r\") as f:\n",
    "            overlap_cnt = f.read()\n",
    "\n",
    "        path = os.path.join(NANODIP_REPORTS, samp + \"_alignedreads.txt\")\n",
    "        with open(path, \"r\") as f:\n",
    "            read_numbers = f.read()\n",
    "\n",
    "        cnv_path = os.path.join(NANODIP_REPORTS, samp + \"_CNVplot.png\") #TODO png\n",
    "        umap_path = os.path.join(\n",
    "            NANODIP_REPORTS,\n",
    "            samp + \"_\" + ref + \"_UMAP_top.png\",\n",
    "        )\n",
    "\n",
    "        html_report = render_template(\n",
    "            \"pdf_report.html\",\n",
    "            sample_name=samp,\n",
    "            sys_name=socket.gethostname(),\n",
    "            date=date_time_string_now(),\n",
    "            barcode=predominant_barcode(samp),\n",
    "            reads=read_numbers,\n",
    "            cpg_overlap_cnt=overlap_cnt,\n",
    "            reference=ref,\n",
    "            cnv_path=cnv_path,\n",
    "            umap_path=umap_path,\n",
    "        )\n",
    "        report_name = samp + \"_\" + ref + \"_NanoDiP_report.pdf\"\n",
    "        report_path = os.path.join(NANODIP_REPORTS, report_name)\n",
    "        convert_html_to_pdf(html_report, report_path)\n",
    "        raise cherrypy.HTTPRedirect(os.path.join(\"reports\", report_name))\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def about(self):\n",
    "        return render_template(\"about.html\")\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def DeviceStatusLive(self,deviceString=\"\"):\n",
    "        currentFlowCellId=getFlowCellID(deviceString)\n",
    "        myString=\"<html><head><title>\"+deviceString+\": \"+currentFlowCellId+\"</title>\"\n",
    "        try:\n",
    "            myString=myString+\"<meta http-equiv='refresh' content='2'>\"\n",
    "            if getRealDeviceActivity(deviceString)==\"sequencing\":\n",
    "                myString=myString+\"<body bgcolor='#00FF00'>\"\n",
    "            else:\n",
    "                myString=myString+\"<body>\"\n",
    "            myString=myString+\"<b>\"+deviceString+\": \"+currentFlowCellId+\"</b><br><tt>\"\n",
    "            myString=myString+getMinKnowApiStatus(deviceString)\n",
    "        except:\n",
    "            myString=myString+\"<br>No previous device activity, information will appear as soon as the device has been running once in this session.<br>\"\n",
    "        myString=myString+\"Sample ID: \"+getThisRunSampleID(deviceString)+\"<br>\"\n",
    "        myString=myString+getThisRunState(deviceString)\n",
    "        myString=myString+\"<br>\"+getThisRunYield(deviceString)\n",
    "        myString=myString+\"</tt></body></html>\"\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def AnalysisStatusLive(self,deviceString=\"\"):\n",
    "        myString=\"\"\n",
    "        if deviceString:\n",
    "            myString=livePage(deviceString)\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analysisLauncher(self,functionName=\"\",sampleName=\"\",refAnno=\"\"):\n",
    "        if functionName and sampleName and refAnno:\n",
    "            myString=\"<html><head><title>\"+sampleName+\" \"+functionName+\"</title></head><body>\"\n",
    "            myString=myString+functionName+\" launched for \"+sampleName+\" \"\n",
    "            if refAnno!=\"None\":\n",
    "                myString=myString+\"against \"+refAnno\n",
    "            myString=myString+\" at \"+date_time_string_now()+\". \"\n",
    "            myString=myString+\"Frame below will display result upon completion, if this tab/window is kept open.\"\n",
    "            if refAnno==\"None\":\n",
    "                myString=myString+\"<br><iframe src='./\"+functionName+\"?sampleName=\"+sampleName+\"' height='95%' width='100%' title='\"+sampleName+\"' border=3></iframe>\"\n",
    "            else:\n",
    "                myString=myString+\"<br><iframe src='./\"+functionName+\"?sampleName=\"+sampleName+\"&refAnno=\"+refAnno+\"' height='95%' width='100%' title='\"+sampleName+\"' border=3></iframe>\"\n",
    "        else:\n",
    "            myString=\"Nothing to launch. You may close this tab now.\"\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def analysisPoller(self,sampleName=\"\",deviceString=\"\",runId=\"\"):\n",
    "        myString=\"<html><head>\"\n",
    "        if sampleName and deviceString and runId:\n",
    "                myString=myString+\"<title>Poller: \"+sampleName+\"/\"+deviceString+\"/\"+runId+\"</title>\"\n",
    "                myString=myString+\"<meta http-equiv='refresh' content='15'>\"\n",
    "                myString=myString+\"<body>\"\n",
    "                myString=myString+\"Last refresh for \"+sampleName+\"/\"+deviceString+\"/\"+runId+\" at \"+date_time_string_now()\n",
    "                myString=myString+\"</body></html>\"\n",
    "                writeRunTmpFile(sampleName,deviceString)\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def methylationPoller(self,sampleName=\"\"):\n",
    "        while UserInterface.cpgQueue>0:\n",
    "            time.sleep(2)\n",
    "        UserInterface.cpgQueue+=1\n",
    "        myString=methcallLivePage(sampleName)\n",
    "        UserInterface.cpgQueue-=1\n",
    "        return myString\n",
    "\n",
    "    @cherrypy.expose\n",
    "    def launchAutoTerminator(self,sampleName=\"\",deviceString=\"\"):\n",
    "        myString=\"ERROR\"\n",
    "        if sampleName and deviceString:\n",
    "            myString=thisRunWatcherTerminator(deviceString,sampleName)\n",
    "        return myString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3879c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Start CherryPy Webserver\n",
    "    if DEBUG_MODE:\n",
    "        #set access logging\n",
    "        cherrypy.log.screen = True\n",
    "        cherrypy.config.update({'log.screen': True})\n",
    "    else:\n",
    "        #set access logging\n",
    "        cherrypy.log.screen = False\n",
    "        cherrypy.config.update({'log.screen': False})\n",
    "        cherrypy.config.update({ \"environment\": \"embedded\" })\n",
    "\n",
    "    print(f\"NanoDiP server running at http://{CHERRYPY_HOST}:{CHERRYPY_PORT}\")\n",
    "\n",
    "    cherrypy_config = {\n",
    "        '/favicon.ico': {\n",
    "            'tools.staticfile.on': True,\n",
    "            'tools.staticfile.filename': BROWSER_FAVICON,\n",
    "        },\n",
    "        '/img': {\n",
    "            'tools.staticdir.on': True,\n",
    "            'tools.staticdir.dir': IMAGES,\n",
    "        },\n",
    "        '/reports': {\n",
    "            'tools.staticdir.on': True,\n",
    "            'tools.staticdir.dir': NANODIP_REPORTS,\n",
    "        },\n",
    "        '/static': {\n",
    "            'tools.staticdir.on': True,\n",
    "            'tools.staticdir.dir': os.path.join(os.getcwd(), \"static\"),\n",
    "        },\n",
    "    }\n",
    "    cherrypy.quickstart(UserInterface(), \"/\", cherrypy_config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba79c83b",
   "metadata": {},
   "source": [
    "\n",
    "### ^^^ LIVE LOG ABOVE ^^^\n",
    "All CherryPy access will be logged here, including live progress bars for\n",
    "computationally intense analyses. Detailed access logging is turned off by\n",
    "default (accessLogging is False), but can be turned on,e.g., for debugging,\n",
    "in the configuration section at the beginning of this notebook. While it is not\n",
    "required to have at look at these during normal operation, information\n",
    "contained in the log may be helpful in troubleshooting. Line numbers in error\n",
    "messages indicated here typically match those given in the respective Jupyter\n",
    "Notebook cells.\n",
    "\n",
    "To preseve these messages, halt the Python kernel, save and close the notebook\n",
    "to send it for support. This makes sure that the code as well as the error\n",
    "messages will be preserved.\n",
    "\n",
    "To launch the user interface, wait until you see a pink log entry that the web\n",
    "server has started, then navigate to http://localhost:8080.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
